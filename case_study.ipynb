{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Data Cleaning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x93G_WOYjsvQ"
   },
   "outputs": [],
   "source": [
    "DATAPOINTS = 112357#number of datapoints to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bceC_3noXskd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('file1.csv',nrows = DATAPOINTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1 finding duplicate rows and removing them </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-UdEORZcZBBh",
    "outputId": "c50e6f0a-be34-4cb2-fac2-b3e5562f0000"
   },
   "outputs": [],
   "source": [
    "print(\"number of duplicated rows\",len(df[df.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "34y8g6m7Wr2N",
    "outputId": "dd508b67-2964-4bfa-fa87-a34b3a953245"
   },
   "outputs": [],
   "source": [
    "#drop duplictes\n",
    "df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "lKSMMTS6bxhJ",
    "outputId": "4bed4350-b330-4542-92a3-c6fdfbbf2112"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "M2Scz96aWr6Y",
    "outputId": "51089f7a-1cbc-49a2-8064-65dfd8348d59"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vpPAjbVcZzZ7",
    "outputId": "69576fa0-71f7-454c-d81f-c9570ebeaf4d"
   },
   "outputs": [],
   "source": [
    "print('~> Total number of questions :\\n   {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.2 Checking whether there are any rows with null values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "R1PdVTFxZzXb",
    "outputId": "b9de667b-24f1-4cb7-ca4b-e6a068233123"
   },
   "outputs": [],
   "source": [
    "nan_rows = df[df.isnull().any(1)]\n",
    "print (nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.3 finding max and min length of questions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vPgdgIPDZzU3",
    "outputId": "5c65db0a-fa0e-46a0-948d-89328cc75f6e"
   },
   "outputs": [],
   "source": [
    "s = df['Body'].str.len()\n",
    "print('Minimum length of the question :',min(s))\n",
    "print('Maximum length of the question :',max(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "-83pPG5RZzNt",
    "outputId": "e78d2e25-6688-4b9a-8b21-e0a2c1d224c9"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.manifold import TSNE\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xCKt_D0eSIP"
   },
   "source": [
    "<h3> 1.4 most common words </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "f_Aw9LokeSE0",
    "outputId": "4ee8a98f-9076-4abb-d678-392bb5dc3337"
   },
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"black\", max_words=len(df),width=1600,\n",
    "                          height=800, stopwords=stopwords1)\n",
    "wc.generate(str(df[\"Body\"]))\n",
    "print (\"Word Cloud for Question \")\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2 Cleaning and preprocessing of Questions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1 Preprocessing </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> \n",
    "    <li> Separate out code-snippets from Body </li>\n",
    "    <li> Remove Spcial characters from Question title and description (not in code)</li>\n",
    "    <li> Remove stop words (Except 'C') </li>\n",
    "    <li> Remove HTML Tags </li>\n",
    "    <li> Convert all the characters into small letters </li>\n",
    "    <li> Use SnowballStemmer to stem the words </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLis6mVWeSCL"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "def striphtml(data):\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    cleantext = soup.get_text()\n",
    "    soup1 = BeautifulSoup(cleantext, 'html5lib')\n",
    "    cleantext = soup1.get_text()\n",
    "    cleantext = re.sub('<.*?>', ' ', str(cleantext))  \n",
    "    cleantext = re.sub('\\\\n', ' ', str(cleantext))  \n",
    "    cleantext=re.sub('\\sdiv\\s', ' ', str(cleantext), flags=re.MULTILINE|re.DOTALL)\n",
    "\n",
    "    return cleantext\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "25Zc5FeLMXtF",
    "outputId": "f70f5f70-95d8-48d5-dc71-c8f71d4cc762"
   },
   "outputs": [],
   "source": [
    "print(df['Body'][1])\n",
    "striphtml(df['Body'][1].encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvOFuqUqaLsM"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "4ERz_WJrjKZc",
    "outputId": "2dd2d043-76d3-4bd5-86d2-ff7996f10546"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "preprocessed_data_list=[]\n",
    "preprocessed_data_list_code = []\n",
    "questions_with_code=0\n",
    "len_pre=0\n",
    "len_post=0\n",
    "questions_proccesed = 0\n",
    "for row in tqdm(range(len(df))):\n",
    "    is_code = 0\n",
    "    title, question = df['Title'][row], df['Body'][row]\n",
    "    if '<code>' in question:\n",
    "        questions_with_code+=1\n",
    "        is_code = 1\n",
    "    x = len(question)+len(title)\n",
    "\n",
    "    len_pre+=x\n",
    "\n",
    "    code = str(re.findall(r'<code>(.*?)</code>', question, flags=re.DOTALL))\n",
    "    preprocessed_data_list_code.append(code)\n",
    "    question = re.sub('<code>(.*?)</code>', '', question, flags=re.MULTILINE|re.DOTALL)#keeping the code content\n",
    "    question=striphtml(question.encode('utf-8'))\n",
    "    question=str(title)+\" \"+str(question)\n",
    "\n",
    "    question=re.sub(r'[^A-Za-z]+',' ',question)\n",
    "    words= word_tokenize(str(question.lower()))\n",
    "\n",
    "    #Removing all single letter and and stopwords from question exceptt for the letter 'c'\n",
    "    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n",
    "    preprocessed_data_list.append(question)\n",
    "    len_post+=len(question)\n",
    "\n",
    "    questions_proccesed += 1\n",
    "\n",
    "no_dup_avg_len_pre=(len_pre*1.0)/questions_proccesed\n",
    "no_dup_avg_len_post=(len_post*1.0)/questions_proccesed\n",
    "\n",
    "print( \"\\nAvg. length of questions(Title+Body) before processing: %d\"%no_dup_avg_len_pre)\n",
    "print( \"\\nAvg. length of questions(Title+Body) after processing: %d\"%no_dup_avg_len_post)\n",
    "print (\"\\nPercent of questions containing code: %d\"%((questions_with_code*100.0)/questions_proccesed))\n",
    "print(\"\\nTime taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MfHI4Z5UqTwx",
    "outputId": "60af1589-870c-4e16-f376-f25e8ae1ff39"
   },
   "outputs": [],
   "source": [
    "print(len(preprocessed_data_list))\n",
    "print(len(preprocessed_data_list_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2 sample output of Preprocessing </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "n_cu3_6tRpJv",
    "outputId": "72125825-8459-4805-9768-29dd0f29a81e"
   },
   "outputs": [],
   "source": [
    "k=1\n",
    "print(df['Body'][k])\n",
    "print('='*100)\n",
    "print(preprocessed_data_list[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.3 converting preprocessed data into dataframe and storing it as csv </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAnMAr0otV87"
   },
   "outputs": [],
   "source": [
    "preprocessed = pd.DataFrame(zip(df['Title'],df['Body'],preprocessed_data_list,preprocessed_data_list_code),columns= [\"title\",\"content\",\"questions\",\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "J6Oi7Gphtzfb",
    "outputId": "0f62553c-f13f-4eeb-a31f-52f74e272da6"
   },
   "outputs": [],
   "source": [
    "preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9aoa3jxldPhp",
    "outputId": "d0c48387-6179-44ef-e875-b546c4b8c4e6"
   },
   "outputs": [],
   "source": [
    "preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n98-qx75t9q9"
   },
   "outputs": [],
   "source": [
    "preprocessed.to_csv(\"preprocessed_1.5_lacs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Machine Learning Models </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Split the data into test and train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s61qUJWiTJAL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preprocessed = pd.read_csv(\"preprocessed_1.5_lacs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3kG3ChfedlIL",
    "outputId": "9b7587e5-6bfb-4c48-b435-f161c65d46a6"
   },
   "outputs": [],
   "source": [
    "preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "W33dPZC2cnLQ",
    "outputId": "68718af4-7d3c-49e0-a42d-8ede914f0c6f"
   },
   "outputs": [],
   "source": [
    "print(preprocessed.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_j1hVnJuZhm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(preprocessed,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "AXaVD7aZRjdj",
    "outputId": "34edc04d-9fd1-4615-c136-672d677742fd"
   },
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "IipPV0dGGY82",
    "outputId": "d84f5cc7-53c1-4104-f766-faccaf33e363"
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace = True)\n",
    "test.reset_index(inplace = True)\n",
    "print(train.index)\n",
    "print(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "wmVurycVLHaf",
    "outputId": "8cbd07ef-2d36-44b5-b5de-2e3d7a2ba163"
   },
   "outputs": [],
   "source": [
    "#finding length of each sentences\n",
    "import numpy as np\n",
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "\n",
    "preprocessed['len'] = preprocessed.questions.apply(get_wordlen)\n",
    "#reviews = reviews[reviews.len<50]\n",
    "leng = (preprocessed[\"len\"].values)\n",
    "print('95%of the questions contains{} words'.format(np.percentile(leng,q = 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5WYIh_xGeHZ"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aOl4Ql2GeDF"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "import tensorflow_hub as hub\n",
    "#from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Model-1 : BERT  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "For this case sudy, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
    "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2.1 loading the model  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MXiPnPGGd8o"
   },
   "outputs": [],
   "source": [
    "## Loading the Pretrained Model from tensorflow HUB\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# maximum length of a seq in the data we have, for now i am making it as 200. You can change this\n",
    "max_seq_length = 200\n",
    "\n",
    "#BERT takes 3 inputs\n",
    "\n",
    "#this is input words. Sequence of words represented as integers\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "#mask vector if you are padding anything\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
    "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
    "#second seq segment vector are 1's\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#bert layer \n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "#Bert model\n",
    "#We are using only pooled output not sequence out. \n",
    "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2.2 summary of the model  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "nAi6fJpaGd5b",
    "outputId": "0774b43f-6819-4a7c-e088-52fc58f2d4fd"
   },
   "outputs": [],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1ODE0HkHHBuC",
    "outputId": "0877663e-bb83-4a57-8ce3-eddcbbf3073b"
   },
   "outputs": [],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2.3 preprocessing the text  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3FPPImAtHBsd",
    "outputId": "d3c1022c-e9d6-431e-a9d9-762bb0570753"
   },
   "outputs": [],
   "source": [
    "#getting Vocab file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "print(do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XWr2mB8NHBo1",
    "outputId": "25c4c006-d5e7-4293-b0f8-983caf0ffd5e"
   },
   "outputs": [],
   "source": [
    "#import tokenization - We have given tokenization.py file\n",
    "!pip install sentencepiece \n",
    "from bert import tokenization\n",
    "from bert.tokenization import FullTokenizer\n",
    "tokenizer = FullTokenizer(vocab_file,do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgPyQcaPHBnN"
   },
   "outputs": [],
   "source": [
    "def tok(text):\n",
    "  tokens = tokenizer.tokenize(text)#tokenizing the input\n",
    "  tokens = tokens[0:max_seq_length-2]\n",
    "  tokens = ['[CLS]',*tokens,'[SEP]']#adding tokens at the START and END\n",
    "  X_train_mask = list([1]*len(tokens)+[0]*(max_seq_length-len(tokens)))#creating mask tokens by putting zeros where there are not any tokens\n",
    "  X_train_segment = list([0]*max_seq_length)#creating segment\n",
    "  remain = max_seq_length-(len(tokens))\n",
    "  tokens.extend(['[PAD]' for i in range(remain)])#padding the tokens\n",
    "  X_train_tokens = list(tokenizer.convert_tokens_to_ids(tokens))#tokenizing the created tokens into ids\n",
    "  return X_train_tokens,X_train_mask,X_train_segment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>converting train data into tokens,mask and segments  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from absl import flags\n",
    "sys.argv=['preserve_unused_tokens=False']\n",
    "flags.FLAGS(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2F4FT3h0HBjt",
    "outputId": "9f844265-be77-482d-8e3e-670f0d9b64f7"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "train_tokens = np.zeros(shape = (len(train),max_seq_length))#array for tokens\n",
    "train_mask = np.zeros(shape = (len(train),max_seq_length))#array for mask\n",
    "train_segment = np.zeros(shape = (len(train),max_seq_length))#array for segments\n",
    "for rows in tqdm(range(len(train))):\n",
    "  tokens,mask,segment = tok(train[\"questions\"][rows])\n",
    "  train_tokens[rows] = tokens\n",
    "  train_mask[rows] = mask\n",
    "  train_segment[rows] = segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>converting test data into tokens,mask and segments  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hcWPd1q2HBgQ",
    "outputId": "9ceb4b36-1772-4ab0-f6d4-fc8b720e388b"
   },
   "outputs": [],
   "source": [
    "test_tokens = np.zeros(shape = (len(test),max_seq_length))\n",
    "test_mask = np.zeros(shape = (len(test),max_seq_length))\n",
    "test_segment = np.zeros(shape = (len(test),max_seq_length))\n",
    "\n",
    "for rows in tqdm(range(len(test))):\n",
    "  tokens,mask,segment = tok(test[\"questions\"][rows])\n",
    "  test_tokens[rows] = tokens\n",
    "  test_mask[rows] = mask\n",
    "  test_segment[rows] = segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>predicting the word embedding  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_WOetWGTRvU"
   },
   "outputs": [],
   "source": [
    "# get the train output, BERT model will give one output so save in\n",
    "train_pooled_output = bert_model.predict([train_tokens, train_mask,train_segment] )\n",
    "import pickle\n",
    "\n",
    "pickle.dump(train_pooled_output,open('train_pooled_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gae82pwOHSX2"
   },
   "outputs": [],
   "source": [
    "# get the test output, BERT model will give one output so save in\n",
    "test_pooled_output =bert_model.predict([ test_tokens, test_mask, test_segment] )\n",
    "import pickle\n",
    "pickle.dump(test_pooled_output,open('test_pooled_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Szc_LB1HWpII"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_pooled_output = pickle.load(open('train_pooled_output.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlpYfcviXGb5"
   },
   "outputs": [],
   "source": [
    "test_pooled_output = pickle.load(open('/test_pooled_output.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSAjCSbcXLV5"
   },
   "outputs": [],
   "source": [
    "test_pooled_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "0hHi6nCoOWCh",
    "outputId": "2006722b-53ef-406b-93da-84c8f5d2d438"
   },
   "source": [
    "<h3>3.2.4 finding most similar document  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbKK4z1mUmh3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def most_sim__doc(text):\n",
    "  pred_tokens = np.zeros(shape = (1,max_seq_length))\n",
    "  pred_mask = np.zeros(shape = (1,max_seq_length))\n",
    "  pred_segment = np.zeros(shape = (1,max_seq_length))\n",
    "\n",
    "  tokens,mask,segment = tok(text)\n",
    "  pred_tokens[0] = tokens\n",
    "  pred_mask[0] = mask\n",
    "  pred_segment[0] = segment\n",
    "  pooled_output = bert_model.predict([pred_tokens,pred_mask,pred_segment])\n",
    "  similarity =  cosine_similarity(pooled_output, Y=train_pooled_output, dense_output=True)\n",
    "  #print('query :\\n',train[\"content\"][train_row])\n",
    "  most_common = np.argsort(similarity[0])\n",
    "  s = most_common[-5:]\n",
    "  print(s)\n",
    "  rev = np.flip(s)\n",
    "  #print(similarity[train_row][rev])\n",
    "  se = train[\"content\"][rev].values\n",
    "  lst = [\"BERT\"]\n",
    "  for i in se:\n",
    "    i = striphtml(i)\n",
    "\n",
    "    sub_string = i.split()[:50]\n",
    "    lst.append(\" \".join(sub_string))\n",
    "  return (lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XI8XeARjM7B"
   },
   "outputs": [],
   "source": [
    "l1 = most_sim__doc('what is superclass in object orient programming?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TJY5hgIkyz_"
   },
   "outputs": [],
   "source": [
    "print(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbTqGFPtQ38K"
   },
   "source": [
    "# 3.3 Model-2 : DOC2VEC MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.1 preprocessing the sentences</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-sIAa7Xlg8f"
   },
   "outputs": [],
   "source": [
    "#https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-download-auto-examples-tutorials-run-doc2vec-lee-py\n",
    "\n",
    "import smart_open\n",
    "import os\n",
    "import gensim\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "        for i, line in enumerate(fname):\n",
    "            tokens = gensim.utils.simple_preprocess(line)#preprocess the sentence\n",
    "            if tokens_only:#for test data yield only tokens\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus((train[\"questions\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "RNYo4_5-nIK8",
    "outputId": "c48fd407-ad4a-4c55-83b8-5d30484702dd"
   },
   "outputs": [],
   "source": [
    "train_corpus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "dBsKgN34lg63",
    "outputId": "a36dabed-2fb9-4c5c-ef70-504bed073687"
   },
   "outputs": [],
   "source": [
    "gensim.models.doc2vec.TaggedDocument.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.2 defining the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMyfS1pKlg5I"
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec(vector_size=30,alpha=0.025,min_alpha=0.00025,min_count=20, epochs=50, workers=-1,dm =1)#\n",
    "#dm defines the training algorithm. If dm=1 means ‘distributed memory’ (PV-DM) and dm =0 means ‘distributed bag of words’ (PV-DBOW). Distributed Memory model preserves the word order in a document whereas Distributed Bag of words just uses the bag of words approach, which doesn’t preserve any word order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.3 building the vocabulary</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKU2lbHtlg0K"
   },
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "FmVRlYxPn2en",
    "outputId": "02e82a8e-445e-4290-9611-6a8e160bc8c1"
   },
   "outputs": [],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.4 training the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjDPtAy3lgyL"
   },
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "glZtrDusx3vD",
    "outputId": "ad0ad8e5-6ec2-487f-da17-aa84daf64be4"
   },
   "outputs": [],
   "source": [
    "model.docvecs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>finding the most similar doc</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "p3PyF1UIlgwW",
    "outputId": "e83cfe4e-e03b-4bb3-acec-044a1ba48d34"
   },
   "outputs": [],
   "source": [
    "test_corpus = list(read_corpus(('what is superclass in object orient programming','what is superclass in object orient programming'), tokens_only=True))\n",
    "vector = model.infer_vector(test_corpus[0])\n",
    "simi = (model.docvecs.most_similar([vector], topn=5))#this algorithm by default calculates cosine similarity as a distance metric\n",
    "print(simi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bVkw-Amlgrb"
   },
   "outputs": [],
   "source": [
    "sim_doc2vec = [\"DOC2VEC\"]\n",
    "for i in range(len(simi)):\n",
    "  idx = (simi[i][0])\n",
    "  se = train[\"content\"][idx].split()[:50]\n",
    "  sim_doc2vec.append(\" \".join(se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.5 displaying result in pretty table</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "GdeTr1FZ98-a",
    "outputId": "2d68baf4-3251-457f-ddd7-0af34fde0903",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable(['model','TOP result1','TOP result2','TOP result3','TOP result4','TOP result5'])\n",
    "x.align = \"l\"\n",
    "#x.add_row(l1)\n",
    "x.add_row(sim_doc2vec)\n",
    "print(\"Qurey : what is superclass in object orient programming\" )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cntgkvUKBv44"
   },
   "outputs": [],
   "source": [
    "Qurey : what is superclass in object orient programming\n",
    "+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| model   | TOP result1                                                                                                                                                                                                                                                                                                                                                                                  | TOP result2                                                                                                                                                                                                                                                                                                                                                    | TOP result3                                                                                                                                                                                                                                                                                                         | TOP result4                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | TOP result5                                                                                                                                                                                                                                                                                           |\n",
    "+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| BERT    | Custom view transition in OpenGL ES<p>I'm trying to create a custom transition, to serve as a replacement for a default transition you would get here, for example:</p> <pre><code>[self.navigationController pushViewController:someController animated:YES]; </code></pre> <p>I have prepared an OpenGL-based view that performs an effect on some static texture mapped to a plane (let's | Dynamic contact information data/design pattern: Is this in any way feasible?<p>I'm currently working on a web business application that has many entities (people,organizations) with lots of contact information ie. multiple postal addresses, email addresses, phone numbers etc. </p> <p>At the moment the database schema is such that persons table has | Databinding with Silverlight<p>If I want to bind a collection to a some form of listing control in Silverlight. Is the only way to do it so make the underlying objects in the collection implement INotifyPropertyChanged and for the collection to be an Observablecollection?</p> <p>If I was using some sort of | SharePoint Default Styles<p>I'm building a custom web part for SharePoint and I'm trying to use the default styles so when people theme the site, it will theme with it.</p> <p>I've found a couple of decent sites that show the different styles like: <a href=\"http://www.sharepointcustomization.com/resources/tipstricks/wss_cssguide.htm\" rel=\"nofollow noreferrer\">http://www.sharepointcustomization.com/resources/tipstricks/wss_cssguide.htm</a></p> <p>but I'm looking for | passing void to a generic class<p>I'm trying to create a form that will animate something while processing a particular task (passed as a delegate to the constructor). It's working fine, but the problem I'm having is that I can't instantiate a copy of my generic class if the particular method |\n",
    "| DOC2VEC | What is software development at your company really like (methodologies, tools, ...)?<p>Since I've started my first job as a professional software developer about two years ago, I've read many articles about commonly accepted methodologies (e.g. Scrum, XP), technologies (e.g. EJB, Spring), techniques (e.g. TDD, code reviews), tools (bug tracking, wikis)                          | Best reference / crib sheet for AWK<p>In a series of similar questions, what is the best AWK reference you've ever seen? </p> <p>If there isn't really one (I've yet to find the grail), perhaps we could compile one in a separate question.</p>                                                                                                              | control lost focus event when using keyboard shortcut<p>For both .NET Winforms and Windows Presentation Foundation, if I have a text box that the user has just entered text into, and a button, if the user clicks the button the \"LostFocus\" event fires before the button click event fires. However if          | Best free Java .class viewer?<p>I've used <a href=\"http://members.fortunecity.com/neshkov/dj.html\" rel=\"noreferrer\">DJ Java Decompiler</a>, which has a handy GUI, but it seems as if the latest version is only a trial and forces you to purchase the software after some period of days (I recall using an earlier free version about a year                                                                                                                                       | How do I turn a python program into an .egg file?<p>How do I turn a python program into an .egg file?</p>                                                                                                                                                                                             |\n",
    "+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhJmWdGzRBFm"
   },
   "source": [
    "# 3.4 Model-3 TFIDF- W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4.1 converting sentences into list of sentences</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeHQnPdSgtkB"
   },
   "outputs": [],
   "source": [
    "list_of_sentance=[]\n",
    "for sentance in (train[\"questions\"]):\n",
    "    list_of_sentance.append(sentance.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4.2 tfidf vectorization of sentences</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDfMLCMPRFRm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(train[\"questions\"])\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "\n",
    "dictionary = dict(zip(tfidf.get_feature_names(),tfidf.idf_))#this dictionary will contain tfidf value of the particular word\n",
    "zip for Converting two lists into a dictionary\n",
    "# refer : https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('tfidf','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JnyGI-nUauNB",
    "outputId": "b4da2f5a-348b-4a95-b6d0-3567e9ccb914"
   },
   "outputs": [],
   "source": [
    "dictionary['extract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4.3 training the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iY4J75EDYOFL",
    "outputId": "469aa9e5-0c6e-4dc2-f6e5-9b6c9c29e1f9"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "vec_size = 50#output vector size\n",
    "w2v_model=Word2Vec(list_of_sentance,min_count=10,size=vec_size, workers=-1, iter=30)#for training w2v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.4.4 for pretrained w2v</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''from gensim.models import KeyedVectors\n",
    "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)'''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ntV9Oz60gB_L",
    "outputId": "009b2e67-0b5e-4cf9-b616-e6d5d1d44cf2"
   },
   "outputs": [],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"sample words \", w2v_words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.4.5 TF-IDF weighted Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "POcxixVTgOE4",
    "outputId": "8c0d5877-d126-4874-d318-7f6e3711fb1b"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_feat = tfidf.get_feature_names()\n",
    "tfidf_sent_vectors = []# the tfidf-w2v for each sentence/review is stored in this list\n",
    "row = 0\n",
    "for sent in tqdm(list_of_sentance): # for each review/sentence \n",
    "  sent_vec = np.zeros(vec_size)# as word vectors are of zero length\n",
    "  weight_sum = 0# num of words with a valid vector in the sentence/review\n",
    "  for word in sent:# for each word in a review/sentence\n",
    "\n",
    "    if word in tfidf_feat and word in w2v_words :\n",
    "      vec = w2v_model.wv[word]\n",
    "        # tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "        # to reduce the computation we are \n",
    "        # dictionary[word] = idf value of word in whole courpus\n",
    "        # sent.count(word) = tf valeus of word in this review\n",
    "      tf_idf = dictionary[str(word)]*(sent.count(word)/len(sent))\n",
    "      sent_vec+= (vec*tf_idf)\n",
    "      weight_sum += tf_idf\n",
    "  if weight_sum !=0:\n",
    "    sent_vec /= weight_sum \n",
    "  tfidf_sent_vectors.append(sent_vec)\n",
    "  row+=1\n",
    "import pickle\n",
    "pickle.dump(tfidf_sent_vectors,open('tfidf_sent_vectors_500','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1nWZ-OtgITt"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tfidf_sent_vectors = pickle.load(open('tfidf_sent_vectors_300','rb'))\n",
    "tfidf = pickle.load(open('tfidf','rb'))\n",
    "w2v_words = pickle.load(open('w2v_words','rb'))\n",
    "w2v_model = pickle.load(open('w2v_model','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CHsCH8nvgZlI",
    "outputId": "090a6e2c-8d37-4a19-e752-f0b0285238a4"
   },
   "outputs": [],
   "source": [
    "print(len(tfidf_sent_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.4.6 finding most similar docs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def preprocess(data):\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    cleantext = soup.get_text()\n",
    "    soup1 = BeautifulSoup(cleantext, 'html5lib')\n",
    "    cleantext = soup1.get_text()\n",
    "    cleantext = re.sub('<.*?>', ' ', str(cleantext))  \n",
    "    cleantext = re.sub('\\\\n', ' ', str(cleantext))  \n",
    "    cleantext=re.sub('\\sdiv\\s', ' ', str(cleantext), flags=re.MULTILINE|re.DOTALL)\n",
    "    cleantext = re.sub(r'[^A-Za-z]+',' ', str(cleantext))  \n",
    "    words=word_tokenize(str(cleantext.lower()))\n",
    "    cleantext=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n",
    "\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULcUyNIQRGqS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "vec_size = 300\n",
    "def most_sim__doc(text):\n",
    "    start = time.time()#noting time for analysis\n",
    "\n",
    "    sent_vec = np.zeros(vec_size)#creating a vector for test sentence\n",
    "    weight_sum = 0\n",
    "    #text = preprocess(text)\n",
    "\n",
    "    lst_sent = list(text.split())#splitting the sentence\n",
    "    for word in lst_sent:#iterating over words\n",
    "        if word in tfidf_feat and word in w2v_words :#finding if word is present in tfidf and in w2v words\n",
    "            vec = w2v_model[word]#finding vector of word\n",
    "            tf_idf = dictionary[str(word)]*(lst_sent.count(word)/len(lst_sent))#computing tfidf \n",
    "            sent_vec+= (vec*tf_idf)#multiplying tfidf woth w2v value\n",
    "            weight_sum += tf_idf#summing the words up\n",
    "    if weight_sum !=0:\n",
    "        sent_vec /= weight_sum #doing weighted sum\n",
    "\n",
    "    similarity =  cosine_similarity((sent_vec).reshape(1, -1), Y=tfidf_sent_vectors, dense_output=True)#finding cosine similaroty of that particular vector with all the vectors in the corpus\n",
    "    most_common = np.argsort(similarity[0])#performing argsort to get index of maximum similarity sentences\n",
    "    s = most_common[-5:]#selecting top 5 results\n",
    "    print(\"top cosine similarities:\",similarity[0][s])\n",
    "    rev = np.flip(s,axis = 0)#flipping the results to get results in decreasing order of similarity\n",
    "    se = train[\"questions\"][rev].values#getting the most similar values\n",
    "    lst = [\"TFIDF-W2V\"]\n",
    "    for i in se:\n",
    "        #i = striphtml(i)#removing the html and preprocessing them\n",
    "        sub_string = i.split()[:50]#considering only first 50 words\n",
    "        lst.append(\" \".join(sub_string))\n",
    "    elapsed_time_fl = (time.time() - start) #counting the time taken to run this loop\n",
    "    print(elapsed_time_fl)\n",
    "    return (lst)#returning the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "3pmPCESNRGl8",
    "outputId": "551a6d3f-443c-446d-ab2d-9e93ba622524"
   },
   "outputs": [],
   "source": [
    "tfidf_feat = tfidf.get_feature_names()\n",
    "tfidf_w2v = most_sim__doc(str('what is superclass in object orient programming'))\n",
    "print((tfidf_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.4.7 displaying the results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "Sh61vkroRGkN",
    "outputId": "a6fe7d54-b0ee-40a6-816b-bbb26efb5772",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable(['model','TOP result1','TOP result2','TOP result3','TOP result4','TOP result5'])#defining the columns of table\n",
    "x.align = \"l\"#alignment of the values\n",
    "\n",
    "x.add_row(tfidf_w2v)#adding row to the table\n",
    "print(\"Qurey : what is superclass in object orient programming\" )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24P_CSg57y1Z"
   },
   "outputs": [],
   "source": [
    "300\n",
    "Qurey : what is superclass in object orient programming\n",
    "+-----------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| model     | TOP result1                                                                                                                 | TOP result2                                                                                                                                                                                                                                                                                                                                                                     | TOP result3                                                                                                                                                                     | TOP result4                                                                                                                                                                                                                                                                                            | TOP result5                                                                                                                                  |\n",
    "+-----------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| TFIDF-W2V | find object class superclass c find object instanc certain class class superclass return true even object actual superclass | problem class design inherit flash problem design class three class one superclass two subclass one subclass animatedcharact made flash use display object screen characterphys made extend superclass problem object use type animatedcharact put variabl type characterphys tri sort decor pattern give object type characterphys refer object overrid method superclass pass | forc variabl superclass assign compil time superclass bunch variabl etc like guarante variabl get overridden assign someth use subclass inherit superclass compil time eleg way | object orient c would set nifti preprocessor hack ansi c iso c compat enabl kind ugli usabl object orient c familiar differ object orient languag pleas respond answer like learn c read object orient program ansi c bewar pdf format sever interest solut most interest see also write object orient | would one write object orient code c way write object orient code c especi regard polymorph see also stack overflow question object orient c |\n",
    "+-----------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ivomASOlVbf"
   },
   "outputs": [],
   "source": [
    "200\n",
    "Qurey : what is superclass in object orient programming\n",
    "+-----------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| model     | TOP result1                                                                                                                 | TOP result2                                                                                                                                             | TOP result3                                                                                                                                                                                                                                                                                            | TOP result4                                                                                                                                  | TOP result5                                                                                                                                                                                                                                                                                                                                                 |\n",
    "+-----------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| TFIDF-W2V | find object class superclass c find object instanc certain class class superclass return true even object actual superclass | object orient model differ object orient program differ object orient model object orient program overheard convers subway train morn seem thing differ | object orient c would set nifti preprocessor hack ansi c iso c compat enabl kind ugli usabl object orient c familiar differ object orient languag pleas respond answer like learn c read object orient program ansi c bewar pdf format sever interest solut most interest see also write object orient | would one write object orient code c way write object orient code c especi regard polymorph see also stack overflow question object orient c | worth convert function javascript code object orient design current build small web applic includ fair amount javascript prototyp initi idea hack togeth function demonstr applic would eventu behav intend go forward write javascript object orient natur get implement phase find creat object orient javascript sake object orient seem overkil project |\n",
    "+-----------+-----------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjDW6y-6NR8n"
   },
   "outputs": [],
   "source": [
    "100\n",
    "Qurey : what is superclass in object orient programming\n",
    "+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| model     | TOP result1                                                                                                                                                                                                                                                                                            | TOP result2                                                                                                                                  | TOP result3                                                                                                                                             | TOP result4                                                                                                                                                                                                                                                                                | TOP result5                                                                                                                                                                                                                                                                                                                                                 |\n",
    "+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| TFIDF-W2V | object orient c would set nifti preprocessor hack ansi c iso c compat enabl kind ugli usabl object orient c familiar differ object orient languag pleas respond answer like learn c read object orient program ansi c bewar pdf format sever interest solut most interest see also write object orient | would one write object orient code c way write object orient code c especi regard polymorph see also stack overflow question object orient c | object orient model differ object orient program differ object orient model object orient program overheard convers subway train morn seem thing differ | make languag object orient sinc debat without meaning term meaningless figur would point eleph room ask exact make languag object orient look textbook answer one base experi oo languag work well domain whatev may relat question might help answer first archetyp object orient languag | worth convert function javascript code object orient design current build small web applic includ fair amount javascript prototyp initi idea hack togeth function demonstr applic would eventu behav intend go forward write javascript object orient natur get implement phase find creat object orient javascript sake object orient seem overkil project |\n",
    "+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtltP3zE3G5a"
   },
   "source": [
    "# 3.5 Model-4 : Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvxbBqvJ4ULU"
   },
   "source": [
    "<h3> 3.5.1 loading the model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "sB_YgNtB4TQZ",
    "outputId": "1fdda46c-b2e7-4224-c138-e56ade3c8254"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")#loading the tensorflow hub model\n",
    "\n",
    "def use(sent):#converting sentence into vectors\n",
    "  with tf.Session() as session:\n",
    "      session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "      message_embeddings = session.run(embed(sent))#this will embed the sentence into vectors of size 512\n",
    "      return message_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.5.2 finding word embedding </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "oL7H0ux3_wmh",
    "outputId": "fc3cc33b-d127-42a7-b82e-cd4a5e0dec8a"
   },
   "outputs": [],
   "source": [
    "message_embeddings = use(train[\"questions\"][:50000])\n",
    "print(message_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hDkL0Tt1OFDZ",
    "outputId": "1964ba74-c77f-4fb2-d0df-134568a2e2b8"
   },
   "outputs": [],
   "source": [
    "message_embeddings2 = use(train[\"questions\"][50000:])\n",
    "print(message_embeddings2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9O8Q6NQOQRx"
   },
   "outputs": [],
   "source": [
    "message_embeddings = np.concatenate((message_embeddings, message_embeddings2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "pwTdToPoOdlO",
    "outputId": "210f0df0-9982-4384-c77f-6100eac6ad4a"
   },
   "outputs": [],
   "source": [
    "message_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.5.3 predicting the results </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhBo_KL64TNR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "def most_sim__doc(text):\n",
    "    start = time.time()#noting the current time\n",
    "    sent_vec = use([text])#predicting the embedding\n",
    "    similarity =  cosine_similarity((sent_vec).reshape(1, -1), Y=message_embeddings, dense_output=True)#finding the cosine similarity\n",
    "    most_common = np.argsort(similarity[0])#sorting the similarity to get top results\n",
    "    s = most_common[-5:]#considering the top 5 results\n",
    "    print(\"top cosine similarities:\",similarity[0][s])\n",
    "    rev = np.flip(s,axis = 0)\n",
    "    se = train[\"content\"][rev].values#finding the top indeces values\n",
    "    lst = [\"universal sentence decoder\"]\n",
    "    for i in se:\n",
    "        i = striphtml(i)Epreprocess the output\n",
    "        sub_string = i.split()[:50]#considering first 50 words\n",
    "        lst.append(\" \".join(sub_string))\n",
    "    elapsed_time_fl = (time.time() - start) \n",
    "    print(elapsed_time_fl)\n",
    "    return (lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6ldsz6jS4TLZ",
    "outputId": "2a2fa3b5-b7a6-4897-b2ec-d795ba87d40b"
   },
   "outputs": [],
   "source": [
    "uni_sen_dec = most_sim__doc('what is superclass in object orient programming')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.5.4 displaying the result </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "colab_type": "code",
    "id": "dl5LcsJm4THx",
    "outputId": "e6444d8c-c78b-487d-9743-54f5327f0954"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable(['model','TOP result1','TOP result2','TOP result3','TOP result4','TOP result5'])\n",
    "x.align = \"l\"\n",
    "x.add_row(uni_sen_dec)\n",
    "print(\"Qurey : what is superclass in object orient programming\" )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrCD4NJY4TD_"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Qurey : what is superclass in object orient programming\n",
    "+----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| model                      | TOP result1                                                                                                                                                                                                                                         | TOP result2                                                                                                                                                                                                                                                                                                                              | TOP result3                                                                                                                                                                                                                                                                           | TOP result4                                                                                                                                                                                                                                                      | TOP result5                                                                                                                                                                                            |\n",
    "+----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| universal sentence decoder | Is JavaScript object-oriented?There have been some questions about whether or not JavaScript is an object-oriented language. Even a statement, \"just because a language has objects doesn't make it OO.\" Is JavaScript an object-oriented language? | When is Object Oriented not the correct solution?I've encountered lately some opinions saying that Object Oriented design/programming should not always be used. Do you know some use-cases that will not benefit from and should not use Object Oriented design? For example: there are some problems (concerns) that will benefit from | Is Object-Oriented Modeling different from Object-Oriented Programming?What is the difference between Object-Oriented Modeling and Object-Oriented Programming? I overheard a conversation on my subway train this morning and it seems that these things are different. Aren't they? | Are there any good courses for learning about Object-Oriented Programming?I'm looking for some good courses on object oriented programming. I've been programming for about 4 years so far, but I don't feel like I have a SOLID grasp on OO. How did you learn? | How would one write object-oriented code in C?What are some ways to write object-oriented code in C? Especially with regard to polymorphism. See also Stack Overflow question Object-orientation in C. |\n",
    "+----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "case_study_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
