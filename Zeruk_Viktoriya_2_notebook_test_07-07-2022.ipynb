{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d65fed5",
   "metadata": {},
   "source": [
    "**Auteur** : Viktoriya Zeruk<br>\n",
    "**Date dernière version** : 12/07/2022<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b69f9",
   "metadata": {},
   "source": [
    "# <center><font color=#7DF9FF>Projet 5: <br>Catégorisez automatiquement des questions</font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04adc7",
   "metadata": {},
   "source": [
    "<img src=\"https://user.oc-static.com/upload/2022/03/23/16480242457412_Screenshot%202022-03-23%20at%2009.30.21.png\" alt=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d96b07",
   "metadata": {},
   "source": [
    "# <center><font color=#15f4ee> Modélisation de la prédiction de tags</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-invalid",
   "metadata": {},
   "source": [
    "Ce notebook regroupe les travaux de prétraitement des docuements et les tests des modèles des approches supervisés et non supervisés afin de prédire les tags des posts de Stack Overflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-canyon",
   "metadata": {},
   "source": [
    "## Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-exhaust",
   "metadata": {},
   "source": [
    "Afin de permettre de faciliter le parcours des utilisateurs de l'outil communautaire Stack Overflow nous avons travaillé sur la mise à disposition d'un *système de suggestion de tags*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-termination",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-preparation",
   "metadata": {},
   "source": [
    "Pour les besoins du notebook nous ne conservons que les titres, corps du texte et tags des document importés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "experienced-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is processing a sorted array faster than p...</td>\n",
       "      <td>&lt;p&gt;Here is a piece of C++ code that shows some...</td>\n",
       "      <td>&lt;java&gt;&lt;c++&gt;&lt;performance&gt;&lt;cpu-architecture&gt;&lt;bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I undo the most recent local commits in...</td>\n",
       "      <td>&lt;p&gt;I accidentally &lt;strong&gt;committed the wrong ...</td>\n",
       "      <td>&lt;git&gt;&lt;version-control&gt;&lt;git-commit&gt;&lt;undo&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I delete a Git branch locally and remot...</td>\n",
       "      <td>&lt;p&gt;I want to delete a branch both locally and ...</td>\n",
       "      <td>&lt;git&gt;&lt;version-control&gt;&lt;git-branch&gt;&lt;git-push&gt;&lt;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I force \"git pull\" to overwrite local f...</td>\n",
       "      <td>&lt;p&gt;How do I force an overwrite of local files ...</td>\n",
       "      <td>&lt;git&gt;&lt;version-control&gt;&lt;overwrite&gt;&lt;git-pull&gt;&lt;gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I revert a Git repository to a previous...</td>\n",
       "      <td>&lt;p&gt;How do I revert from my current state to a ...</td>\n",
       "      <td>&lt;git&gt;&lt;git-checkout&gt;&lt;git-reset&gt;&lt;git-revert&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do I check out a remote Git branch?</td>\n",
       "      <td>&lt;p&gt;Somebody pushed a branch called &lt;code&gt;test&lt;...</td>\n",
       "      <td>&lt;git&gt;&lt;git-checkout&gt;&lt;remote-branch&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How to make Git \"forget\" about a file that was...</td>\n",
       "      <td>&lt;p&gt;There is a file that was being tracked by &lt;...</td>\n",
       "      <td>&lt;git&gt;&lt;gitignore&gt;&lt;git-rm&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the difference between \"px\", \"dip\", \"d...</td>\n",
       "      <td>&lt;p&gt;What is the difference between Android unit...</td>\n",
       "      <td>&lt;android&gt;&lt;android-layout&gt;&lt;user-interface&gt;&lt;dime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do I find all files containing specific te...</td>\n",
       "      <td>&lt;p&gt;I'm trying to find a way to scan my entire ...</td>\n",
       "      <td>&lt;linux&gt;&lt;text&gt;&lt;grep&gt;&lt;directory&gt;&lt;find&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the difference between POST and PUT in...</td>\n",
       "      <td>&lt;p&gt;According to &lt;a href=\"https://tools.ietf.or...</td>\n",
       "      <td>&lt;http&gt;&lt;rest&gt;&lt;post&gt;&lt;put&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Why is processing a sorted array faster than p...   \n",
       "1  How do I undo the most recent local commits in...   \n",
       "2  How do I delete a Git branch locally and remot...   \n",
       "3  How do I force \"git pull\" to overwrite local f...   \n",
       "4  How do I revert a Git repository to a previous...   \n",
       "5            How do I check out a remote Git branch?   \n",
       "6  How to make Git \"forget\" about a file that was...   \n",
       "7  What is the difference between \"px\", \"dip\", \"d...   \n",
       "8  How do I find all files containing specific te...   \n",
       "9  What is the difference between POST and PUT in...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>Here is a piece of C++ code that shows some...   \n",
       "1  <p>I accidentally <strong>committed the wrong ...   \n",
       "2  <p>I want to delete a branch both locally and ...   \n",
       "3  <p>How do I force an overwrite of local files ...   \n",
       "4  <p>How do I revert from my current state to a ...   \n",
       "5  <p>Somebody pushed a branch called <code>test<...   \n",
       "6  <p>There is a file that was being tracked by <...   \n",
       "7  <p>What is the difference between Android unit...   \n",
       "8  <p>I'm trying to find a way to scan my entire ...   \n",
       "9  <p>According to <a href=\"https://tools.ietf.or...   \n",
       "\n",
       "                                                Tags  \n",
       "0  <java><c++><performance><cpu-architecture><bra...  \n",
       "1           <git><version-control><git-commit><undo>  \n",
       "2  <git><version-control><git-branch><git-push><g...  \n",
       "3  <git><version-control><overwrite><git-pull><gi...  \n",
       "4         <git><git-checkout><git-reset><git-revert>  \n",
       "5                 <git><git-checkout><remote-branch>  \n",
       "6                           <git><gitignore><git-rm>  \n",
       "7  <android><android-layout><user-interface><dime...  \n",
       "8               <linux><text><grep><directory><find>  \n",
       "9                            <http><rest><post><put>  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "\n",
    "data = pd.read_csv('./data/filtered_data.csv', usecols=['Id','Title', 'Body', 'Tags'], index_col='Id')\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(columns='Id', inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-affiliate",
   "metadata": {},
   "source": [
    "## Pré-traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-supplier",
   "metadata": {},
   "source": [
    "### Constitution du corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-mayor",
   "metadata": {},
   "source": [
    "Nous commençons par créer une nouvelle variable associant le titre (Title) et le corps du texte (Body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "timely-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dix première observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is processing a sorted array faster than p...</td>\n",
       "      <td>&lt;p&gt;Here is a piece of C++ code that shows some...</td>\n",
       "      <td>&lt;java&gt;&lt;c++&gt;&lt;performance&gt;&lt;cpu-architecture&gt;&lt;bra...</td>\n",
       "      <td>Why is processing a sorted array faster than p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I undo the most recent local commits in...</td>\n",
       "      <td>&lt;p&gt;I accidentally &lt;strong&gt;committed the wrong ...</td>\n",
       "      <td>&lt;git&gt;&lt;version-control&gt;&lt;git-commit&gt;&lt;undo&gt;</td>\n",
       "      <td>How do I undo the most recent local commits in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I delete a Git branch locally and remot...</td>\n",
       "      <td>&lt;p&gt;I want to delete a branch both locally and ...</td>\n",
       "      <td>&lt;git&gt;&lt;version-control&gt;&lt;git-branch&gt;&lt;git-push&gt;&lt;g...</td>\n",
       "      <td>How do I delete a Git branch locally and remot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I force \"git pull\" to overwrite local f...</td>\n",
       "      <td>&lt;p&gt;How do I force an overwrite of local files ...</td>\n",
       "      <td>&lt;git&gt;&lt;version-control&gt;&lt;overwrite&gt;&lt;git-pull&gt;&lt;gi...</td>\n",
       "      <td>How do I force \"git pull\" to overwrite local f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I revert a Git repository to a previous...</td>\n",
       "      <td>&lt;p&gt;How do I revert from my current state to a ...</td>\n",
       "      <td>&lt;git&gt;&lt;git-checkout&gt;&lt;git-reset&gt;&lt;git-revert&gt;</td>\n",
       "      <td>How do I revert a Git repository to a previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do I check out a remote Git branch?</td>\n",
       "      <td>&lt;p&gt;Somebody pushed a branch called &lt;code&gt;test&lt;...</td>\n",
       "      <td>&lt;git&gt;&lt;git-checkout&gt;&lt;remote-branch&gt;</td>\n",
       "      <td>How do I check out a remote Git branch? &lt;p&gt;Som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How to make Git \"forget\" about a file that was...</td>\n",
       "      <td>&lt;p&gt;There is a file that was being tracked by &lt;...</td>\n",
       "      <td>&lt;git&gt;&lt;gitignore&gt;&lt;git-rm&gt;</td>\n",
       "      <td>How to make Git \"forget\" about a file that was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the difference between \"px\", \"dip\", \"d...</td>\n",
       "      <td>&lt;p&gt;What is the difference between Android unit...</td>\n",
       "      <td>&lt;android&gt;&lt;android-layout&gt;&lt;user-interface&gt;&lt;dime...</td>\n",
       "      <td>What is the difference between \"px\", \"dip\", \"d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do I find all files containing specific te...</td>\n",
       "      <td>&lt;p&gt;I'm trying to find a way to scan my entire ...</td>\n",
       "      <td>&lt;linux&gt;&lt;text&gt;&lt;grep&gt;&lt;directory&gt;&lt;find&gt;</td>\n",
       "      <td>How do I find all files containing specific te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the difference between POST and PUT in...</td>\n",
       "      <td>&lt;p&gt;According to &lt;a href=\"https://tools.ietf.or...</td>\n",
       "      <td>&lt;http&gt;&lt;rest&gt;&lt;post&gt;&lt;put&gt;</td>\n",
       "      <td>What is the difference between POST and PUT in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Why is processing a sorted array faster than p...   \n",
       "1  How do I undo the most recent local commits in...   \n",
       "2  How do I delete a Git branch locally and remot...   \n",
       "3  How do I force \"git pull\" to overwrite local f...   \n",
       "4  How do I revert a Git repository to a previous...   \n",
       "5            How do I check out a remote Git branch?   \n",
       "6  How to make Git \"forget\" about a file that was...   \n",
       "7  What is the difference between \"px\", \"dip\", \"d...   \n",
       "8  How do I find all files containing specific te...   \n",
       "9  What is the difference between POST and PUT in...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>Here is a piece of C++ code that shows some...   \n",
       "1  <p>I accidentally <strong>committed the wrong ...   \n",
       "2  <p>I want to delete a branch both locally and ...   \n",
       "3  <p>How do I force an overwrite of local files ...   \n",
       "4  <p>How do I revert from my current state to a ...   \n",
       "5  <p>Somebody pushed a branch called <code>test<...   \n",
       "6  <p>There is a file that was being tracked by <...   \n",
       "7  <p>What is the difference between Android unit...   \n",
       "8  <p>I'm trying to find a way to scan my entire ...   \n",
       "9  <p>According to <a href=\"https://tools.ietf.or...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  <java><c++><performance><cpu-architecture><bra...   \n",
       "1           <git><version-control><git-commit><undo>   \n",
       "2  <git><version-control><git-branch><git-push><g...   \n",
       "3  <git><version-control><overwrite><git-pull><gi...   \n",
       "4         <git><git-checkout><git-reset><git-revert>   \n",
       "5                 <git><git-checkout><remote-branch>   \n",
       "6                           <git><gitignore><git-rm>   \n",
       "7  <android><android-layout><user-interface><dime...   \n",
       "8               <linux><text><grep><directory><find>   \n",
       "9                            <http><rest><post><put>   \n",
       "\n",
       "                                                Post  \n",
       "0  Why is processing a sorted array faster than p...  \n",
       "1  How do I undo the most recent local commits in...  \n",
       "2  How do I delete a Git branch locally and remot...  \n",
       "3  How do I force \"git pull\" to overwrite local f...  \n",
       "4  How do I revert a Git repository to a previous...  \n",
       "5  How do I check out a remote Git branch? <p>Som...  \n",
       "6  How to make Git \"forget\" about a file that was...  \n",
       "7  What is the difference between \"px\", \"dip\", \"d...  \n",
       "8  How do I find all files containing specific te...  \n",
       "9  What is the difference between POST and PUT in...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why is processing a sorted array faster than processing an unsorted array? <p>Here is a piece of C++ code that shows some very peculiar behavior. For some strange reason, sorting the data miraculously makes the code almost six times faster:</p>\\n<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;algorithm&gt;\\n#include &lt;ctime&gt;\\n#include &lt;iostream&gt;\\n\\nint main()\\n{\\n    // Generate data\\n    const unsigned arraySize = 32768;\\n    int data[arraySize];\\n\\n    for (unsigned c = 0; c &lt; arraySize; ++c)\\n        data[c] = std::rand() % 256;\\n\\n    // !!! With this, the next loop runs faster.\\n    std::sort(data, data + arraySize);\\n\\n    // Test\\n    clock_t start = clock();\\n    long long sum = 0;\\n    for (unsigned i = 0; i &lt; 100000; ++i)\\n    {\\n        for (unsigned c = 0; c &lt; arraySize; ++c)\\n        {   // Primary loop\\n            if (data[c] &gt;= 128)\\n                sum += data[c];\\n        }\\n    }\\n\\n    double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC;\\n\\n    std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl;\\n    std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; std::endl;\\n}\\n</code></pre>\\n<ul>\\n<li>Without <code>std::sort(data, data + arraySize);</code>, the code runs in 11.54 seconds.</li>\\n<li>With the sorted data, the code runs in 1.93 seconds.</li>\\n</ul>\\n<hr />\\n<p>Initially, I thought this might be just a language or compiler anomaly, so I tried Java:</p>\\n<pre class=\"lang-java prettyprint-override\"><code>import java.util.Arrays;\\nimport java.util.Random;\\n\\npublic class Main\\n{\\n    public static void main(String[] args)\\n    {\\n        // Generate data\\n        int arraySize = 32768;\\n        int data[] = new int[arraySize];\\n\\n        Random rnd = new Random(0);\\n        for (int c = 0; c &lt; arraySize; ++c)\\n            data[c] = rnd.nextInt() % 256;\\n\\n        // !!! With this, the next loop runs faster\\n        Arrays.sort(data);\\n\\n        // Test\\n        long start = System.nanoTime();\\n        long sum = 0;\\n        for (int i = 0; i &lt; 100000; ++i)\\n        {\\n            for (int c = 0; c &lt; arraySize; ++c)\\n            {   // Primary loop\\n                if (data[c] &gt;= 128)\\n                    sum += data[c];\\n            }\\n        }\\n\\n        System.out.println((System.nanoTime() - start) / 1000000000.0);\\n        System.out.println(&quot;sum = &quot; + sum);\\n    }\\n}\\n</code></pre>\\n<p>With a similar but less extreme result.</p>\\n<hr />\\n<p>My first thought was that sorting brings the data into the <a href=\"https://en.wikipedia.org/wiki/CPU_cache\" rel=\"noreferrer\">cache</a>, but then I thought how silly that was because the array was just generated.</p>\\n<ul>\\n<li>What is going on?</li>\\n<li>Why is processing a sorted array faster than processing an unsorted array?</li>\\n</ul>\\n<p>The code is summing up some independent terms, so the order should not matter.</p>\\n<hr />\\n<p><strong>Related / followup Q&amp;As</strong> about the same effect with different / later compilers and options:</p>\\n<ul>\\n<li><a href=\"https://stackoverflow.com/q/66521344\">Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?</a></li>\\n<li><a href=\"https://stackoverflow.com/q/28875325\">gcc optimization flag -O3 makes code slower than -O2</a></li>\\n</ul>\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Premier éléments de la liste tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<java><c++><performance><cpu-architecture><branch-prediction>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences dans le corpus: 35888\n",
      "Occurences dans les tags: 35888\n",
      "CPU times: total: 547 ms\n",
      "Wall time: 627 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['Post'] = data.apply(lambda x: x['Title'] + ' ' + x['Body'] if x['Title'] == x['Title'] else x['Body'], axis=1)\n",
    "corpus = data['Post'].to_list()\n",
    "tags = data['Tags'].to_list()\n",
    "\n",
    "print(\"Dix première observations\")\n",
    "display(data.head(10))\n",
    "\n",
    "print(\"Premier élément de la liste corpus\\n\")\n",
    "display(corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier éléments de la liste tags\\n\")\n",
    "display(tags[0])\n",
    "\n",
    "print(f\"Occurences dans le corpus: {len(corpus)}\")\n",
    "print(f\"Occurences dans les tags: {len(tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-rebound",
   "metadata": {},
   "source": [
    "### Nettoyage HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cdbc4",
   "metadata": {},
   "source": [
    "Afin de traiter au mieux les données textuelles du `Body`, il est nécessaire de réaliser plusieurs tâches de data cleaning. Par exemple, le texte stocké dans cette variable est au format HTML. Ces balises vont polluer notre analyse. Nous allons donc **supprimer toutes les balises HTML** avec la librairie `BeautifulSoup` pour ne conserver que le texte brut.\n",
    "\n",
    "Mais avant cette opération,nous allons supprimer tout le contenu placé entre 2 balises html `<code></code>`, cela nous permettra de supprimer tout le code brut souvent copié dans les questions Stackoverflow et qui pourrait avoir un fort impact pour la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-consistency",
   "metadata": {},
   "source": [
    "Nous constatons que les contenus importés comportent un nombre importante de balise HTML. Nous créeons une fonction afin de les retirer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wired-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste corpus sans html\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why is processing a sorted array faster than processing an unsorted array? Here is a piece of C++ code that shows some very peculiar behavior. For some strange reason, sorting the data miraculously makes the code almost six times faster: #include <algorithm>\\n#include <ctime>\\n#include <iostream>\\n\\nint main()\\n{\\n    // Generate data\\n    const unsigned arraySize = 32768;\\n    int data[arraySize];\\n\\n    for (unsigned c = 0; c < arraySize; ++c)\\n        data[c] = std::rand() % 256;\\n\\n    // !!! With this, the next loop runs faster.\\n    std::sort(data, data + arraySize);\\n\\n    // Test\\n    clock_t start = clock();\\n    long long sum = 0;\\n    for (unsigned i = 0; i < 100000; ++i)\\n    {\\n        for (unsigned c = 0; c < arraySize; ++c)\\n        {   // Primary loop\\n            if (data[c] >= 128)\\n                sum += data[c];\\n        }\\n    }\\n\\n    double elapsedTime = static_cast<double>(clock() - start) / CLOCKS_PER_SEC;\\n\\n    std::cout << elapsedTime << std::endl;\\n    std::cout << \"sum = \" << sum << std::endl;\\n} Without std::sort(data, data + arraySize); , the code runs in 11.54 seconds. With the sorted data, the code runs in 1.93 seconds. Initially, I thought this might be just a language or compiler anomaly, so I tried Java: import java.util.Arrays;\\nimport java.util.Random;\\n\\npublic class Main\\n{\\n    public static void main(String[] args)\\n    {\\n        // Generate data\\n        int arraySize = 32768;\\n        int data[] = new int[arraySize];\\n\\n        Random rnd = new Random(0);\\n        for (int c = 0; c < arraySize; ++c)\\n            data[c] = rnd.nextInt() % 256;\\n\\n        // !!! With this, the next loop runs faster\\n        Arrays.sort(data);\\n\\n        // Test\\n        long start = System.nanoTime();\\n        long sum = 0;\\n        for (int i = 0; i < 100000; ++i)\\n        {\\n            for (int c = 0; c < arraySize; ++c)\\n            {   // Primary loop\\n                if (data[c] >= 128)\\n                    sum += data[c];\\n            }\\n        }\\n\\n        System.out.println((System.nanoTime() - start) / 1000000000.0);\\n        System.out.println(\"sum = \" + sum);\\n    }\\n} With a similar but less extreme result. My first thought was that sorting brings the data into the cache , but then I thought how silly that was because the array was just generated. What is going on? Why is processing a sorted array faster than processing an unsorted array? The code is summing up some independent terms, so the order should not matter. Related / followup Q&As about the same effect with different / later compilers and options: Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang? gcc optimization flag -O3 makes code slower than -O2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Occurences dans le corpus: 35888\n",
      "CPU times: total: 50.1 s\n",
      "Wall time: 50.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def clean_html(text):\n",
    "    \"\"\"\n",
    "    Remove HTML from a text.\n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text with html \n",
    "             \n",
    "    Returns:\n",
    "        cleaned String\n",
    "    \"\"\"\n",
    "    import lxml\n",
    "    import html5lib\n",
    "    from bs4 import BeautifulSoup\n",
    " \n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "\n",
    "    for sent in soup(['style', 'script']):\n",
    "            sent.decompose()\n",
    "   \n",
    "        \n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "corpus_wo_html = [clean_html(text) for text in corpus]\n",
    "\n",
    "print(\"Premier élément de la liste corpus sans html\\n\")\n",
    "display(corpus_wo_html[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Occurences dans le corpus: {len(corpus_wo_html)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-savannah",
   "metadata": {},
   "source": [
    "### Nettoyage du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-seating",
   "metadata": {},
   "source": [
    "Pour les besoin des traitemment futurs et entrainements des modèles, nous avons besoins de passer les textes en minuscule. Nous en profitons pour ne conserver que les caractères alphabétiques et ne garder que les termes de plus de trois lettres. Le filtrage sur la taille des termes permet de retirer ceux qui sont générique liés au code (if, for …). Il  reste toutefois perfectible puisqu’il élimine les occurrences de certains langages (C, C++, C#, R… ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compliant-wayne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste cleaned_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'processing sorted array faster than processing unsorted array here piece code that shows some very peculiar behavior some strange reason sorting data miraculously makes code almost times faster include algorithm include ctime include iostream main generate data const unsigned arraysize data arraysize unsigned arraysize data rand with this next loop runs faster sort data data arraysize test clock start clock long long unsigned unsigned arraysize primary loop data data double elapsedtime static cast double clock start clocks cout elapsedtime endl cout endl without sort data data arraysize code runs seconds with sorted data code runs seconds initially thought this might just language compiler anomaly tried java import java util arrays import java util random public class main public static void main string args generate data arraysize data arraysize random random arraysize data nextint with this next loop runs faster arrays sort data test long start system nanotime long arraysize primary loop data data system println system nanotime start system println with similar less extreme result first thought that sorting brings data into cache then thought silly that because array just generated what going processing sorted array faster than processing unsorted array code summing some independent terms order should matter related followup about same effect with different later compilers options processing unsorted array same speed processing sorted array with modern clang optimization flag makes code slower than'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Premier élément de la liste cleaned_tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'java performance architecture branch prediction'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Occurences dans le corpus nettoyé: 35888\n",
      "Occurences dans les tags nettoyés: 35888\n",
      "CPU times: total: 6.28 s\n",
      "Wall time: 6.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    Remove figures, punctuation, words shorter than two letters (excepted C or R) in a lowered text. \n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text to clean\n",
    "        \n",
    "    Returns:\n",
    "       res(string): Cleaned text\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    pattern = re.compile(r'[^\\w]|[\\d_]')\n",
    "    \n",
    "    try: \n",
    "        res = re.sub(pattern,\" \", text).lower()\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = res.split(\" \")\n",
    "    res = list(filter(lambda x: len(x)>3 , res))\n",
    "    res = \" \".join(res)\n",
    "    return res\n",
    "\n",
    "cleaned_corpus = [text_cleaning(text) for text in corpus_wo_html]\n",
    "cleaned_tags = [text_cleaning(text).strip() for text in tags]\n",
    "\n",
    "\n",
    "print(\"Premier élément de la liste cleaned_corpus\\n\")\n",
    "display(cleaned_corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste cleaned_tags\\n\")\n",
    "display(cleaned_tags[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Occurences dans le corpus nettoyé: {len(cleaned_corpus)}\")\n",
    "print(f\"Occurences dans les tags nettoyés: {len(cleaned_tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-naples",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-aircraft",
   "metadata": {},
   "source": [
    "La tokenisation permet de transformer les textes passés en entrée en liste de termes distincts (token).  Pendant le traitement les termes génériques (stop words) ne sont pas conservés dans la liste des tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moral-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste tokenized_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['processing',\n",
       " 'sorted',\n",
       " 'array',\n",
       " 'faster',\n",
       " 'processing',\n",
       " 'unsorted',\n",
       " 'array',\n",
       " 'piece',\n",
       " 'code',\n",
       " 'shows',\n",
       " 'peculiar',\n",
       " 'behavior',\n",
       " 'strange',\n",
       " 'reason',\n",
       " 'sorting',\n",
       " 'data',\n",
       " 'miraculously',\n",
       " 'makes',\n",
       " 'code',\n",
       " 'almost',\n",
       " 'times',\n",
       " 'faster',\n",
       " 'include',\n",
       " 'algorithm',\n",
       " 'include',\n",
       " 'ctime',\n",
       " 'include',\n",
       " 'iostream',\n",
       " 'main',\n",
       " 'generate',\n",
       " 'data',\n",
       " 'const',\n",
       " 'unsigned',\n",
       " 'arraysize',\n",
       " 'data',\n",
       " 'arraysize',\n",
       " 'unsigned',\n",
       " 'arraysize',\n",
       " 'data',\n",
       " 'rand',\n",
       " 'next',\n",
       " 'loop',\n",
       " 'runs',\n",
       " 'faster',\n",
       " 'sort',\n",
       " 'data',\n",
       " 'data',\n",
       " 'arraysize',\n",
       " 'test',\n",
       " 'clock',\n",
       " 'start',\n",
       " 'clock',\n",
       " 'long',\n",
       " 'long',\n",
       " 'unsigned',\n",
       " 'unsigned',\n",
       " 'arraysize',\n",
       " 'primary',\n",
       " 'loop',\n",
       " 'data',\n",
       " 'data',\n",
       " 'double',\n",
       " 'elapsedtime',\n",
       " 'static',\n",
       " 'cast',\n",
       " 'double',\n",
       " 'clock',\n",
       " 'start',\n",
       " 'clocks',\n",
       " 'cout',\n",
       " 'elapsedtime',\n",
       " 'endl',\n",
       " 'cout',\n",
       " 'endl',\n",
       " 'without',\n",
       " 'sort',\n",
       " 'data',\n",
       " 'data',\n",
       " 'arraysize',\n",
       " 'code',\n",
       " 'runs',\n",
       " 'seconds',\n",
       " 'sorted',\n",
       " 'data',\n",
       " 'code',\n",
       " 'runs',\n",
       " 'seconds',\n",
       " 'initially',\n",
       " 'thought',\n",
       " 'might',\n",
       " 'language',\n",
       " 'compiler',\n",
       " 'anomaly',\n",
       " 'tried',\n",
       " 'java',\n",
       " 'import',\n",
       " 'java',\n",
       " 'util',\n",
       " 'arrays',\n",
       " 'import',\n",
       " 'java',\n",
       " 'util',\n",
       " 'random',\n",
       " 'public',\n",
       " 'class',\n",
       " 'main',\n",
       " 'public',\n",
       " 'static',\n",
       " 'void',\n",
       " 'main',\n",
       " 'string',\n",
       " 'args',\n",
       " 'generate',\n",
       " 'data',\n",
       " 'arraysize',\n",
       " 'data',\n",
       " 'arraysize',\n",
       " 'random',\n",
       " 'random',\n",
       " 'arraysize',\n",
       " 'data',\n",
       " 'nextint',\n",
       " 'next',\n",
       " 'loop',\n",
       " 'runs',\n",
       " 'faster',\n",
       " 'arrays',\n",
       " 'sort',\n",
       " 'data',\n",
       " 'test',\n",
       " 'long',\n",
       " 'start',\n",
       " 'system',\n",
       " 'nanotime',\n",
       " 'long',\n",
       " 'arraysize',\n",
       " 'primary',\n",
       " 'loop',\n",
       " 'data',\n",
       " 'data',\n",
       " 'system',\n",
       " 'println',\n",
       " 'system',\n",
       " 'nanotime',\n",
       " 'start',\n",
       " 'system',\n",
       " 'println',\n",
       " 'similar',\n",
       " 'less',\n",
       " 'extreme',\n",
       " 'result',\n",
       " 'first',\n",
       " 'thought',\n",
       " 'sorting',\n",
       " 'brings',\n",
       " 'data',\n",
       " 'cache',\n",
       " 'thought',\n",
       " 'silly',\n",
       " 'array',\n",
       " 'generated',\n",
       " 'going',\n",
       " 'processing',\n",
       " 'sorted',\n",
       " 'array',\n",
       " 'faster',\n",
       " 'processing',\n",
       " 'unsorted',\n",
       " 'array',\n",
       " 'code',\n",
       " 'summing',\n",
       " 'independent',\n",
       " 'terms',\n",
       " 'order',\n",
       " 'matter',\n",
       " 'related',\n",
       " 'followup',\n",
       " 'effect',\n",
       " 'different',\n",
       " 'later',\n",
       " 'compilers',\n",
       " 'options',\n",
       " 'processing',\n",
       " 'unsorted',\n",
       " 'array',\n",
       " 'speed',\n",
       " 'processing',\n",
       " 'sorted',\n",
       " 'array',\n",
       " 'modern',\n",
       " 'clang',\n",
       " 'optimization',\n",
       " 'flag',\n",
       " 'makes',\n",
       " 'code',\n",
       " 'slower']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Longueur du premier éléments de liste tokenized_corpus: 196\n",
      "\n",
      "\n",
      "Premier élément de la liste tokenized_tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['java', 'performance', 'architecture', 'branch', 'prediction']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Occurences dans le corpus tokenizé: 35888\n",
      "Occurences dans la liste des tags: 35888\n",
      "CPU times: total: 33.1 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize words of a text.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        text(String): Row text\n",
    "        \n",
    "    Returns\n",
    "    \n",
    "        res(list): Tokenized string.\n",
    "    \"\"\"\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk import word_tokenize\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    try:\n",
    "        res = word_tokenize(text, language='english')\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = [token for token in res if token not in stop_words]\n",
    "    return res\n",
    "\n",
    "tokenized_corpus = [tokenize(text) for text in cleaned_corpus]\n",
    "tokenized_tags = [tokenize(text) for text in cleaned_tags]\n",
    "\n",
    "print(\"Premier élément de la liste tokenized_corpus\\n\")\n",
    "display(tokenized_corpus[0])\n",
    "print(\"\\n\")\n",
    "print(f\"Longueur du premier éléments de liste tokenized_corpus: {len(tokenized_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste tokenized_tags\\n\")\n",
    "display(tokenized_tags[0])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(f\"Occurences dans le corpus tokenizé: {len(tokenized_corpus)}\")\n",
    "print(f\"Occurences dans la liste des tags: {len(tokenized_tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-electricity",
   "metadata": {},
   "source": [
    "NLTK propose des listes de stop words génériques. Nous attirons  l’attention sur le fait que le corpus utilisé pour les travaux est de nature spécifique. En effet les posts contiennent souvent du code, des messages d’erreur de compilateurs / interpréteurs ou des logs alors qu’aucune liste de stop words mis à disposition ne porte sur le thématique. Le risque est de laisser passer des termes génériques vis-à-vis du contexte étudié. Sans allouer un important temps de travail il s’avère difficile de construire une liste de stop words spécifique exhaustive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-basement",
   "metadata": {},
   "source": [
    "### Filtrage des noms à l'aide d'un modèle de POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-meter",
   "metadata": {},
   "source": [
    "Lors de pré-traitement des posts nous cherchons avant tout à identifier à termes liés à des technologies utilisées. Ces dernières sont généralement des noms. Afin de mettre en œuvre le filtrage nous utilisons un modèle de POS. Ce dernier se base sur des chaînes de Markov . Leur principe est d’identifier la probabilité  la plus forte de la fonction grammaticale d’un terme par rapport :\n",
    "- la fonction grammaticale du terme précédent \n",
    "- A la probabilité la plus forte de l’association entre le terme et une fonction grammaticale particulière\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste noun_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['processing',\n",
       " 'processing',\n",
       " 'array',\n",
       " 'piece',\n",
       " 'code',\n",
       " 'reason',\n",
       " 'code',\n",
       " 'generate',\n",
       " 'const',\n",
       " 'arraysize',\n",
       " 'arraysize',\n",
       " 'arraysize',\n",
       " 'loop',\n",
       " 'sort',\n",
       " 'test',\n",
       " 'clock',\n",
       " 'start',\n",
       " 'clock',\n",
       " 'arraysize',\n",
       " 'loop',\n",
       " 'cast',\n",
       " 'clock',\n",
       " 'start',\n",
       " 'cout',\n",
       " 'elapsedtime',\n",
       " 'endl',\n",
       " 'cout',\n",
       " 'endl',\n",
       " 'sort',\n",
       " 'arraysize',\n",
       " 'code',\n",
       " 'code',\n",
       " 'language',\n",
       " 'java',\n",
       " 'import',\n",
       " 'java',\n",
       " 'java',\n",
       " 'class',\n",
       " 'void',\n",
       " 'string',\n",
       " 'generate',\n",
       " 'arraysize',\n",
       " 'nextint',\n",
       " 'loop',\n",
       " 'test',\n",
       " 'system',\n",
       " 'loop',\n",
       " 'system',\n",
       " 'println',\n",
       " 'system',\n",
       " 'start',\n",
       " 'system',\n",
       " 'result',\n",
       " 'processing',\n",
       " 'processing',\n",
       " 'array',\n",
       " 'code',\n",
       " 'order',\n",
       " 'matter',\n",
       " 'effect',\n",
       " 'array',\n",
       " 'speed',\n",
       " 'processing',\n",
       " 'clang',\n",
       " 'optimization',\n",
       " 'flag',\n",
       " 'code']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Longueur du premier éléments de liste noun_corpus: 67\n",
      "\n",
      "\n",
      "Occurences dans le corpus tokenizé: 35888\n",
      "CPU times: total: 3min 3s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def filtering_nouns(tokens):\n",
    "    \"\"\"\n",
    "    Filter singular nouns\n",
    "    \n",
    "    Args:\n",
    "        tokens(list): A list o tokens\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        res(list): Filtered token list\n",
    "    \"\"\" \n",
    "    \n",
    "    import nltk\n",
    "    \n",
    "    res = nltk.pos_tag(tokens)\n",
    "    \n",
    "    res = [token[0] for token in res if token[1] == 'NN']\n",
    "    \n",
    "    return res\n",
    "\n",
    "noun_corpus = [filtering_nouns(tokens) for tokens in tokenized_corpus]\n",
    "\n",
    "print(\"Premier élément de la liste noun_corpus\\n\")\n",
    "display(noun_corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Longueur du premier éléments de liste noun_corpus: {len(noun_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"Occurences dans le corpus tokenizé: {len(noun_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-bangladesh",
   "metadata": {},
   "source": [
    "Nous attirons une nouvelle fois l’attention sur le fait que le corpus utilisé pour les travaux est de nature spécifique. Aucun corpus mis à disposition par NLTK ne couvre le domaine étudié. Le risque est que certaines technologies, dont la dénomination ne découle pas d’un nom commun, ne soient pas retenues par  le filtre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-bargain",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-causing",
   "metadata": {},
   "source": [
    "Afin d’éviter d’utiliser de multiples déclinaisons d’un même terme (conjugaisons, féminin, pluriel …). Les deux méthodes les couramment utilisées sont le stemming et la lemmatisation. Elles consistent toutes deux à dédupliquer les déclinaisons de termes en ne conservant que leur racine. Le stemming procède par troncature simple. De manière générale cette méthode peut poser un problème car plusieurs mots termes sémantiquement différents peuvent avoir la même racine (stem). La lemmatisation  consiste à identifier la racine sémantique (lemme) d’un terme référencé dans un corpus ou un dictionnaire d’une langue. Cette méthode évite, a priori, l’écueil de diminuer le nombre de termes ayant un stem identique mais des lemmes différents. Nous retenons donc la lemmatisation.  Par contre une fois encore nous sommes confrontés à la généricité des outils mis à disposition par NLTK. A titre d’exemple, “keras” (Framework de deep learning) devient “kera” une fois lemmatisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loved-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste lemmatized_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['processing',\n",
       " 'processing',\n",
       " 'array',\n",
       " 'piece',\n",
       " 'code',\n",
       " 'reason',\n",
       " 'code',\n",
       " 'generate',\n",
       " 'const',\n",
       " 'arraysize',\n",
       " 'arraysize',\n",
       " 'arraysize',\n",
       " 'loop',\n",
       " 'sort',\n",
       " 'test',\n",
       " 'clock',\n",
       " 'start',\n",
       " 'clock',\n",
       " 'arraysize',\n",
       " 'loop',\n",
       " 'cast',\n",
       " 'clock',\n",
       " 'start',\n",
       " 'cout',\n",
       " 'elapsedtime',\n",
       " 'endl',\n",
       " 'cout',\n",
       " 'endl',\n",
       " 'sort',\n",
       " 'arraysize',\n",
       " 'code',\n",
       " 'code',\n",
       " 'language',\n",
       " 'java',\n",
       " 'import',\n",
       " 'java',\n",
       " 'java',\n",
       " 'class',\n",
       " 'void',\n",
       " 'string',\n",
       " 'generate',\n",
       " 'arraysize',\n",
       " 'nextint',\n",
       " 'loop',\n",
       " 'test',\n",
       " 'system',\n",
       " 'loop',\n",
       " 'system',\n",
       " 'println',\n",
       " 'system',\n",
       " 'start',\n",
       " 'system',\n",
       " 'result',\n",
       " 'processing',\n",
       " 'processing',\n",
       " 'array',\n",
       " 'code',\n",
       " 'order',\n",
       " 'matter',\n",
       " 'effect',\n",
       " 'array',\n",
       " 'speed',\n",
       " 'processing',\n",
       " 'clang',\n",
       " 'optimization',\n",
       " 'flag',\n",
       " 'code']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Longueur du premier éléments de liste lemmatized_corpus: 67\n",
      "\n",
      "\n",
      "Premier élément de la liste lemmatized_tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['java', 'performance', 'architecture', 'branch', 'prediction']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences dans le corpus lemmatisé: 35888\n",
      "Occurences dans les tags lemmatisés: 35888\n",
      "CPU times: total: 6.92 s\n",
      "Wall time: 6.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def lemmatization(tokens):\n",
    "    \"\"\"\n",
    "    Transform tokens into lems \n",
    "    \n",
    "    Args:\n",
    "        tokens(list): List of tokens\n",
    "        \n",
    "    Returns:\n",
    "        lemmatized(list): List of lemmatized tokens\n",
    "    \"\"\"\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(token))\n",
    "        \n",
    "    return lemmatized\n",
    "\n",
    "lemmatized_corpus = [lemmatization(tokens) for tokens in noun_corpus]\n",
    "lemmatized_tags = [lemmatization(tokens) for tokens in tokenized_tags]\n",
    "\n",
    "tags_wo_blanks = []\n",
    "for tokens in lemmatized_tags:\n",
    "    tokens = [token for token in tokens if len(token)>1]\n",
    "    tags_wo_blanks.append(tokens)\n",
    "\n",
    "print(\"Premier élément de la liste lemmatized_corpus\\n\")\n",
    "display(lemmatized_corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Longueur du premier éléments de liste lemmatized_corpus: {len(lemmatized_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste lemmatized_tags\\n\")\n",
    "display(tags_wo_blanks[0])\n",
    "\n",
    "\n",
    "print(f\"Occurences dans le corpus lemmatisé: {len(lemmatized_corpus)}\")\n",
    "print(f\"Occurences dans les tags lemmatisés: {len(tags_wo_blanks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-paraguay",
   "metadata": {},
   "source": [
    "### Filtrage des valeurs vides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-butter",
   "metadata": {},
   "source": [
    "Les premiers traitements on généré des docuements vides. Nous décidons de filtrer le corpus pour les éliminer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "victorian-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations restante du corpus original: 35888\n",
      "observations restantes du corpus traité: 34473\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>splitted_text</th>\n",
       "      <th>splitted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is processing a sorted array faster than p...</td>\n",
       "      <td>[processing, processing, array, piece, code, r...</td>\n",
       "      <td>[java, performance, architecture, branch, pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I undo the most recent local commits in...</td>\n",
       "      <td>[commit, server, repository]</td>\n",
       "      <td>[version, control, commit, undo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I delete a Git branch locally and remot...</td>\n",
       "      <td>[branch, branch, branch, branch, bugfix, error...</td>\n",
       "      <td>[version, control, branch, push, remote]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I force \"git pull\" to overwrite local f...</td>\n",
       "      <td>[force, pull, scenario, team, member, source, ...</td>\n",
       "      <td>[version, control, overwrite, pull, fetch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I revert a Git repository to a previous...</td>\n",
       "      <td>[repository, commit, revert, state, snapshot, ...</td>\n",
       "      <td>[checkout, reset, revert]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do I check out a remote Git branch? &lt;p&gt;Som...</td>\n",
       "      <td>[check, branch, somebody, branch, test, push, ...</td>\n",
       "      <td>[checkout, remote, branch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How to make Git \"forget\" about a file that was...</td>\n",
       "      <td>[forget, file, file, gitignore, list, status, ...</td>\n",
       "      <td>[gitignore]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the difference between \"px\", \"dip\", \"d...</td>\n",
       "      <td>[difference, difference, measure]</td>\n",
       "      <td>[android, android, layout, user, interface, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do I find all files containing specific te...</td>\n",
       "      <td>[text, linux, linux, system, clarify, text, fi...</td>\n",
       "      <td>[linux, text, grep, directory, find]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the difference between POST and PUT in...</td>\n",
       "      <td>[difference, post, http, post, create, resourc...</td>\n",
       "      <td>[http, rest, post]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Post  \\\n",
       "0  Why is processing a sorted array faster than p...   \n",
       "1  How do I undo the most recent local commits in...   \n",
       "2  How do I delete a Git branch locally and remot...   \n",
       "3  How do I force \"git pull\" to overwrite local f...   \n",
       "4  How do I revert a Git repository to a previous...   \n",
       "5  How do I check out a remote Git branch? <p>Som...   \n",
       "6  How to make Git \"forget\" about a file that was...   \n",
       "7  What is the difference between \"px\", \"dip\", \"d...   \n",
       "8  How do I find all files containing specific te...   \n",
       "9  What is the difference between POST and PUT in...   \n",
       "\n",
       "                                       splitted_text  \\\n",
       "0  [processing, processing, array, piece, code, r...   \n",
       "1                       [commit, server, repository]   \n",
       "2  [branch, branch, branch, branch, bugfix, error...   \n",
       "3  [force, pull, scenario, team, member, source, ...   \n",
       "4  [repository, commit, revert, state, snapshot, ...   \n",
       "5  [check, branch, somebody, branch, test, push, ...   \n",
       "6  [forget, file, file, gitignore, list, status, ...   \n",
       "7                  [difference, difference, measure]   \n",
       "8  [text, linux, linux, system, clarify, text, fi...   \n",
       "9  [difference, post, http, post, create, resourc...   \n",
       "\n",
       "                                       splitted_tags  \n",
       "0  [java, performance, architecture, branch, pred...  \n",
       "1                   [version, control, commit, undo]  \n",
       "2           [version, control, branch, push, remote]  \n",
       "3         [version, control, overwrite, pull, fetch]  \n",
       "4                          [checkout, reset, revert]  \n",
       "5                         [checkout, remote, branch]  \n",
       "6                                        [gitignore]  \n",
       "7  [android, android, layout, user, interface, di...  \n",
       "8               [linux, text, grep, directory, find]  \n",
       "9                                 [http, rest, post]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Observations restante du corpus original: {data.shape[0]}\")\n",
    "\n",
    "joined_corpus = [\" \".join(text) for text in lemmatized_corpus]\n",
    "corpus_df = pd.DataFrame(joined_corpus, columns=['preprocessed_text'])\n",
    "corpus_df['len_text'] = corpus_df['preprocessed_text'].apply(lambda x: len(x))\n",
    "\n",
    "joined_tags = [\" \".join(tags) for tags in tags_wo_blanks]\n",
    "tag_df = pd.DataFrame(joined_tags, columns=['preprocessed_tags'])\n",
    "tag_df['len_tags'] = tag_df['preprocessed_tags'].apply(lambda x: len(x))\n",
    "\n",
    "corpus_tag_df = pd.concat([corpus_df, tag_df], axis=1)\n",
    "\n",
    "empty_data_idx = corpus_tag_df[(corpus_tag_df['len_text']==0) | (corpus_tag_df['len_tags']==0)].index\n",
    "\n",
    "corpus_tag_df.drop(index=empty_data_idx, inplace=True)\n",
    "data.drop(index=empty_data_idx, inplace=True)\n",
    "\n",
    "print(f\"observations restantes du corpus traité: {corpus_tag_df.shape[0]}\")\n",
    "\n",
    "corpus_tag_df['splitted_text'] = corpus_tag_df['preprocessed_text'].apply(lambda x: x.split(' ') )\n",
    "corpus_tag_df['splitted_tags'] = corpus_tag_df['preprocessed_tags'].apply(lambda x: x.split(' ') )\n",
    "\n",
    "filtered_corpus = corpus_tag_df['splitted_text'].to_list()\n",
    "filtered_tags = corpus_tag_df['splitted_tags'].to_list()\n",
    "filtered_original_posts = data['Post'].to_list()\n",
    "\n",
    "filtered_tokenized_vs_original = pd.concat([data['Post'],\n",
    "                                            corpus_tag_df['splitted_text'], \n",
    "                                            corpus_tag_df['splitted_tags']],\n",
    "                                            axis=1)\n",
    "\n",
    "filtered_tokenized_vs_original.to_csv(\"./data/cleaned_corpus.csv\", index=False)\n",
    "filtered_tokenized_vs_original.to_pickle('./data/cleaned_corpus.pkl')\n",
    "\n",
    "filtered_tokenized_vs_original.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-senator",
   "metadata": {},
   "source": [
    "### Fréquence de distribution tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-fashion",
   "metadata": {},
   "source": [
    "Nous observons à présent la fréquence de distribution des tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "systematic-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens du corpus 86066\n",
      "Affichage des 20 tokens les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>33174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>23288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>22088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>19479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>19187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>18638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>14979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>13735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>13319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>12989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>12093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>11657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>10967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>10525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import</th>\n",
       "      <td>10495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application</th>\n",
       "      <td>9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>9117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>8417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Frequency\n",
       "Word                  \n",
       "java             33174\n",
       "error            23288\n",
       "class            22088\n",
       "name             19479\n",
       "file             19187\n",
       "code             18638\n",
       "function         14979\n",
       "value            13735\n",
       "http             13319\n",
       "android          12989\n",
       "version          12093\n",
       "system           11657\n",
       "return           10967\n",
       "type             10525\n",
       "import           10495\n",
       "application       9394\n",
       "line              9372\n",
       "test              9231\n",
       "time              9117\n",
       "view              8417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 938 ms\n",
      "Wall time: 980 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def build_word_distribution(corpus):\n",
    "    \"\"\"\n",
    "    Build corpus word distribution\n",
    "    \n",
    "    Args:\n",
    "        Corpus(List of lists): Original corpus\n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "        word_dist_df(DataFrame): Word distribution of the corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    from nltk import FreqDist\n",
    "    word_corpus = [token for token_list in corpus for token in token_list]\n",
    "    word_dist = FreqDist(word_corpus)\n",
    "    word_dist_df = pd.DataFrame(word_dist.items(), columns=['Word', 'Frequency']).set_index('Word')\n",
    "    word_dist_df.sort_values(\"Frequency\", ascending=False, inplace=True)\n",
    "\n",
    "    return word_dist_df\n",
    "\n",
    "word_dist = build_word_distribution(filtered_corpus)\n",
    "\n",
    "print(f\"Nombre de tokens du corpus {word_dist.shape[0]}\")\n",
    "print(\"Affichage des 20 tokens les plus utilisés\")\n",
    "display(word_dist.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-chocolate",
   "metadata": {},
   "source": [
    "Nous constatons un nombre important de termes génériques tels que : error, class, value, return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-public",
   "metadata": {},
   "source": [
    "### Fréquence de distribution des tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-courtesy",
   "metadata": {},
   "source": [
    "Nous réalisons le même traitement sur les tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latin-situation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 des tags les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>4207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>3988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html</th>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jquery</th>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studio</th>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular</th>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>server</th>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysql</th>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swift</th>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xcode</th>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>array</th>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Frequency\n",
       "Word                 \n",
       "android          5652\n",
       "java             4450\n",
       "javascript       4207\n",
       "python           3988\n",
       "html             2027\n",
       "jquery           1708\n",
       "studio           1433\n",
       "angular          1117\n",
       "visual           1088\n",
       "spring           1057\n",
       "google            981\n",
       "server            908\n",
       "mysql             835\n",
       "window            783\n",
       "swift             781\n",
       "node              766\n",
       "xcode             719\n",
       "array             707\n",
       "string            701\n",
       "json              691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags: 5799\n"
     ]
    }
   ],
   "source": [
    "tag_dist = build_word_distribution(filtered_tags)\n",
    "print(\"Top 20 des tags les plus utilisés\")\n",
    "display(tag_dist.head(20))\n",
    "print(f\"Nombre de tags: {len(tag_dist)}\")\n",
    "first_200_tags = tag_dist[0:200].index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-breath",
   "metadata": {},
   "source": [
    "### filtrage top 200 tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-calvin",
   "metadata": {},
   "source": [
    "Pour les besoin des entrainements des modèles supervisés, nous avons besoin limiter le nombre de tags. Nous décidons de ne retenir que les 200 premiers.Du nous avons du à nouveau filtrer les documents qui ne sont pas liés aux 200 premiers tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations restantes dans le corpus original: 34473\n",
      "Observations restantes dans le coprus traité: 30933\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observations restantes dans le corpus original: {data.shape[0]}\")\n",
    "filtered_corpus_tag_df = corpus_tag_df.copy()\n",
    "filtered_corpus_tag_df['tags_in_top200'] = filtered_corpus_tag_df['splitted_tags'].apply(lambda tags: [tag for tag in tags if tag in first_200_tags])\n",
    "\n",
    "filtered_corpus_tag_df['len_tags_in_top200'] = filtered_corpus_tag_df['tags_in_top200'].apply(lambda x: len(x))\n",
    "missing_filtered_data = filtered_corpus_tag_df[filtered_corpus_tag_df['len_tags_in_top200'] == 0].index\n",
    "\n",
    "filtered_corpus_tag_df.drop(index=missing_filtered_data, inplace=True)\n",
    "data.drop(index=missing_filtered_data, inplace=True)\n",
    "print(f\"Observations restantes dans le coprus traité: {filtered_corpus_tag_df.shape[0]}\")\n",
    "\n",
    "top200_corpus = filtered_corpus_tag_df['splitted_text'].to_list()\n",
    "top200_joined_corpus = filtered_corpus_tag_df['preprocessed_text'].to_list()\n",
    "top200_tags = filtered_corpus_tag_df['tags_in_top200'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-stylus",
   "metadata": {},
   "source": [
    "### Fréquences de distribution des tokens après filtrage du top 200 tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-marijuana",
   "metadata": {},
   "source": [
    "Nous souhaitons à nouveau appréhender la distribution des tokens sur le corpus filtré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "front-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens du corpus 80459\n",
      "Affichage des 20 tokens les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>32981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>21303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>20501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>18046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>17454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>16824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>13942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>12980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>12363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>12319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>11323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import</th>\n",
       "      <td>10337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>10233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>10067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>9537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application</th>\n",
       "      <td>8687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>8458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>7978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Frequency\n",
       "Word                  \n",
       "java             32981\n",
       "error            21303\n",
       "class            20501\n",
       "name             18046\n",
       "file             17454\n",
       "code             16824\n",
       "function         13942\n",
       "android          12980\n",
       "http             12363\n",
       "value            12319\n",
       "version          11323\n",
       "import           10337\n",
       "system           10233\n",
       "return           10067\n",
       "type              9537\n",
       "application       8687\n",
       "line              8599\n",
       "test              8458\n",
       "time              8300\n",
       "view              7978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre des tokens ayant plus de 1000 occurences sur le corpus filtré\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dist_top200 = build_word_distribution(top200_corpus)\n",
    "print(f\"Nombre de tokens du corpus {word_dist_top200.shape[0]}\")\n",
    "print(\"Affichage des 20 tokens les plus utilisés\")\n",
    "display(word_dist_top200.head(20))\n",
    "print(\"Nombre des tokens ayant plus de 1000 occurences sur le corpus filtré\")\n",
    "word_dist_top200[word_dist_top200[\"Frequency\"]>=1000].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-prisoner",
   "metadata": {},
   "source": [
    "Nous constaton que le filtrage par top 200 tags a changé le classement des tokens les plus représenté. De plus un filtrage par fréquence des token a drastiquement le nombre de tokens retenus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-consultation",
   "metadata": {},
   "source": [
    "### Fréquences de distribution des tags après filtrage du top 200 tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-trust",
   "metadata": {},
   "source": [
    "Nous réalisons le même traitement sur les tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confirmed-continuity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 des tags les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>4207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>3988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html</th>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jquery</th>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studio</th>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular</th>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>server</th>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysql</th>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swift</th>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xcode</th>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>array</th>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Frequency\n",
       "Word                 \n",
       "android          5652\n",
       "java             4450\n",
       "javascript       4207\n",
       "python           3988\n",
       "html             2027\n",
       "jquery           1708\n",
       "studio           1433\n",
       "angular          1117\n",
       "visual           1088\n",
       "spring           1057\n",
       "google            981\n",
       "server            908\n",
       "mysql             835\n",
       "window            783\n",
       "swift             781\n",
       "node              766\n",
       "xcode             719\n",
       "array             707\n",
       "string            701\n",
       "json              691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags: 200\n"
     ]
    }
   ],
   "source": [
    "tag_dist_top_200 = build_word_distribution(top200_tags)\n",
    "print(\"Top 20 des tags les plus utilisés\")\n",
    "display(tag_dist_top_200.head(20))\n",
    "print(f\"Nombre de tags: {len(tag_dist_top_200)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-complaint",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-excerpt",
   "metadata": {},
   "source": [
    "Afin de pouvoir entraîner les modèles nous avons besoin de transformer les listes de tokens lemmatisés en vecteurs. Deux méthodes sont couramment utilisées :\n",
    "- Bag of words : Chaque liste de token (appelée document) est transformée en un vecteur indiquant la fréquence brute de chaque terme du corpus dans la liste. \n",
    "- TF-IDF : Dans cette méthode, la fréquence brute d’un token  est remplacée par un indicateur composé de sa fréquence d’apparition du token dans le document et la fréquence inverse du nombre de documents où le token apparaît. Tel que TF-IDF=TF ×log⁡〖|D|/|{d_j ∶ t_i∈d_j }| 〗 avec |D| : le nombre total de documents dans le corpus et |{d_j ∶ t_i∈d_j }| : le nombre de documents ou le token apparaît. Cette méthode permet de minorer les tokens présents dans un nombre élevé de documents et de normaliser la taille des documents. \n",
    "Les documents contenant des termes très génériques et de longueurs très variables, nous avons décidé d’utiliser une vectorisation par TF-IDF pour la suite des travaux. Afin de de ne garder que les tokens les plus représentatifs, nous avons entrainé les modèles de vectorisation sur des dictionnaire de correspondance (vocabulary) ne comportant que des termes dont la fréquence est supérieure à 1000 occurrences dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "municipal-limit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>java</th>\n",
       "      <th>error</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "      <th>file</th>\n",
       "      <th>code</th>\n",
       "      <th>function</th>\n",
       "      <th>android</th>\n",
       "      <th>http</th>\n",
       "      <th>value</th>\n",
       "      <th>...</th>\n",
       "      <th>frame</th>\n",
       "      <th>parameter</th>\n",
       "      <th>zygoteinit</th>\n",
       "      <th>annotation</th>\n",
       "      <th>storage</th>\n",
       "      <th>development</th>\n",
       "      <th>byte</th>\n",
       "      <th>dialog</th>\n",
       "      <th>gradle</th>\n",
       "      <th>fragment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150818</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       java     error     class      name      file      code  function  \\\n",
       "0  0.262283  0.000000  0.072405  0.000000  0.000000  0.358282       0.0   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "2  0.000000  0.383837  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "3  0.000000  0.155654  0.000000  0.000000  0.174871  0.000000       0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "5  0.000000  0.000000  0.000000  0.150818  0.429448  0.000000       0.0   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "\n",
       "   android      http  value  ...  frame  parameter  zygoteinit  annotation  \\\n",
       "0      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "1      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "2      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "3      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "4      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "5      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "6      0.0  0.109536    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "7      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "8      0.0  0.435691    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "9      0.0  0.000000    0.0  ...    0.0        0.0         0.0         0.0   \n",
       "\n",
       "   storage  development  byte  dialog  gradle  fragment  \n",
       "0      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "1      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "2      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "3      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "4      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "5      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "6      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "7      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "8      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "9      0.0          0.0   0.0     0.0     0.0       0.0  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nombre d'observations: 30933, nombre de variables: 300\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = list(word_dist_top200[word_dist_top200[\"Frequency\"]>=1000].index)\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "X = tfidf_vectorizer.fit_transform(top200_joined_corpus)\n",
    "tfidf_data = pd.DataFrame(X.toarray(), columns=vocabulary)\n",
    "print(\"Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\")\n",
    "display(tfidf_data.head(10))\n",
    "print(f\" Nombre d'observations: {tfidf_data.shape[0]}, nombre de variables: {tfidf_data.shape[1]}\")\n",
    "\n",
    "filename_tfidf_model = './models/tfidf_model.pkl'\n",
    "pickle.dump(tfidf_vectorizer, open(filename_tfidf_model, 'wb'))\n",
    "\n",
    "filename_vocabulary = \"./models/vocabulary.pkl\"\n",
    "pickle.dump(vocabulary, open(filename_vocabulary, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-appraisal",
   "metadata": {},
   "source": [
    "## Entrainement des modèles en approche supervisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-interest",
   "metadata": {},
   "source": [
    "### Dédoublonnage des labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-account",
   "metadata": {},
   "source": [
    "Le dédoublonnage des tags – label s’avère nécessaire après le pré-traitement des documents. En effet, il n’est pas rare que les utilisateurs spécifient plusieurs versions d’une même technologie dans leurs tags. Après traitement préalable, notamment avec la suppression des caractères numérique, les tags-label peuvent contenir des doublons pour un même document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complimentary-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage de la première occurence de dedup_tags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'java', 'performance'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dedup_tags = []\n",
    "for tags in top200_tags:\n",
    "    dedup_tags.append(set(tags))\n",
    "\n",
    "print('Affichage de la première occurence de dedup_tags')\n",
    "display(dedup_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-microwave",
   "metadata": {},
   "source": [
    "### Partition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-uncle",
   "metadata": {},
   "source": [
    "Nous conservons 80% des données pour le jeu d’entraînement et 20% pour le jeu de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "running-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, dedup_tags, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-paintball",
   "metadata": {},
   "source": [
    "### Réduction des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-weight",
   "metadata": {},
   "source": [
    "La vectorisation a transformé les documents en un vecteur de  456 composantes. Afin de casser les corrélations entre celles-ci et optimiser le temps d’entrainement des modèles en réduisant les dimensions nous réalisons une ACP (Analyse en Composantes Principales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceramic-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)\n",
    "\n",
    "def display_scree_plot(pca):\n",
    "    scree = pca.explained_variance_ratio_*100\n",
    "    plt.bar(np.arange(len(scree))+1, scree)\n",
    "    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n",
    "    plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "    plt.ylabel(\"pourcentage d'inertie\")\n",
    "    plt.title(\"Eboulis des valeurs propres\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "display_scree_plot(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-british",
   "metadata": {},
   "source": [
    "A défaut d’un coude significatif dans la visualisation l’éboulis des composantes principales, nous utilisons un hyper paramètre consistant à retenir un nombre de vecteurs permettant de conserver 85% d’inertie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "continued-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de composantes principales: 193\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "pca = PCA(n_components=0.85, random_state=42)\n",
    "pca.fit(X_train)\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)\n",
    "print(f\"Nombre de composantes principales: {pca.components_.shape[0]}\")\n",
    "\n",
    "filename_pca_model = './models/pca_model.pkl'\n",
    "pickle.dump(pca, open(filename_pca_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-bulgarian",
   "metadata": {},
   "source": [
    "### Vectorisaton des labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-pathology",
   "metadata": {},
   "source": [
    "A l’image des documents nous avons besoin de vectoriser les tags – labels afin d’entrainer les modèles. Scikit-learn fournit un module permettant de prendre en charge l’opération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alternative-dressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des classes du modèle de vectorisation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['android', 'java', 'javascript', 'python', 'html', 'jquery',\n",
       "       'studio', 'angular', 'visual', 'spring', 'google', 'server',\n",
       "       'mysql', 'window', 'swift', 'node', 'xcode', 'array', 'string',\n",
       "       'json', 'linux', 'core', 'ruby', 'laravel', 'file', 'performance',\n",
       "       'reactjs', 'framework', 'algorithm', 'angularjs', 'objective',\n",
       "       'service', 'docker', 'react', 'chrome', 'typescript', 'bash',\n",
       "       'http', 'macos', 'regex', 'django', 'entity', 'bootstrap',\n",
       "       'firebase', 'database', 'apache', 'gradle', 'eclipse', 'amazon',\n",
       "       'image', 'rail', 'data', 'iphone', 'code', 'twitter', 'excel',\n",
       "       'memory', 'maven', 'ajax', 'list', 'function', 'panda', 'flutter',\n",
       "       'ubuntu', 'multithreading', 'design', 'boot', 'internet', 'date',\n",
       "       'explorer', 'oracle', 'native', 'postgresql', 'testing', 'form',\n",
       "       'class', 'loop', 'exception', 'numpy', 'security', 'azure', 'type',\n",
       "       'language', 'pointer', 'layout', 'github', 'selenium', 'math',\n",
       "       'ecmascript', 'variable', 'shell', 'library', 'error', 'interface',\n",
       "       'operator', 'datetime', 'map', 'facebook', 'rest', 'statement',\n",
       "       'intellij', 'optimization', 'mongodb', 'unit', 'browser', 'event',\n",
       "       'idea', 'lambda', 'debugging', 'plugin', 'opencv', 'object',\n",
       "       'line', 'hibernate', 'cloud', 'dictionary', 'command', 'express',\n",
       "       'authentication', 'kotlin', 'sorting', 'unix', 'compiler',\n",
       "       'collection', 'fragment', 'build', 'linq', 'time', 'handling',\n",
       "       'floating', 'point', 'validation', 'encoding', 'material', 'tsql',\n",
       "       'spark', 'webpack', 'dart', 'socket', 'random', 'static',\n",
       "       'powershell', 'processing', 'tomcat', 'syntax', 'session',\n",
       "       'parsing', 'firefox', 'text', 'notification', 'winforms', 'post',\n",
       "       'cross', 'mobile', 'control', 'email', 'template', 'user',\n",
       "       'dependency', 'assembly', 'video', 'management', 'push', 'unicode',\n",
       "       'ionic', 'input', 'symfony', 'integer', 'font', 'installation',\n",
       "       'asynchronous', 'version', 'module', 'programming', 'pattern',\n",
       "       'dataframe', 'view', 'tensorflow', 'character', 'reference',\n",
       "       'recyclerview', 'vector', 'formatting', 'sqlite', 'uitableview',\n",
       "       'promise', 'async', 'structure', 'stream', 'number', 'scala',\n",
       "       'xamarin', 'encryption', 'model', 'webdriver', 'jenkins', 'play',\n",
       "       'curl', 'junit', 'enums'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=first_200_tags)\n",
    "train_labels = mlb.fit_transform(y_train)\n",
    "test_labels = mlb.transform(y_test)\n",
    "\n",
    "print(\"Affichage des classes du modèle de vectorisation\")\n",
    "display(mlb.classes_)\n",
    "\n",
    "filename_mlb_model = './models/mlb_model.pkl'\n",
    "pickle.dump(mlb, open(filename_mlb_model,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-runner",
   "metadata": {},
   "source": [
    "### Fonction d'évaluation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-crystal",
   "metadata": {},
   "source": [
    "Afin de comparer les modèles nous avons évalué quatre indicateurs :\n",
    "- Jaccard : l'indice et la distance de Jaccard sont deux métriques utilisées en statistiques pour comparer la similarité et la diversité (en) entre des échantillons.\n",
    "- Précision : capacité à prédire correctement les tags associés à chaque document\n",
    "- Recall : capacité à retourner pour chaque tags tous les documents qui y sont associés\n",
    "- F1 Score : moyenne harmonique de ces deux indicateurs\n",
    "\n",
    "Etant face à une classification multi-classes nous utilisons les version micro de ces indicateurs. Concrètement, cette version des indicateurs est calculée par classe puis agrégés là où les indicateurs macro sont calculés globalement. Lors de l’évaluation nous nous intéressons à la précision et au temps d’entraînement. Dans le cadre d’une API de suggestion de tags, la capacité d’un modèle à retourner tous les documents associés à chaque terme n’est pas essentielle. Le recall et le F1 score seront toutefois été observés pour affiner l’analyse. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hourly-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "models_performance = {}\n",
    "\n",
    "def metrics_report(model_name, test_labels, predictions, performances):\n",
    "    \"\"\"\n",
    "    Compute performance metrics of a model and store them in a dictionary\n",
    "    \n",
    "    Args:\n",
    "        model_name(string): name of the evaluated model\n",
    "        test_labels(array): labels related to predictors\n",
    "        preductions(array): predicted results\n",
    "        performances(dict): used dictionary to store metrics\n",
    "    Returns:\n",
    "        performances(dict): used dictionary to store metrics filed with models ones\n",
    "    \"\"\"    \n",
    "    jaccard = jaccard_score(test_labels, predictions, average='macro')\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + model_name + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(jaccard, accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "    \n",
    "    performances[model_name] = {}\n",
    "    performances[model_name][\"jaccard\"] =  jaccard\n",
    "    performances[model_name][\"micro_precision\"] =  micro_precision\n",
    "    performances[model_name][\"micro_recall\"] = micro_recall\n",
    "    performances[model_name][\"micro_f1\"] = micro_f1\n",
    "    \n",
    "    return performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-entity",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "employed-meaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------knn Model Metrics-----\n",
      "Accuracy: 0.1047\n",
      "Hamming Loss: 0.1123\n",
      "Precision:\n",
      "  - Macro: 0.0090\n",
      "  - Micro: 0.3643\n",
      "Recall:\n",
      "  - Macro: 0.6521\n",
      "  - Micro: 0.1227\n",
      "F1-measure:\n",
      "  - Macro: 0.2206\n",
      "  - Micro: 0.1623\n",
      "CPU times: total: 23.9 s\n",
      "Wall time: 21.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': {'jaccard': 0.1047386119063031,\n",
       "  'micro_precision': 0.6520593869731801,\n",
       "  'micro_recall': 0.22055726551109672,\n",
       "  'micro_f1': 0.3296211112456119}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_transformed, train_labels)\n",
    "knn_predictions = knn_clf.predict(X_test_transformed)\n",
    "metrics_report(\"knn\", test_labels, knn_predictions, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-liabilities",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "upper-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------svm Model Metrics-----\n",
      "Accuracy: 0.1064\n",
      "Hamming Loss: 0.1450\n",
      "Precision:\n",
      "  - Macro: 0.0080\n",
      "  - Micro: 0.2842\n",
      "Recall:\n",
      "  - Macro: 0.8056\n",
      "  - Micro: 0.1198\n",
      "F1-measure:\n",
      "  - Macro: 0.2655\n",
      "  - Micro: 0.1523\n",
      "CPU times: total: 1.95 s\n",
      "Wall time: 24.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': {'jaccard': 0.1047386119063031,\n",
       "  'micro_precision': 0.6520593869731801,\n",
       "  'micro_recall': 0.22055726551109672,\n",
       "  'micro_f1': 0.3296211112456119},\n",
       " 'svm': {'jaccard': 0.10640343918322688,\n",
       "  'micro_precision': 0.8056033423445564,\n",
       "  'micro_recall': 0.2655110967114855,\n",
       "  'micro_f1': 0.39939080109655806}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "svm_clf = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svm_clf.fit(X_train_transformed, train_labels)\n",
    "\n",
    "svm_preds = svm_clf.predict(X_test_transformed)\n",
    "metrics_report(\"svm\", test_labels, svm_preds, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-silly",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tropical-board",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Random Forest Model Metrics-----\n",
      "Accuracy: 0.0328\n",
      "Hamming Loss: 0.0826\n",
      "Precision:\n",
      "  - Macro: 0.0088\n",
      "  - Micro: 0.1952\n",
      "Recall:\n",
      "  - Macro: 0.8749\n",
      "  - Micro: 0.0338\n",
      "F1-measure:\n",
      "  - Macro: 0.1388\n",
      "  - Micro: 0.0519\n",
      "CPU times: total: 26min 14s\n",
      "Wall time: 5min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': {'jaccard': 0.1047386119063031,\n",
       "  'micro_precision': 0.6520593869731801,\n",
       "  'micro_recall': 0.22055726551109672,\n",
       "  'micro_f1': 0.3296211112456119},\n",
       " 'svm': {'jaccard': 0.10640343918322688,\n",
       "  'micro_precision': 0.8056033423445564,\n",
       "  'micro_recall': 0.2655110967114855,\n",
       "  'micro_f1': 0.39939080109655806},\n",
       " 'Random Forest': {'jaccard': 0.03276138118251846,\n",
       "  'micro_precision': 0.8749361919346605,\n",
       "  'micro_recall': 0.13883039040984935,\n",
       "  'micro_f1': 0.23963649073750437}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1)\n",
    "rf_clf.fit(X_train_transformed, train_labels)\n",
    "rf_preds = rf_clf.predict(X_test_transformed)\n",
    "metrics_report(\"Random Forest\", test_labels, rf_preds, models_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-compression",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "considerable-grocery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.multiclass import OneVsRestClassifier\\n\\ngb_clf = OneVsRestClassifier(GradientBoostingClassifier())\\ngb_clf.fit(X_train_transformed, train_labels)\\ngb_preds = gb_clf.predict(X_test_transformed)\\nmetrics_report(\"Gradient Boosting\", test_labels, gb_preds, models_performance)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "gb_clf = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "gb_clf.fit(X_train_transformed, train_labels)\n",
    "gb_preds = gb_clf.predict(X_test_transformed)\n",
    "metrics_report(\"Gradient Boosting\", test_labels, gb_preds, models_performance)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-walker",
   "metadata": {},
   "source": [
    "### Synthèse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "clear-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.104739</td>\n",
       "      <td>0.652059</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.329621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.106403</td>\n",
       "      <td>0.805603</td>\n",
       "      <td>0.265511</td>\n",
       "      <td>0.399391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.032761</td>\n",
       "      <td>0.874936</td>\n",
       "      <td>0.138830</td>\n",
       "      <td>0.239636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                jaccard  micro_precision  micro_recall  micro_f1\n",
       "knn            0.104739         0.652059      0.220557  0.329621\n",
       "svm            0.106403         0.805603      0.265511  0.399391\n",
       "Random Forest  0.032761         0.874936      0.138830  0.239636"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(models_performance, orient=\"index\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-shanghai",
   "metadata": {},
   "source": [
    "Si la Random Forest offre la meilleur précision (7 points supérieure à la SVM), le modèle a un ordre de grandeur de temps d’entrainement significativement plus grand (8 fois plus long que la SVM). Si ce critère n’est pas pénalisant à l’échelle des données utilisée pour les travaux, il pourrait le devenir à une échelle plus importante. Pour cette raison nous avons sélectionné la SVM pour cette approche.\n",
    "\n",
    "A noter que pour les besoins de l’approche supervisée, nous avons besoins d’entraîner et de maintenir quatre modèles : un vectoriseur de documents, une ACP, un vectoriseur de tags et le modèle supervisé. Il a également été nécessaire de nettoyer les tags et supprimer les documents ne correspondant pas au top 200 tags. \n",
    "\n",
    "Nous sauvegardons le modèle de SVM retenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "manual-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename_svm_model = './models/svm_model.pkl'\n",
    "pickle.dump(svm_clf, open(filename_svm_model,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-julian",
   "metadata": {},
   "source": [
    "### Fonction de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-rolling",
   "metadata": {},
   "source": [
    " Afin de filtrer les tags suggérés nous avons également ajouté un filtre à la fonction de prédiction. Celui-ci consiste à parcourir le document ayant servi à la prédiction et de ne garder que les tags prédits y figurant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "disturbed-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def predict_supervised_tags(supervised_model, mlb_model, text):\n",
    "    \"\"\"\n",
    "    Predict tags according to a lemmatized text using a supervied model.\n",
    "    \n",
    "    Args:\n",
    "        supervised_model(): Used mode to get prediction\n",
    "        mlb_model(): Used model to detransform\n",
    "    Returns:\n",
    "        res(list): List of predicted tags\n",
    "    \"\"\"\n",
    "    res = tfidf_vectorizer.transform(text)\n",
    "    res = pd.DataFrame(res.toarray(), columns=vocabulary)\n",
    "    res = pca.transform(res)\n",
    "    res = supervised_model.predict(res)\n",
    "    res = mlb.inverse_transform(res)\n",
    "    res = list({tag for tag_list in res for tag in tag_list if (len(tag_list) != 0)})\n",
    "    res = [tag for tag  in res if tag in text]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-finland",
   "metadata": {},
   "source": [
    "### Fonction de vérification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-premium",
   "metadata": {},
   "source": [
    "Afin de comparer les tags prédits et les tags renseignés par les utilisateurs, nous réalisons une fonction de vérification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lesbian-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publication originale: \n",
      "\n",
      "Why is processing a sorted array faster than processing an unsorted array? <p>Here is a piece of C++ code that shows some very peculiar behavior. For some strange reason, sorting the data miraculously makes the code almost six times faster:</p>\n",
      "<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;algorithm&gt;\n",
      "#include &lt;ctime&gt;\n",
      "#include &lt;iostream&gt;\n",
      "\n",
      "int main()\n",
      "{\n",
      "    // Generate data\n",
      "    const unsigned arraySize = 32768;\n",
      "    int data[arraySize];\n",
      "\n",
      "    for (unsigned c = 0; c &lt; arraySize; ++c)\n",
      "        data[c] = std::rand() % 256;\n",
      "\n",
      "    // !!! With this, the next loop runs faster.\n",
      "    std::sort(data, data + arraySize);\n",
      "\n",
      "    // Test\n",
      "    clock_t start = clock();\n",
      "    long long sum = 0;\n",
      "    for (unsigned i = 0; i &lt; 100000; ++i)\n",
      "    {\n",
      "        for (unsigned c = 0; c &lt; arraySize; ++c)\n",
      "        {   // Primary loop\n",
      "            if (data[c] &gt;= 128)\n",
      "                sum += data[c];\n",
      "        }\n",
      "    }\n",
      "\n",
      "    double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC;\n",
      "\n",
      "    std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl;\n",
      "    std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; std::endl;\n",
      "}\n",
      "</code></pre>\n",
      "<ul>\n",
      "<li>Without <code>std::sort(data, data + arraySize);</code>, the code runs in 11.54 seconds.</li>\n",
      "<li>With the sorted data, the code runs in 1.93 seconds.</li>\n",
      "</ul>\n",
      "<hr />\n",
      "<p>Initially, I thought this might be just a language or compiler anomaly, so I tried Java:</p>\n",
      "<pre class=\"lang-java prettyprint-override\"><code>import java.util.Arrays;\n",
      "import java.util.Random;\n",
      "\n",
      "public class Main\n",
      "{\n",
      "    public static void main(String[] args)\n",
      "    {\n",
      "        // Generate data\n",
      "        int arraySize = 32768;\n",
      "        int data[] = new int[arraySize];\n",
      "\n",
      "        Random rnd = new Random(0);\n",
      "        for (int c = 0; c &lt; arraySize; ++c)\n",
      "            data[c] = rnd.nextInt() % 256;\n",
      "\n",
      "        // !!! With this, the next loop runs faster\n",
      "        Arrays.sort(data);\n",
      "\n",
      "        // Test\n",
      "        long start = System.nanoTime();\n",
      "        long sum = 0;\n",
      "        for (int i = 0; i &lt; 100000; ++i)\n",
      "        {\n",
      "            for (int c = 0; c &lt; arraySize; ++c)\n",
      "            {   // Primary loop\n",
      "                if (data[c] &gt;= 128)\n",
      "                    sum += data[c];\n",
      "            }\n",
      "        }\n",
      "\n",
      "        System.out.println((System.nanoTime() - start) / 1000000000.0);\n",
      "        System.out.println(&quot;sum = &quot; + sum);\n",
      "    }\n",
      "}\n",
      "</code></pre>\n",
      "<p>With a similar but less extreme result.</p>\n",
      "<hr />\n",
      "<p>My first thought was that sorting brings the data into the <a href=\"https://en.wikipedia.org/wiki/CPU_cache\" rel=\"noreferrer\">cache</a>, but then I thought how silly that was because the array was just generated.</p>\n",
      "<ul>\n",
      "<li>What is going on?</li>\n",
      "<li>Why is processing a sorted array faster than processing an unsorted array?</li>\n",
      "</ul>\n",
      "<p>The code is summing up some independent terms, so the order should not matter.</p>\n",
      "<hr />\n",
      "<p><strong>Related / followup Q&amp;As</strong> about the same effect with different / later compilers and options:</p>\n",
      "<ul>\n",
      "<li><a href=\"https://stackoverflow.com/q/66521344\">Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?</a></li>\n",
      "<li><a href=\"https://stackoverflow.com/q/28875325\">gcc optimization flag -O3 makes code slower than -O2</a></li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['java', 'performance', 'architecture', 'branch', 'prediction']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle: ['loop', 'array', 'java', 'string']\n"
     ]
    }
   ],
   "source": [
    "def check_tag_predction(original_text, original_tags, preprocessed_text, model):\n",
    "    \"\"\"\n",
    "    Check original tags vs predicted tags for a post.\n",
    "    \n",
    "    Args:\n",
    "        post(list) : original text\n",
    "        original_tags(list) : preprocessed_tags\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_tags = predict_supervised_tags(model, mlb, preprocessed_text)\n",
    "    print(\"Publication originale: \\n\")\n",
    "    print(f\"{original_text}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags pré-traités utilisés par l'utilisateur: {original_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle: {predicted_tags}\")\n",
    "\n",
    "check_tag_predction(filtered_tokenized_vs_original.loc[0,'Post'], \n",
    "                filtered_tokenized_vs_original.loc[0,'splitted_tags'],\n",
    "                filtered_tokenized_vs_original.loc[0,'splitted_text'],\n",
    "                svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-charge",
   "metadata": {},
   "source": [
    "## Méthode non supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-producer",
   "metadata": {},
   "source": [
    "Nous allons utiliser un modèle LDA (Latent Dirichlet Allocation) pour cette approche. Le modèle permet de générer à partir d'un nombre k restreint de topics, une distribution de topic par document et une distribution de topic par token. Nous utilisons le module LdaMulticore de Gensim qui permet de paralléliser les calculs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-professor",
   "metadata": {},
   "source": [
    "### Recherche du modèle ayant l'indice de cohérence maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-manner",
   "metadata": {},
   "source": [
    "Le modèle nécessité de définir le nombre de topics que nous souhaitons générer. Pour se faire nous observons le score de cohérence pour un ensemble de modèles LDA entrainés avec de 2 à 50 topics en hyperparamètre. L’indicateur mesure le degré de similitude sémantique des mots les plus représentés pour chaque topic. Il détermine ainsi si chaque topic est cohérent d’un point de vue sémantique ou s’il est un amalgame aléatoire de mots. Plus le score est élevé et plus le topic est cohérent. Voici diagramme d’évolution du score de cohérence par nombre de topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "experimental-alpha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4691\n",
      "Num Topics = 3  has Coherence Value of 0.5147\n",
      "Num Topics = 4  has Coherence Value of 0.5458\n",
      "Num Topics = 5  has Coherence Value of 0.5413\n",
      "Num Topics = 6  has Coherence Value of 0.537\n",
      "Num Topics = 7  has Coherence Value of 0.5443\n",
      "Num Topics = 8  has Coherence Value of 0.5581\n",
      "Num Topics = 9  has Coherence Value of 0.577\n",
      "Num Topics = 10  has Coherence Value of 0.5533\n",
      "Num Topics = 11  has Coherence Value of 0.559\n",
      "Num Topics = 12  has Coherence Value of 0.5724\n",
      "Num Topics = 13  has Coherence Value of 0.577\n",
      "Num Topics = 14  has Coherence Value of 0.571\n",
      "Num Topics = 15  has Coherence Value of 0.5637\n",
      "Num Topics = 16  has Coherence Value of 0.5674\n",
      "Num Topics = 17  has Coherence Value of 0.5619\n",
      "Num Topics = 18  has Coherence Value of 0.5651\n",
      "Num Topics = 19  has Coherence Value of 0.5641\n",
      "Num Topics = 20  has Coherence Value of 0.5619\n",
      "Num Topics = 21  has Coherence Value of 0.5552\n",
      "Num Topics = 22  has Coherence Value of 0.5646\n",
      "Num Topics = 23  has Coherence Value of 0.5596\n",
      "Num Topics = 24  has Coherence Value of 0.5531\n",
      "Num Topics = 25  has Coherence Value of 0.5666\n",
      "Num Topics = 26  has Coherence Value of 0.5486\n",
      "Num Topics = 27  has Coherence Value of 0.5528\n",
      "Num Topics = 28  has Coherence Value of 0.5644\n",
      "Num Topics = 29  has Coherence Value of 0.5558\n",
      "Num Topics = 30  has Coherence Value of 0.5694\n",
      "Num Topics = 31  has Coherence Value of 0.5626\n",
      "Num Topics = 32  has Coherence Value of 0.5495\n",
      "Num Topics = 33  has Coherence Value of 0.5545\n",
      "Num Topics = 34  has Coherence Value of 0.5584\n",
      "Num Topics = 35  has Coherence Value of 0.5623\n",
      "Num Topics = 36  has Coherence Value of 0.5589\n",
      "Num Topics = 37  has Coherence Value of 0.5608\n",
      "Num Topics = 38  has Coherence Value of 0.5589\n",
      "Num Topics = 39  has Coherence Value of 0.563\n",
      "Num Topics = 40  has Coherence Value of 0.5566\n",
      "Num Topics = 41  has Coherence Value of 0.5615\n",
      "Num Topics = 42  has Coherence Value of 0.5668\n",
      "Num Topics = 43  has Coherence Value of 0.5594\n",
      "Num Topics = 44  has Coherence Value of 0.5639\n",
      "Num Topics = 45  has Coherence Value of 0.5615\n",
      "Num Topics = 46  has Coherence Value of 0.5623\n",
      "Num Topics = 47  has Coherence Value of 0.5587\n",
      "Num Topics = 48  has Coherence Value of 0.5579\n",
      "Num Topics = 49  has Coherence Value of 0.5604\n",
      "Num Topics = 50  has Coherence Value of 0.5691\n",
      "CPU times: total: 14min 8s\n",
      "Wall time: 22min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import gensim\n",
    "from gensim.models import TfidfModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Args:\n",
    "  \n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "        model_list : List of LDA topic models\n",
    "        coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                            id2word=dictionary,\n",
    "                            num_topics=num_topics, \n",
    "                            random_state=42,\n",
    "                            passes=10,\n",
    "                            workers=7)\n",
    "\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "data = pd.read_pickle(\"./data/cleaned_corpus.pkl\")\n",
    "texts = data['splitted_text'].to_list()\n",
    "id2word = corpora.Dictionary(texts)\n",
    "id2word.filter_extremes(no_below=1000)\n",
    "bow_corpus = [id2word.doc2bow(text) for text in texts]\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = [tfidf[text] for text in bow_corpus]\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=tfidf_corpus, texts=texts, start=2, limit=51, step=1)\n",
    "\n",
    "\n",
    "limit=51; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-stevens",
   "metadata": {},
   "source": [
    "L’entrainement de l’ensemble des modèles a pris 24 minutes et 45 seconds soit environs 30 secondes par modèle.  Nous constatons que la cohérence maximale (0.6168) est atteinte avec 7 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-dominican",
   "metadata": {},
   "source": [
    "### Indices de log perplexité, de cohérence et du top 20 des tags les plus représentés par topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "geological-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -5.689641257134172\n",
      "\n",
      "Coherence Score:  0.5442526190356581\n",
      "[(0,\n",
      "  '0.053*\"json\" + 0.038*\"request\" + 0.035*\"http\" + 0.034*\"response\" + '\n",
      "  '0.027*\"service\" + 0.024*\"error\" + 0.024*\"client\" + 0.023*\"test\" + '\n",
      "  '0.022*\"post\" + 0.018*\"server\" + 0.018*\"application\" + 0.017*\"name\" + '\n",
      "  '0.017*\"core\" + 0.014*\"config\" + 0.014*\"import\" + 0.014*\"root\" + '\n",
      "  '0.013*\"class\" + 0.013*\"status\" + 0.013*\"access\" + 0.013*\"file\" + '\n",
      "  '0.012*\"function\" + 0.011*\"message\" + 0.011*\"code\" + 0.011*\"return\" + '\n",
      "  '0.011*\"property\" + 0.011*\"info\" + 0.011*\"body\" + 0.011*\"type\" + '\n",
      "  '0.010*\"password\" + 0.010*\"context\"'),\n",
      " (1,\n",
      "  '0.104*\"java\" + 0.060*\"android\" + 0.046*\"project\" + 0.039*\"studio\" + '\n",
      "  '0.036*\"version\" + 0.027*\"support\" + 0.027*\"class\" + 0.025*\"google\" + '\n",
      "  '0.022*\"error\" + 0.021*\"application\" + 0.017*\"package\" + 0.016*\"method\" + '\n",
      "  '0.015*\"build\" + 0.014*\"name\" + 0.014*\"code\" + 0.014*\"import\" + '\n",
      "  '0.013*\"source\" + 0.013*\"file\" + 0.013*\"anyone\" + 0.012*\"base\" + '\n",
      "  '0.011*\"http\" + 0.010*\"problem\" + 0.010*\"core\" + 0.010*\"view\" + 0.010*\"idea\" '\n",
      "  '+ 0.009*\"target\" + 0.009*\"test\" + 0.008*\"work\" + 0.008*\"debug\" + '\n",
      "  '0.008*\"void\"'),\n",
      " (2,\n",
      "  '0.052*\"file\" + 0.035*\"command\" + 0.032*\"line\" + 0.029*\"error\" + '\n",
      "  '0.027*\"path\" + 0.026*\"program\" + 0.023*\"python\" + 0.023*\"directory\" + '\n",
      "  '0.021*\"memory\" + 0.021*\"install\" + 0.019*\"number\" + 0.018*\"process\" + '\n",
      "  '0.017*\"version\" + 0.016*\"difference\" + 0.015*\"option\" + 0.015*\"code\" + '\n",
      "  '0.014*\"problem\" + 0.014*\"home\" + 0.014*\"time\" + 0.013*\"application\" + '\n",
      "  '0.013*\"work\" + 0.013*\"environment\" + 0.013*\"script\" + 0.012*\"output\" + '\n",
      "  '0.012*\"machine\" + 0.011*\"help\" + 0.011*\"system\" + 0.011*\"server\" + '\n",
      "  '0.011*\"location\" + 0.011*\"project\"'),\n",
      " (3,\n",
      "  '0.042*\"image\" + 0.030*\"html\" + 0.029*\"array\" + 0.027*\"page\" + 0.026*\"list\" '\n",
      "  '+ 0.025*\"jquery\" + 0.024*\"python\" + 0.024*\"import\" + 0.023*\"color\" + '\n",
      "  '0.022*\"script\" + 0.021*\"function\" + 0.021*\"text\" + 0.021*\"element\" + '\n",
      "  '0.020*\"style\" + 0.018*\"module\" + 0.018*\"class\" + 0.016*\"javascript\" + '\n",
      "  '0.016*\"document\" + 0.015*\"file\" + 0.015*\"display\" + 0.015*\"index\" + '\n",
      "  '0.014*\"code\" + 0.013*\"body\" + 0.013*\"width\" + 0.012*\"content\" + '\n",
      "  '0.012*\"example\" + 0.012*\"link\" + 0.012*\"http\" + 0.011*\"browser\" + '\n",
      "  '0.011*\"size\"'),\n",
      " (4,\n",
      "  '0.050*\"database\" + 0.041*\"query\" + 0.039*\"item\" + 0.036*\"javascript\" + '\n",
      "  '0.033*\"table\" + 0.028*\"connection\" + 0.026*\"server\" + 0.025*\"access\" + '\n",
      "  '0.024*\"result\" + 0.023*\"length\" + 0.022*\"create\" + 0.021*\"name\" + '\n",
      "  '0.018*\"array\" + 0.017*\"error\" + 0.016*\"function\" + 0.015*\"user\" + '\n",
      "  '0.013*\"case\" + 0.013*\"code\" + 0.012*\"need\" + 0.012*\"console\" + 0.011*\"list\" '\n",
      "  '+ 0.011*\"time\" + 0.010*\"something\" + 0.010*\"column\" + 0.010*\"status\" + '\n",
      "  '0.010*\"example\" + 0.009*\"password\" + 0.009*\"client\" + 0.009*\"index\" + '\n",
      "  '0.009*\"order\"'),\n",
      " (5,\n",
      "  '0.051*\"system\" + 0.046*\"view\" + 0.040*\"size\" + 0.033*\"void\" + 0.033*\"class\" '\n",
      "  '+ 0.029*\"button\" + 0.028*\"code\" + 0.028*\"print\" + 0.028*\"model\" + '\n",
      "  '0.022*\"exception\" + 0.018*\"error\" + 0.017*\"string\" + 0.016*\"list\" + '\n",
      "  '0.016*\"message\" + 0.014*\"return\" + 0.014*\"default\" + 0.013*\"method\" + '\n",
      "  '0.011*\"name\" + 0.011*\"time\" + 0.011*\"show\" + 0.010*\"file\" + 0.009*\"type\" + '\n",
      "  '0.009*\"value\" + 0.009*\"something\" + 0.009*\"output\" + 0.009*\"program\" + '\n",
      "  '0.009*\"problem\" + 0.009*\"application\" + 0.009*\"work\" + 0.008*\"import\"'),\n",
      " (6,\n",
      "  '0.055*\"value\" + 0.047*\"function\" + 0.041*\"date\" + 0.031*\"input\" + '\n",
      "  '0.031*\"return\" + 0.027*\"column\" + 0.025*\"name\" + 0.025*\"type\" + '\n",
      "  '0.025*\"class\" + 0.024*\"form\" + 0.023*\"time\" + 0.023*\"number\" + '\n",
      "  '0.020*\"string\" + 0.020*\"example\" + 0.019*\"something\" + 0.017*\"field\" + '\n",
      "  '0.016*\"code\" + 0.015*\"question\" + 0.014*\"event\" + 0.014*\"check\" + '\n",
      "  '0.013*\"order\" + 0.013*\"case\" + 0.013*\"method\" + 0.012*\"password\" + '\n",
      "  '0.012*\"state\" + 0.011*\"object\" + 0.010*\"text\" + 0.010*\"array\" + '\n",
      "  '0.010*\"output\" + 0.010*\"null\"')]\n",
      "CPU times: total: 8.48 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pprint import pprint\n",
    "optimal_model = model_list[5]\n",
    "\n",
    "print('\\nPerplexity: ', optimal_model.log_perplexity(tfidf_corpus))\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=optimal_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-artwork",
   "metadata": {},
   "source": [
    "Nous constatons un nombre important de tags génériques dans ceux les plus représentés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-christopher",
   "metadata": {},
   "source": [
    "### Test du topic dominant, des mots clés associés des documents du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impressed-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "<timed exec>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 54.9 s\n",
      "Wall time: 55.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Original_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>system, view, size, void, class, button, code,...</td>\n",
       "      <td>Why is processing a sorted array faster than p...</td>\n",
       "      <td>[java, performance, architecture, branch, pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5707</td>\n",
       "      <td>database, query, item, javascript, table, conn...</td>\n",
       "      <td>How do I undo the most recent local commits in...</td>\n",
       "      <td>[version, control, commit, undo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>value, function, date, input, return, column, ...</td>\n",
       "      <td>How do I delete a Git branch locally and remot...</td>\n",
       "      <td>[version, control, branch, push, remote]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>java, android, project, studio, version, suppo...</td>\n",
       "      <td>How do I force \"git pull\" to overwrite local f...</td>\n",
       "      <td>[version, control, overwrite, pull, fetch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>value, function, date, input, return, column, ...</td>\n",
       "      <td>How do I revert a Git repository to a previous...</td>\n",
       "      <td>[checkout, reset, revert]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6652</td>\n",
       "      <td>value, function, date, input, return, column, ...</td>\n",
       "      <td>How do I check out a remote Git branch? &lt;p&gt;Som...</td>\n",
       "      <td>[checkout, remote, branch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>json, request, http, response, service, error,...</td>\n",
       "      <td>How to make Git \"forget\" about a file that was...</td>\n",
       "      <td>[gitignore]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>file, command, line, error, path, program, pyt...</td>\n",
       "      <td>What is the difference between \"px\", \"dip\", \"d...</td>\n",
       "      <td>[android, android, layout, user, interface, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4469</td>\n",
       "      <td>image, html, array, page, list, jquery, python...</td>\n",
       "      <td>How do I find all files containing specific te...</td>\n",
       "      <td>[linux, text, grep, directory, find]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>json, request, http, response, service, error,...</td>\n",
       "      <td>What is the difference between POST and PUT in...</td>\n",
       "      <td>[http, rest, post]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0          0.0             5.0              0.7923   \n",
       "1          1.0             4.0              0.5707   \n",
       "2          2.0             6.0              0.6700   \n",
       "3          3.0             1.0              0.7077   \n",
       "4          4.0             6.0              0.6427   \n",
       "5          5.0             6.0              0.6652   \n",
       "6          6.0             0.0              0.6821   \n",
       "7          7.0             2.0              0.5711   \n",
       "8          8.0             3.0              0.4469   \n",
       "9          9.0             0.0              0.7533   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  system, view, size, void, class, button, code,...   \n",
       "1  database, query, item, javascript, table, conn...   \n",
       "2  value, function, date, input, return, column, ...   \n",
       "3  java, android, project, studio, version, suppo...   \n",
       "4  value, function, date, input, return, column, ...   \n",
       "5  value, function, date, input, return, column, ...   \n",
       "6  json, request, http, response, service, error,...   \n",
       "7  file, command, line, error, path, program, pyt...   \n",
       "8  image, html, array, page, list, jquery, python...   \n",
       "9  json, request, http, response, service, error,...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Why is processing a sorted array faster than p...   \n",
       "1  How do I undo the most recent local commits in...   \n",
       "2  How do I delete a Git branch locally and remot...   \n",
       "3  How do I force \"git pull\" to overwrite local f...   \n",
       "4  How do I revert a Git repository to a previous...   \n",
       "5  How do I check out a remote Git branch? <p>Som...   \n",
       "6  How to make Git \"forget\" about a file that was...   \n",
       "7  What is the difference between \"px\", \"dip\", \"d...   \n",
       "8  How do I find all files containing specific te...   \n",
       "9  What is the difference between POST and PUT in...   \n",
       "\n",
       "                                   Original_keywords  \n",
       "0  [java, performance, architecture, branch, pred...  \n",
       "1                   [version, control, commit, undo]  \n",
       "2           [version, control, branch, push, remote]  \n",
       "3         [version, control, overwrite, pull, fetch]  \n",
       "4                          [checkout, reset, revert]  \n",
       "5                         [checkout, remote, branch]  \n",
       "6                                        [gitignore]  \n",
       "7  [android, android, layout, user, interface, di...  \n",
       "8               [linux, text, grep, directory, find]  \n",
       "9                                 [http, rest, post]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "original_post = data['Post']\n",
    "original_cleaned_keywords = data['splitted_tags']\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=tfidf_corpus, texts=original_post)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic = pd.concat([df_dominant_topic, original_cleaned_keywords], axis=1)\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text', 'Original_keywords']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-spiritual",
   "metadata": {},
   "source": [
    "### Document le plus significatif par topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "industrial-pointer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 25 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>json, request, http, response, service, error,...</td>\n",
       "      <td>Wavy shape with css &lt;p&gt;I'm trying to recreate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>java, android, project, studio, version, suppo...</td>\n",
       "      <td>TOAD for Oracle and Windows 7: Can't initializ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8694</td>\n",
       "      <td>file, command, line, error, path, program, pyt...</td>\n",
       "      <td>detect 404 error on page load &lt;p&gt;I am embeddin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>image, html, array, page, list, jquery, python...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>database, query, item, javascript, table, conn...</td>\n",
       "      <td>Unit Testing HTTP traffic in Alamofire app &lt;p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>system, view, size, void, class, button, code,...</td>\n",
       "      <td>bash export command &lt;p&gt;I am encountering a str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>value, function, date, input, return, column, ...</td>\n",
       "      <td>Securing a password in a properties file &lt;p&gt;I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.8710   \n",
       "1        1.0              0.8784   \n",
       "2        2.0              0.8694   \n",
       "3        3.0              0.8593   \n",
       "4        4.0              0.8464   \n",
       "5        5.0              0.8582   \n",
       "6        6.0              0.8510   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  json, request, http, response, service, error,...   \n",
       "1  java, android, project, studio, version, suppo...   \n",
       "2  file, command, line, error, path, program, pyt...   \n",
       "3  image, html, array, page, list, jquery, python...   \n",
       "4  database, query, item, javascript, table, conn...   \n",
       "5  system, view, size, void, class, button, code,...   \n",
       "6  value, function, date, input, return, column, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  Wavy shape with css <p>I'm trying to recreate ...  \n",
       "1  TOAD for Oracle and Windows 7: Can't initializ...  \n",
       "2  detect 404 error on page load <p>I am embeddin...  \n",
       "3                                                NaN  \n",
       "4  Unit Testing HTTP traffic in Alamofire app <p>...  \n",
       "5  bash export command <p>I am encountering a str...  \n",
       "6  Securing a password in a properties file <p>I ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sent_topics_sorteddf = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf = pd.concat([sent_topics_sorteddf, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-damages",
   "metadata": {},
   "source": [
    "### Répartition des topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-bacteria",
   "metadata": {},
   "source": [
    "Nous appréhendons tout d'abord la répartition des topics à l'aide d'un tableau;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "regular-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>json, request, http, response, service, error,...</td>\n",
       "      <td>4196</td>\n",
       "      <td>0.1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>java, android, project, studio, version, suppo...</td>\n",
       "      <td>4489</td>\n",
       "      <td>0.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>file, command, line, error, path, program, pyt...</td>\n",
       "      <td>6335</td>\n",
       "      <td>0.1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>image, html, array, page, list, jquery, python...</td>\n",
       "      <td>5939</td>\n",
       "      <td>0.1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>database, query, item, javascript, table, conn...</td>\n",
       "      <td>3223</td>\n",
       "      <td>0.0935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>system, view, size, void, class, button, code,...</td>\n",
       "      <td>3799</td>\n",
       "      <td>0.1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>value, function, date, input, return, column, ...</td>\n",
       "      <td>6492</td>\n",
       "      <td>0.1883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dominant_Topic                                     Topic_Keywords  \\\n",
       "0.0             0.0  json, request, http, response, service, error,...   \n",
       "1.0             1.0  java, android, project, studio, version, suppo...   \n",
       "2.0             2.0  file, command, line, error, path, program, pyt...   \n",
       "3.0             3.0  image, html, array, page, list, jquery, python...   \n",
       "4.0             4.0  database, query, item, javascript, table, conn...   \n",
       "5.0             5.0  system, view, size, void, class, button, code,...   \n",
       "6.0             6.0  value, function, date, input, return, column, ...   \n",
       "\n",
       "     Num_Documents  Perc_Documents  \n",
       "0.0           4196          0.1217  \n",
       "1.0           4489          0.1302  \n",
       "2.0           6335          0.1838  \n",
       "3.0           5939          0.1723  \n",
       "4.0           3223          0.0935  \n",
       "5.0           3799          0.1102  \n",
       "6.0           6492          0.1883  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = sent_topics_sorteddf[[\"Topic_Num\",\"Keywords\"]]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics_prop = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics_prop.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-usage",
   "metadata": {},
   "source": [
    "Nous ajoutons une visualisation spaciale des topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "planned-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .jp-icon-warn0 path {fill: var(--jp-warn-color0);} .bp3-button-text path { fill: var(--jp-inverse-layout-color3);} .jp-icon-brand0 path { fill: var(--jp-brand-color0);} text.terms { fill: #616161;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1611622292244783523490226709\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1611622292244783523490226709_data = {\"mdsDat\": {\"x\": [0.09458555639177826, -0.12702967504200519, -0.06066415430080135, 0.02734001064804409, 0.15235326784510375, 0.005329112367206852, -0.09191411790932608], \"y\": [-0.0631904946371516, 0.04838370017864972, -0.1343816280001673, 0.020160335407133734, 0.047365434221355404, 0.038145732181082005, 0.04351692064909837], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [17.1800252886498, 16.298757437526678, 16.270066570112355, 14.079404935022572, 13.392654045407218, 12.12236757695281, 10.656724146328576]}, \"tinfo\": {\"Term\": [\"java\", \"android\", \"json\", \"database\", \"view\", \"query\", \"studio\", \"date\", \"request\", \"system\", \"javascript\", \"response\", \"project\", \"item\", \"image\", \"size\", \"value\", \"command\", \"table\", \"column\", \"void\", \"connection\", \"function\", \"model\", \"input\", \"button\", \"support\", \"jquery\", \"python\", \"service\", \"directory\", \"install\", \"command\", \"memory\", \"environment\", \"path\", \"process\", \"program\", \"home\", \"difference\", \"machine\", \"option\", \"line\", \"file\", \"location\", \"python\", \"start\", \"number\", \"information\", \"someone\", \"nothing\", \"site\", \"script\", \"everything\", \"build\", \"package\", \"output\", \"root\", \"anything\", \"please\", \"error\", \"help\", \"version\", \"problem\", \"work\", \"solution\", \"application\", \"time\", \"server\", \"code\", \"system\", \"project\", \"date\", \"form\", \"column\", \"input\", \"field\", \"value\", \"event\", \"null\", \"check\", \"function\", \"state\", \"return\", \"order\", \"type\", \"object\", \"password\", \"string\", \"number\", \"reference\", \"answer\", \"time\", \"case\", \"something\", \"example\", \"instance\", \"question\", \"point\", \"name\", \"change\", \"call\", \"method\", \"class\", \"code\", \"output\", \"text\", \"array\", \"color\", \"element\", \"image\", \"jquery\", \"style\", \"width\", \"html\", \"document\", \"display\", \"page\", \"link\", \"body\", \"array\", \"click\", \"script\", \"browser\", \"module\", \"header\", \"title\", \"text\", \"none\", \"python\", \"content\", \"list\", \"site\", \"auto\", \"index\", \"import\", \"load\", \"javascript\", \"function\", \"class\", \"file\", \"code\", \"example\", \"http\", \"size\", \"response\", \"json\", \"request\", \"service\", \"client\", \"post\", \"config\", \"root\", \"core\", \"status\", \"info\", \"http\", \"context\", \"configuration\", \"body\", \"header\", \"property\", \"test\", \"server\", \"password\", \"init\", \"console\", \"access\", \"content\", \"connection\", \"application\", \"browser\", \"message\", \"title\", \"import\", \"error\", \"name\", \"user\", \"class\", \"file\", \"function\", \"return\", \"type\", \"code\", \"android\", \"java\", \"studio\", \"support\", \"project\", \"google\", \"build\", \"base\", \"package\", \"version\", \"target\", \"source\", \"debug\", \"idea\", \"application\", \"anyone\", \"core\", \"method\", \"configuration\", \"thing\", \"reference\", \"class\", \"action\", \"context\", \"info\", \"width\", \"exception\", \"import\", \"reason\", \"issue\", \"error\", \"content\", \"view\", \"name\", \"problem\", \"code\", \"http\", \"file\", \"test\", \"void\", \"work\", \"model\", \"view\", \"size\", \"void\", \"print\", \"system\", \"button\", \"exception\", \"show\", \"debug\", \"message\", \"default\", \"machine\", \"context\", \"string\", \"class\", \"action\", \"init\", \"code\", \"note\", \"list\", \"method\", \"click\", \"object\", \"reason\", \"change\", \"property\", \"start\", \"program\", \"output\", \"return\", \"error\", \"time\", \"type\", \"something\", \"name\", \"problem\", \"work\", \"application\", \"value\", \"file\", \"import\", \"query\", \"database\", \"table\", \"item\", \"connection\", \"length\", \"javascript\", \"access\", \"result\", \"create\", \"server\", \"status\", \"need\", \"console\", \"user\", \"action\", \"case\", \"field\", \"array\", \"order\", \"password\", \"client\", \"update\", \"column\", \"part\", \"name\", \"index\", \"browser\", \"null\", \"instance\", \"function\", \"something\", \"error\", \"list\", \"code\", \"time\", \"example\"], \"Freq\": [1452.0, 711.0, 707.0, 589.0, 698.0, 467.0, 549.0, 670.0, 530.0, 955.0, 654.0, 454.0, 839.0, 495.0, 751.0, 679.0, 1204.0, 602.0, 397.0, 513.0, 588.0, 437.0, 1369.0, 389.0, 601.0, 554.0, 403.0, 452.0, 800.0, 448.0, 323.4433357707645, 293.8895863587168, 503.2821159788155, 299.7024850557903, 188.06319631868112, 390.24281181425704, 254.79739826672687, 375.81743657995855, 203.4671633501192, 225.51018141342956, 171.87590016999187, 220.48466231840334, 464.2070891513562, 746.2314198502861, 158.90877940604892, 334.07844320923635, 141.51279994067104, 276.27091017333527, 106.69200795366973, 101.88396924707595, 106.36339238864575, 111.569844241198, 183.15217003895893, 94.04985198884906, 92.14581768355494, 123.81248783310073, 176.86263320830332, 96.76011930404044, 104.12294133790631, 129.79444097455655, 421.6907224749085, 163.70464667230985, 237.40773435987967, 204.65915174098728, 188.45253584573794, 151.3662437572848, 192.54489785794868, 194.8721278806508, 162.0201646317172, 213.8166982865066, 163.59568330171095, 158.3459485548825, 561.2407591151731, 330.2199925978974, 368.37302963652326, 425.89997814722847, 230.55589963110515, 751.7709069230118, 194.79425485537283, 129.26008293864683, 192.74922482730517, 636.0069173902484, 160.4822221773683, 424.1122074966718, 177.3588393098644, 340.85914426792493, 143.5839139534901, 164.3364105754673, 276.203057056298, 309.72132977897627, 120.5706645962616, 101.07049352845372, 318.7148910990684, 174.4383790808878, 252.98524654998047, 268.2517299242234, 102.93056149670272, 198.81354077360106, 103.06936046460558, 341.7623835603494, 117.0746699373788, 106.23942625067828, 173.6408269767185, 336.10525591632165, 212.38409934226544, 134.99603671662499, 139.2757547768962, 136.98913958653546, 313.55023880450085, 280.4541217256651, 570.4510183234277, 342.6849083541598, 276.122101578787, 172.67442349579196, 408.1854607966339, 210.5480604777222, 198.96012046407512, 365.9698352543147, 161.9491550346642, 174.1497234588948, 390.02765489416737, 136.56763102654196, 291.46563507349117, 155.05518952429549, 245.74647811124277, 138.91461196905868, 140.9147678308706, 283.9002148945805, 132.88556405881047, 331.2448036983508, 167.9866066960493, 346.622381217931, 138.48430457976247, 99.55749209217527, 198.188098383279, 319.98814308762974, 125.58444563862942, 211.907020222383, 285.8870585079698, 238.84608991419435, 204.01792944225136, 185.10039162957034, 163.4743853930355, 156.95359185882793, 150.65084159736207, 404.3702159680325, 625.4992667369922, 444.9713674165564, 320.7631604734243, 276.9248361870349, 261.08924059791883, 166.24131251073183, 164.61919916499977, 198.49338744088246, 154.78014348417133, 126.63569347752262, 405.4551554317458, 121.74250293568406, 117.7448569803637, 126.09987358597796, 108.89111327062663, 127.60379666646008, 267.15771670977875, 214.20129299287427, 122.19492138173916, 66.14676415050917, 105.57481934425405, 150.1814458704361, 106.60226880921084, 106.0366392886813, 206.85502112897467, 72.77800347241933, 133.8761247796089, 71.54942090639973, 165.47422231079898, 286.8437991443876, 202.2787953893973, 106.46463130981364, 156.93862268534886, 149.35992306959133, 144.4506811890686, 130.92932830203458, 124.19968990627929, 131.09598924239947, 665.8633977033417, 1157.743615367555, 436.4510544799015, 305.2937708736542, 512.1722366072237, 276.4790748919075, 168.58423125658635, 136.27552228367688, 186.83410651624175, 402.7802170157375, 104.01983725388142, 149.4870842806455, 93.79907492858756, 106.6925763602209, 233.5886149271172, 140.49018311443504, 110.0434195116416, 181.3228570729851, 76.74998684375939, 73.52631806246359, 70.98102857296645, 295.5668634794555, 60.79400214722874, 57.08046691557352, 52.329293105851654, 45.60047163133831, 90.13856364004631, 152.12173547329272, 58.73890628815138, 84.3942529337998, 248.40958083428538, 70.82543108426536, 109.11540183379533, 158.86841682443378, 114.29031017501144, 156.61796850265557, 122.04658609904622, 143.78770110935287, 102.0709866277351, 90.50531690769662, 94.4396311667428, 282.66881411232805, 468.2080790941073, 407.6804808143191, 332.5194504053106, 283.54038941523294, 512.7418108323227, 287.87286308130706, 224.10840414322553, 108.5485525764583, 82.35918417835256, 160.67200108739073, 136.758481591191, 79.9677250516518, 74.31875957635528, 169.48898945030905, 331.77868754997775, 68.58420286038776, 51.100504384386966, 286.87651109274907, 53.018917721808045, 163.5786059128313, 133.56692675328367, 51.003607841990686, 64.75839004082307, 58.60972082777117, 81.02783800179049, 59.94688183104184, 60.34054606928841, 89.31390495179437, 89.70457481282722, 141.82916090505591, 186.73402619080306, 110.85306664673054, 95.61233533227474, 93.5139679155826, 111.18926422651911, 89.18496340238721, 86.20464142864904, 88.18708837110199, 93.54831158893181, 96.4275392512755, 82.68059320128971, 361.0009143564203, 441.2776635060639, 289.18148839146335, 348.08673792624637, 247.509841121676, 207.88092652088946, 316.77560330581144, 222.75211291718804, 212.65784314774817, 195.2112399669672, 227.74459255372824, 89.60253951695917, 105.87140598738002, 102.32149265706008, 135.4981622267054, 65.56373899216061, 119.47762050856161, 74.72857614146986, 159.1947951116635, 80.77273746867606, 82.76282324051897, 81.5015209450469, 38.59538245268863, 91.91869719360095, 48.99974409935206, 188.95943332670075, 81.10637168287829, 49.34747396239302, 41.46346061108124, 48.45746452898813, 142.331869979718, 92.59454450414825, 146.63744397786206, 96.83143785623551, 118.7715404900389, 94.81574767506842, 89.15084236305523], \"Total\": [1452.0, 711.0, 707.0, 589.0, 698.0, 467.0, 549.0, 670.0, 530.0, 955.0, 654.0, 454.0, 839.0, 495.0, 751.0, 679.0, 1204.0, 602.0, 397.0, 513.0, 588.0, 437.0, 1369.0, 389.0, 601.0, 554.0, 403.0, 452.0, 800.0, 448.0, 381.44263315395284, 350.1886881126306, 602.2997239783338, 379.0002167670884, 276.93730454030685, 600.8979882150996, 396.7318784616179, 585.4967173449076, 335.06648583124047, 374.6885850841999, 300.5786781477771, 411.49043190125644, 871.134725697432, 1447.9544243261464, 308.41031879570806, 800.1047629699536, 377.0515701121246, 803.7753416915028, 316.8483618536266, 316.6687865392037, 333.6808408107348, 358.36730317149375, 597.3046852413391, 309.3224322328903, 303.5094947803089, 409.24791781989467, 594.4521327515752, 325.96102325794783, 350.8774856766172, 444.8598087732927, 1513.320063132955, 565.4925168041543, 901.6144456339634, 803.3770589675631, 777.3205139266054, 571.9940847345181, 868.4638535766537, 917.0969568840131, 720.1910952173683, 1304.6631985861854, 955.7542112727571, 839.717924747037, 670.599253815868, 445.6576022181043, 513.4014403972143, 601.4420770837393, 358.69137531798685, 1204.977600403361, 378.4357303903783, 275.8942564268028, 411.52554841769927, 1369.1766496790076, 347.56446166317585, 942.4466251198205, 401.751327079245, 834.7852496914496, 359.4086432008968, 412.70241928503214, 696.3425184488733, 803.7753416915028, 313.787933213809, 271.6317108814282, 917.0969568840131, 549.8079390028679, 806.4210814226612, 865.5358663106247, 342.26118028757736, 674.9738645073732, 356.8243467000784, 1209.7518941999224, 476.6207869534995, 435.2983926767116, 717.688147519158, 1443.272446745775, 1304.6631985861854, 594.4521327515752, 658.740260189322, 786.2464157488614, 372.33184122543673, 334.68422999539837, 751.518829583418, 452.82705945030517, 381.55527912199057, 251.9426381383105, 608.6160231939695, 314.6553722574435, 323.84686473946994, 625.4132056392182, 299.1150886478539, 346.0867812896143, 786.2464157488614, 279.67754351620766, 597.3046852413391, 318.4098087996998, 505.7304568563418, 308.0933919340961, 325.0405032547237, 658.740260189322, 320.44016028580734, 800.1047629699536, 410.5985837390311, 873.3893391108489, 358.36730317149375, 258.2176823734826, 520.437056761839, 848.076900580033, 336.21896168196656, 654.8921433915552, 1369.1766496790076, 1443.272446745775, 1447.9544243261464, 1304.6631985861854, 865.5358663106247, 890.8822291705228, 679.8558579798043, 454.9265870618637, 707.9327539802059, 530.6482225647057, 448.29040282252805, 449.38317736115994, 471.16589231580923, 315.20205958430535, 325.96102325794783, 411.7972658225164, 333.40164901759334, 275.3204610837977, 890.8822291705228, 299.7768763964201, 314.95869329725593, 346.0867812896143, 308.0933919340961, 370.8350483166728, 819.308091293684, 720.1910952173683, 412.70241928503214, 227.9108686847649, 388.6631481985936, 558.4682747589062, 410.5985837390311, 437.0917476007118, 868.4638535766537, 318.4098087996998, 597.9105090525029, 325.0405032547237, 848.076900580033, 1513.320063132955, 1209.7518941999224, 559.5385248777858, 1443.272446745775, 1447.9544243261464, 1369.1766496790076, 942.4466251198205, 834.7852496914496, 1304.6631985861854, 711.7972019762622, 1452.718110181186, 549.3766237429327, 403.7659333209959, 839.717924747037, 462.3193441940296, 303.5094947803089, 281.63945088133494, 409.24791781989467, 901.6144456339634, 274.97838247929315, 460.0456660360134, 289.25405512914557, 383.03642592439746, 868.4638535766537, 522.9682243524073, 411.7972658225164, 717.688147519158, 314.95869329725593, 310.6187312615821, 313.787933213809, 1443.272446745775, 301.0237783729667, 299.7768763964201, 275.3204610837977, 251.9426381383105, 500.51713140360454, 848.076900580033, 334.57677170202794, 483.0983321242277, 1513.320063132955, 410.5985837390311, 698.542926647262, 1209.7518941999224, 803.3770589675631, 1304.6631985861854, 890.8822291705228, 1447.9544243261464, 819.308091293684, 588.1540611012915, 777.3205139266054, 389.60386600650963, 698.542926647262, 679.8558579798043, 588.1540611012915, 522.2303897624265, 955.7542112727571, 554.5731308155018, 500.51713140360454, 368.439830092579, 289.25405512914557, 597.9105090525029, 512.3937080130833, 300.5786781477771, 299.7768763964201, 696.3425184488733, 1443.272446745775, 301.0237783729667, 227.9108686847649, 1304.6631985861854, 274.33835278183744, 873.3893391108489, 717.688147519158, 279.67754351620766, 359.4086432008968, 334.57677170202794, 476.6207869534995, 370.8350483166728, 377.0515701121246, 585.4967173449076, 594.4521327515752, 942.4466251198205, 1513.320063132955, 917.0969568840131, 834.7852496914496, 806.4210814226612, 1209.7518941999224, 803.3770589675631, 777.3205139266054, 868.4638535766537, 1204.977600403361, 1447.9544243261464, 848.076900580033, 467.58151590922046, 589.6937935631136, 397.369641938678, 495.20038365925257, 437.0917476007118, 391.8160872870151, 654.8921433915552, 558.4682747589062, 582.2157567726343, 596.9680022254718, 720.1910952173683, 333.40164901759334, 396.0460344086166, 388.6631481985936, 559.5385248777858, 301.0237783729667, 549.8079390028679, 358.69137531798685, 786.2464157488614, 401.751327079245, 412.70241928503214, 449.38317736115994, 213.40548439663988, 513.4014403972143, 304.4035251427846, 1209.7518941999224, 520.437056761839, 318.4098087996998, 275.8942564268028, 342.26118028757736, 1369.1766496790076, 806.4210814226612, 1513.320063132955, 873.3893391108489, 1304.6631985861854, 917.0969568840131, 865.5358663106247], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.7894, -3.8853, -3.3473, -3.8657, -4.3317, -3.6017, -4.028, -3.6394, -4.253, -4.1501, -4.4217, -4.1726, -3.4281, -2.9534, -4.5001, -3.7571, -4.6161, -3.9471, -4.8985, -4.9446, -4.9016, -4.8538, -4.3582, -5.0246, -5.0451, -4.7497, -4.3931, -4.9962, -4.9229, -4.7025, -3.5242, -4.4704, -4.0987, -4.2471, -4.3296, -4.5488, -4.3081, -4.2961, -4.4807, -4.2033, -4.4711, -4.5037, -3.1857, -3.7161, -3.6067, -3.4616, -4.0753, -2.8934, -4.2439, -4.654, -4.2544, -3.0606, -4.4376, -3.4658, -4.3376, -3.6843, -4.5489, -4.4139, -3.8947, -3.7801, -4.7236, -4.9, -3.7515, -4.3542, -3.9825, -3.9239, -4.8818, -4.2234, -4.8804, -3.6817, -4.753, -4.8501, -4.3588, -3.6984, -4.1574, -4.6106, -4.5794, -4.5959, -3.7661, -3.8776, -3.1676, -3.6772, -3.8932, -4.3626, -3.5023, -4.1643, -4.2209, -3.6115, -4.4268, -4.3541, -3.5478, -4.5972, -3.8391, -4.4703, -4.0097, -4.5802, -4.5659, -3.8654, -4.6246, -3.7112, -4.3902, -3.6658, -4.5833, -4.9133, -4.2248, -3.7458, -4.6811, -4.1579, -3.8585, -4.0382, -4.1958, -4.2932, -4.4174, -4.4581, -4.4991, -3.3671, -2.9309, -3.2714, -3.5987, -3.7457, -3.8046, -4.256, -4.2658, -4.0787, -4.3274, -4.5281, -3.3644, -4.5675, -4.6009, -4.5324, -4.6791, -4.5205, -3.7816, -4.0025, -4.5638, -5.1776, -4.71, -4.3576, -4.7003, -4.7057, -4.0374, -5.082, -4.4725, -5.099, -4.2606, -3.7105, -4.0598, -4.7016, -4.3136, -4.3631, -4.3965, -4.4948, -4.5475, -4.4935, -2.8183, -2.2652, -3.2408, -3.5982, -3.0808, -3.6973, -4.192, -4.4047, -4.0892, -3.321, -4.6748, -4.3122, -4.7783, -4.6495, -3.8659, -4.3743, -4.6186, -4.1191, -4.9789, -5.0218, -5.057, -3.6305, -5.2119, -5.275, -5.3619, -5.4995, -4.8181, -4.2947, -5.2463, -4.8839, -3.8043, -5.0592, -4.627, -4.2514, -4.5807, -4.2656, -4.515, -4.3511, -4.6938, -4.814, -4.7715, -3.5755, -3.0709, -3.2093, -3.4131, -3.5724, -2.98, -3.5573, -3.8076, -4.5326, -4.8087, -4.1404, -4.3016, -4.8382, -4.9114, -4.087, -3.4153, -4.9917, -5.286, -3.5607, -5.2491, -4.1225, -4.3252, -5.2879, -5.0491, -5.1489, -4.825, -5.1263, -5.1198, -4.7276, -4.7233, -4.2652, -3.9901, -4.5116, -4.6595, -4.6817, -4.5085, -4.7291, -4.763, -4.7403, -4.6813, -4.651, -4.8048, -3.202, -3.0012, -3.4239, -3.2385, -3.5795, -3.7539, -3.3327, -3.6849, -3.7312, -3.8168, -3.6627, -4.5955, -4.4287, -4.4628, -4.182, -4.9079, -4.3078, -4.7771, -4.0208, -4.6993, -4.6749, -4.6903, -5.4378, -4.57, -5.1991, -3.8494, -4.6952, -5.192, -5.3661, -5.2102, -4.1328, -4.5627, -4.1029, -4.5179, -4.3137, -4.539, -4.6006], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5965, 1.5862, 1.5818, 1.5267, 1.3744, 1.3298, 1.3186, 1.3181, 1.2626, 1.2537, 1.2025, 1.1375, 1.132, 1.0986, 1.0983, 0.8881, 0.7814, 0.6935, 0.6729, 0.6274, 0.6181, 0.5945, 0.5793, 0.5709, 0.5694, 0.5659, 0.5492, 0.5469, 0.5466, 0.5296, 0.4836, 0.5218, 0.427, 0.3939, 0.3444, 0.432, 0.255, 0.2126, 0.2696, -0.0472, -0.0037, 0.0931, 1.6361, 1.5143, 1.4821, 1.469, 1.3721, 1.3423, 1.15, 1.0559, 1.0556, 1.0473, 1.0413, 1.0156, 0.9964, 0.9184, 0.8965, 0.8933, 0.8894, 0.8604, 0.8576, 0.8255, 0.7572, 0.6661, 0.6548, 0.6427, 0.6126, 0.5918, 0.5722, 0.55, 0.4102, 0.4037, 0.395, 0.3568, -0.0012, 0.3317, 0.2602, 0.0667, 1.644, 1.6391, 1.5402, 1.5371, 1.4924, 1.438, 1.4164, 1.4141, 1.3287, 1.28, 1.2023, 1.1291, 1.1148, 1.099, 1.0983, 1.0963, 1.0941, 1.0193, 0.98, 0.9741, 0.9356, 0.934, 0.9221, 0.8917, 0.865, 0.8628, 0.8504, 0.8412, 0.8311, 0.6875, 0.2495, 0.017, -0.1439, -0.137, 0.1492, 0.0796, 0.3089, 1.8427, 1.8367, 1.7844, 1.6257, 1.4763, 1.3701, 1.3207, 1.2773, 1.2307, 1.1931, 1.1838, 1.1733, 1.0593, 0.9765, 0.9508, 0.9204, 0.8936, 0.8398, 0.7479, 0.7433, 0.7234, 0.6572, 0.6471, 0.6119, 0.5441, 0.5257, 0.4845, 0.4639, 0.4469, 0.3263, 0.2973, 0.1719, 0.3012, -0.2584, -0.3111, -0.2886, -0.0134, 0.0552, -0.3373, 1.9438, 1.7835, 1.7804, 1.7309, 1.5161, 1.4963, 1.4225, 1.2845, 1.2264, 1.2047, 1.0384, 0.8863, 0.8843, 0.7323, 0.6973, 0.6961, 0.6908, 0.6347, 0.5986, 0.5695, 0.5242, 0.4247, 0.4108, 0.3519, 0.3501, 0.3012, 0.2962, 0.2922, 0.2707, 0.2657, 0.2035, 0.2531, 0.1539, -0.0196, 0.0604, -0.1094, 0.0227, -0.2991, -0.0723, 0.1389, -0.0974, 1.7893, 1.71, 1.5987, 1.5398, 1.4994, 1.4874, 1.4544, 1.3066, 0.888, 0.8539, 0.796, 0.7892, 0.786, 0.7154, 0.6971, 0.6399, 0.631, 0.615, 0.5955, 0.4664, 0.435, 0.4287, 0.4084, 0.3963, 0.3682, 0.3382, 0.2878, 0.2777, 0.2298, 0.219, 0.2163, 0.0177, -0.0029, -0.0568, -0.0444, -0.2768, -0.088, -0.089, -0.1771, -0.4456, -0.599, -0.2179, 1.9803, 1.9491, 1.9212, 1.8865, 1.6703, 1.6052, 1.5127, 1.3198, 1.2318, 1.1212, 1.0877, 0.925, 0.9197, 0.9044, 0.8208, 0.7148, 0.7125, 0.6704, 0.6418, 0.6348, 0.6322, 0.5317, 0.5289, 0.5188, 0.4124, 0.3823, 0.3801, 0.3745, 0.3438, 0.2841, -0.0248, 0.0746, -0.0951, 0.0396, -0.1575, -0.0303, -0.034]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7], \"Freq\": [0.1450395728118453, 0.023277956130296158, 0.03223101618041006, 0.2685918015034172, 0.08057754045102516, 0.05013713628063788, 0.39930647823508025, 0.02325397693775221, 0.11626988468876104, 0.056473943991683935, 0.1561338451534791, 0.20264179902898352, 0.22921777267212892, 0.2192517825559494, 0.011239156290286729, 0.001404894536285841, 0.005619578145143364, 0.011239156290286729, 0.9356597611663702, 0.021073418044287615, 0.01264405082657257, 0.18775421998598077, 0.3718269846781188, 0.09571783763991176, 0.051540374113798644, 0.09571783763991176, 0.10676220352144004, 0.08835492705222625, 0.2160743133866845, 0.10134458946455115, 0.15297296522951118, 0.06692567228791113, 0.2677026891516445, 0.09943242739918226, 0.09369594120307559, 0.2963997527497406, 0.1567498692426513, 0.11114990728115275, 0.0712499405648415, 0.142499881129683, 0.13109989063930835, 0.08834992630040346, 0.22223147135618251, 0.036846668825895545, 0.0483612528339879, 0.2383518889675118, 0.2694412657893612, 0.10132833927121275, 0.08520792165988345, 0.03179664733503264, 0.17424562739597887, 0.4960276984265092, 0.04833090394924961, 0.005087463573605223, 0.04197157448224308, 0.2022266770508076, 0.050345119205264084, 0.1161810443198402, 0.38727014773280066, 0.05421782068259209, 0.14716265613846424, 0.13554455170648022, 0.11230834284251219, 0.11006980699256314, 0.08521533444585533, 0.07811405657536738, 0.127823001668783, 0.4828868951931802, 0.06746213976963547, 0.04615830615817163, 0.0028894486991780663, 0.04912062788602713, 0.5027640736569836, 0.36407053609643636, 0.0086683460975342, 0.04623117918684906, 0.0260050382926026, 0.07537456239326326, 0.025124854131087754, 0.48679404878982524, 0.22926429394617576, 0.021984247364701785, 0.0062812135327719384, 0.1538897315529125, 0.30312066535708515, 0.006589579681675764, 0.026358318726703057, 0.05930621713508188, 0.5568194831016021, 0.03294789840837882, 0.01647394920418941, 0.003606377389865594, 0.10999451039090061, 0.25785598337538995, 0.01262232086452958, 0.07573392518717748, 0.5193183441406455, 0.019835075644260767, 0.12175556099367947, 0.24351112198735894, 0.13553920940805828, 0.19067380306557352, 0.08959371469346225, 0.13094465993659868, 0.08729643995773245, 0.12186073580805554, 0.3164741497104726, 0.0818467628561567, 0.0672962272372844, 0.06547741028492536, 0.1291360036174917, 0.21643921733072552, 0.1468672829975194, 0.24547817301013952, 0.20771230023934883, 0.06504122532747286, 0.0797279536272248, 0.16994642746855815, 0.08392416171286822, 0.172528778038186, 0.4689866783291535, 0.08504939762445789, 0.07046950088883654, 0.03158977626051293, 0.05831958694248541, 0.11177920830643036, 0.014550267378380183, 0.23280427805408294, 0.1655959001634697, 0.10878057040027089, 0.2050894830476445, 0.2300327985534391, 0.043650802135140554, 0.04290655534631648, 0.13229521231780914, 0.4898498402037798, 0.03217991650973736, 0.08938865697149266, 0.18235286022184505, 0.03217991650973736, 0.06675817322794356, 0.013351634645588712, 0.024477996850245973, 0.6164004661380122, 0.0511812661414234, 0.04450544881862904, 0.18247234015637906, 0.1640270073011209, 0.1624940446160637, 0.14179904836779145, 0.10040905587124692, 0.12033757077699057, 0.2199801453057089, 0.09121127976090368, 0.0026857762062700605, 0.005371552412540121, 0.843333728768799, 0.008057328618810181, 0.06445862895048145, 0.04834397171286109, 0.029543538268970666, 0.0038955870448135425, 0.7167880162456918, 0.052590425104982824, 0.01753014170166094, 0.009738967612033855, 0.021425728746474484, 0.17919700406142294, 0.835132376746854, 0.011622120551149062, 0.019923635230541248, 0.039847270461082496, 0.04482817926871781, 0.026564846974055, 0.023244241102298124, 0.2855311292023084, 0.009517704306743613, 0.025380544817982967, 0.5266463049731466, 0.050761089635965935, 0.08565933876069252, 0.012690272408991484, 0.22225136657502723, 0.003175019522500389, 0.006350039045000778, 0.3746523036550459, 0.24447650323252995, 0.13017580042251595, 0.022225136657502722, 0.034317737825841244, 0.002287849188389416, 0.002287849188389416, 0.2425120139692781, 0.05490838052134599, 0.09608966591235547, 0.5673865987205752, 0.07204181855104244, 0.15180240337541087, 0.09777103946212903, 0.27272974165751784, 0.046312597639955856, 0.09519811737102038, 0.2624380532930832, 0.04383843664555957, 0.01704828091771761, 0.4091587420252227, 0.2605951511708263, 0.1729182778797072, 0.06332218626580827, 0.03653203053796631, 0.03335814329713731, 0.036693957626851036, 0.046701400615992227, 0.40696934822507513, 0.19014141679368265, 0.24685026039881605, 0.036693957626851036, 0.09470679685573459, 0.01942703525245838, 0.04856758813114594, 0.48081912249834485, 0.2671217347213027, 0.06799462338360432, 0.01942703525245838, 0.13903592770563827, 0.11893434779638937, 0.08375658295520377, 0.07873118797789155, 0.1440613226829505, 0.10720842618266084, 0.32665067352529475, 0.03222011187398816, 0.06783181447155402, 0.0033915907235777015, 0.04578647476829897, 0.02374113506504391, 0.08139817736586484, 0.7478457545488831, 0.01938564638422565, 0.8365652016577376, 0.016403239248190933, 0.05070092131259016, 0.028332867792329797, 0.01938564638422565, 0.029824071360347152, 0.17977276058163869, 0.010371505418171462, 0.013828673890895283, 0.1659440866907434, 0.32497383643603917, 0.2834878147633533, 0.020743010836342925, 0.1541783178921917, 0.1619848150006571, 0.10148446241005023, 0.1463718207837263, 0.07806497108465402, 0.26737252596494004, 0.08977471674735213, 0.603167561000593, 0.1868218109293872, 0.0533776602655392, 0.02935771314604656, 0.02135106410621568, 0.0533776602655392, 0.0533776602655392, 0.846785261860425, 0.005243252395420588, 0.023594635779392647, 0.04981089775649559, 0.05243252395420588, 0.01310813098855147, 0.007864878593130883, 0.02470303365893594, 0.0833727385989088, 0.6144879622660314, 0.04323030890313789, 0.04940606731787188, 0.10498789305047775, 0.0802848593915418, 0.03178080173319984, 0.11441088623951941, 0.6705749165705165, 0.08580816467963956, 0.006356160346639967, 0.009534240519959951, 0.08263008450631958, 0.002987891004048052, 0.0746972751012013, 0.8366094811334546, 0.023903128032384417, 0.01792734602428831, 0.02987891004048052, 0.011951564016192209, 0.6788540110624119, 0.01083277677227253, 0.02166555354454506, 0.1444370236303004, 0.08666221417818024, 0.04333110708909012, 0.014443702363030041, 0.2788570708078457, 0.07070546582094667, 0.07665265453485806, 0.1896492400991747, 0.1638780890055586, 0.12356936550015912, 0.0971374156605529, 0.0237821095558709, 0.5152790403772028, 0.22725126908943305, 0.06870387205029371, 0.05284913234637978, 0.06870387205029371, 0.04492176249442281, 0.3038900196194855, 0.0775889411794431, 0.13254777451488195, 0.0937533039251604, 0.17457511765374698, 0.10021904902344733, 0.11638341176916464, 0.1201567769147493, 0.30963477128031547, 0.1883226407413859, 0.08434081456516056, 0.10282647255204506, 0.09127293631024225, 0.10282647255204506, 0.07392354362824821, 0.055942141124079726, 0.015983468892594208, 0.17182229059538773, 0.1798140250416848, 0.4475371289926378, 0.05394420751250545, 0.008363736087438517, 0.6440076787327658, 0.02509120826231555, 0.041818680437192585, 0.033454944349754066, 0.03903076840804641, 0.20909340218596292, 0.5152095863425922, 0.031078326253909713, 0.14088841235105737, 0.1029037913740566, 0.09945064401251108, 0.06630042934167406, 0.043509656755473594, 0.006731625321925516, 0.7404787854118068, 0.07404787854118068, 0.08975500429234022, 0.006731625321925516, 0.05609687768271264, 0.026926501287702066, 0.05112561627194777, 0.4645127421279826, 0.20888466076824375, 0.10517269633086399, 0.010955489201131664, 0.055507811952400433, 0.10371196443737976, 0.05840119030076414, 0.028119091626293845, 0.14059545813146923, 0.10382433831246958, 0.5969899452967001, 0.015141049337235148, 0.05623818325258769, 0.03570345969105692, 0.03570345969105692, 0.4511618997324465, 0.35378882784774585, 0.022720383439763493, 0.05842384313082041, 0.04219499781670363, 0.2900126794370963, 0.12378589975973622, 0.14146959972541284, 0.09018686982495068, 0.15031144970825114, 0.09726034981122132, 0.10787056979062729, 0.6058499091498006, 0.014922411555413809, 0.12236377475439324, 0.1163948101322277, 0.08654998702140008, 0.026860340799744857, 0.023875858488662093, 0.046006018463099575, 0.07393824395855289, 0.6703734118908796, 0.10679968571790974, 0.02464608131951763, 0.03450451384732468, 0.04107680219919605, 0.1122482823494048, 0.02918455341084525, 0.17622980328856555, 0.45460554351508947, 0.13694290446627386, 0.030307036234339297, 0.05949158964518455, 0.21668957410432366, 0.11226086369260141, 0.1070394281720153, 0.07048937952791251, 0.279346800351357, 0.11226086369260141, 0.09920727489113614, 0.06653193244368343, 0.00798383189324201, 0.758464029857991, 0.0505642686571994, 0.06254001649706242, 0.03858852081733639, 0.013306386488736685, 0.08725623814230585, 0.050702949190799346, 0.3773242730478091, 0.19455782829027654, 0.17922902969770932, 0.09786848332177547, 0.012970521886018436, 0.17677449905743509, 0.0730155539585058, 0.3804494653627407, 0.1441096459707351, 0.01152877167765881, 0.05764385838829405, 0.15563841764839392, 0.1816065533348856, 0.025424917466883985, 0.05084983493376797, 0.46128064547060943, 0.18887081546828102, 0.05448196600046568, 0.039953441733674835, 0.33770097271145255, 0.09468251571349137, 0.06312167714232758, 0.1514920251415862, 0.10099468342772412, 0.11046293499907325, 0.13886768971312066, 0.14918112592088414, 0.07020288278629841, 0.08775360348287302, 0.289586891493481, 0.15795648626917144, 0.2237716888813262, 0.017550720696574602, 0.0532054560518296, 0.7082976336899816, 0.1064109121036592, 0.0332534100323935, 0.0066506820064787, 0.07149483156964602, 0.021614716521055774, 0.8395473925343965, 0.03997844726354269, 0.025700430383706015, 0.08281249790305271, 0.00571120675193467, 0.002855603375967335, 0.0964175953938816, 0.30093976744150924, 0.03506094377959331, 0.14900901106327158, 0.1285567938585088, 0.14608726574830547, 0.14024377511837324, 0.27323629833202673, 0.09107876611067557, 0.14282806503719578, 0.13661814916601336, 0.1738776443931079, 0.10556856981010124, 0.07451899045418911, 0.002019384542092964, 0.016155076336743714, 0.10702738073092712, 0.016155076336743714, 0.05856215172069597, 0.09693045802046228, 0.7027458206483516, 0.04474371149120807, 0.049562265036415094, 0.005506918337379455, 0.04474371149120807, 0.7971264293356761, 0.05093899462075996, 0.00757201271389675, 0.006107875992044738, 0.15116993080310726, 0.3237174275783711, 0.030539379960223687, 0.003053937996022369, 0.0015269689980111844, 0.4840491723695455, 0.0044166971877251235, 0.09937568672381528, 0.7574635676948587, 0.05300036625270148, 0.08391724656677733, 0.02118845316262822, 0.02118845316262822, 0.02401358025097865, 0.8828522151095092, 0.011300508353401718, 0.0028251270883504296, 0.035314088604380366, 0.028074396016165168, 0.16078972263803687, 0.07401431676989, 0.07656653458954137, 0.035731049475119306, 0.09443205932710103, 0.5308613064874869, 0.532638622147132, 0.0665798277683915, 0.16300578522606196, 0.06084018744353017, 0.04476919453391842, 0.08724253293789232, 0.04476919453391842, 0.1571301541906927, 0.03343194770014738, 0.5415975527423876, 0.11701181695051585, 0.056834311090250555, 0.0434615320101916, 0.050147921550221075, 0.06182809611000578, 0.13281591016223465, 0.39730276574392603, 0.05495830765333847, 0.05495830765333847, 0.1877742178155731, 0.11106158004945484, 0.18142938665577288, 0.02974252240258572, 0.37475578227258005, 0.1695323776947386, 0.05948504480517144, 0.12194434185060145, 0.06543354928568858, 0.5155469525820959, 0.042151637632498413, 0.07133354060884346, 0.1556368158738403, 0.10375787724922686, 0.08430327526499683, 0.025939469312306715, 0.5722295442241501, 0.01330766381916628, 0.00998074786437471, 0.04990373932187356, 0.05988448718624827, 0.26615327638332564, 0.029942243593124133, 0.7915562755056751, 0.05277041836704501, 0.023746688265170252, 0.029023730101874756, 0.013192604591761253, 0.07915562755056751, 0.013192604591761253, 0.1856465111742216, 0.056864697116428234, 0.056864697116428234, 0.22411380628239363, 0.11205690314119682, 0.2692710657572043, 0.09533199222460027, 0.036227434004413396, 0.24244513526030503, 0.07245486800882679, 0.1574500016345659, 0.2521986751845702, 0.18671062140736133, 0.0529477881602965, 0.005133419286877876, 0.10010167609411857, 0.023100386790950438, 0.06416774108597344, 0.028233806077828313, 0.7263788290932194, 0.05390090251221769, 0.24914457551800498, 0.023728054811238568, 0.48642512363039064, 0.11864027405619285, 0.10084423294776391, 0.011864027405619284, 0.007909351603746189, 0.08514142486060726, 0.28270259516822993, 0.08596804063595297, 0.16697638661983172, 0.13143190827996656, 0.09175435106337287, 0.1562303815403376, 0.1691722531701287, 0.20957159721075647, 0.13382282713457944, 0.053024139053323927, 0.07574877007617704, 0.09342348309395168, 0.2676456542691589, 0.19348386277394472, 0.11234546870745178, 0.4150540927247524, 0.09986263885106825, 0.05929344181782177, 0.08113839406649295, 0.040569197033246476, 0.2515142316060744, 0.1640310206126572, 0.10935401374177146, 0.06925754203645526, 0.08748321099341717, 0.19319209094379625, 0.123934548907341, 0.3176688231258793, 0.08391251931627, 0.13785628173387213, 0.08391251931627, 0.1468469088034725, 0.1468469088034725, 0.08391251931627, 0.036245770859869596, 0.4675704440923178, 0.025372039601908716, 0.1087373125796088, 0.08336527297770008, 0.1268601980095436, 0.14860766052546534, 0.34337953117493325, 0.3856799082037293, 0.0497651494456425, 0.02488257472282125, 0.014929544833692748, 0.08708901152987437, 0.09330965521057968, 0.027823482237210283, 0.40065814421582807, 0.07512340204046776, 0.14468210763349346, 0.04729991980325748, 0.18085263454186684, 0.1279880182911673, 0.5346418359802652, 0.19441521308373277, 0.10206798686895971, 0.036452852453199895, 0.05589437376157317, 0.03159247212610657, 0.04617361310738653, 0.10454228068228769, 0.4405710400182124, 0.0945858729982603, 0.049782038420136995, 0.03733652881510275, 0.07218395570919864, 0.20161725560155483, 0.29775315832531346, 0.22709986651930686, 0.12616659251072604, 0.06392440687210119, 0.04541997330386137, 0.15139991101287123, 0.08915772537424639, 0.30299482196650046, 0.012217533143810503, 0.09040974526419772, 0.09285325189295981, 0.4569357395785128, 0.04153961268895571, 0.007330519886286302, 0.06555665859037145, 0.04477040098854636, 0.5852130986359988, 0.11992071693360631, 0.015989428924480843, 0.05596300123568295, 0.11352494536381398, 0.19382167132369854, 0.23324302820309487, 0.15768542751758524, 0.08541293990535868, 0.05913203531909447, 0.1116938444916229, 0.1609705405908683, 0.05573022818680182, 0.39738075750589125, 0.002423053399426166, 0.2956125147299922, 0.019384427195409327, 0.026653587393687825, 0.2011134321523718, 0.6490286332268335, 0.011649231878430344, 0.08487297511427822, 0.14311913450642993, 0.07322374323584788, 0.0266268157221265, 0.011649231878430344, 0.29222689358806514, 0.1393697492496926, 0.11239495907233274, 0.07193277380629295, 0.1640966402456058, 0.09890756398365282, 0.12588235416101268, 0.21298995066578313, 0.2886574331391535, 0.10929747468375714, 0.047642488964714645, 0.13171746949068167, 0.14853246559587507, 0.06165498571904249, 0.05518226260438422, 0.18040355082202533, 0.050937473173277736, 0.5539450207593954, 0.029713526017745347, 0.029713526017745347, 0.09975255163100223, 0.09382831976187966, 0.1225512747910265, 0.16659313916905163, 0.05744591005829367, 0.005744591005829367, 0.5438212818851801, 0.011489182011658734, 0.25517283287059483, 0.15559319077475295, 0.15061420866996086, 0.09086642341245572, 0.1419009899865747, 0.1107823518316241, 0.09460065999104979, 0.6427514748469353, 0.03276772224709867, 0.035288316266106255, 0.09326197870328082, 0.09074138468427323, 0.045370692342136615, 0.06049425645618215, 0.6421897661614111, 0.06490215721844049, 0.025619272586226507, 0.027327224091974942, 0.06831806022993735, 0.1520076840116106, 0.018787466563232772, 0.18815842242214503, 0.016672265277911585, 0.03572628273838197, 0.07621606984188153, 0.6097285587350523, 0.053589424107572954, 0.020244893551749785, 0.008089850227528022, 0.21033610591572854, 0.134830837125467, 0.34516694304119555, 0.051235718107677464, 0.16179700455056042, 0.09168496924531758, 0.4174453339837732, 0.08498887039190592, 0.413695824995895, 0.03374558089090382, 0.0037495089878782023, 0.04249443519595296, 0.004999345317170937, 0.006415993571017125, 0.1454291876097215, 0.010693322618361875, 0.03207996785508563, 0.010693322618361875, 0.023525309760396126, 0.7720578930457274, 0.2148231326050345, 0.29482623026484045, 0.12148618533526089, 0.05629847613097455, 0.1051892580341893, 0.1051892580341893, 0.10370771918863733, 0.20324184387958766, 0.14944253226440268, 0.10759862323036994, 0.07173241548691328, 0.17634218807199517, 0.17634218807199517, 0.11656517516623409, 0.060550448213232494, 0.385610749147428, 0.0892322394721321, 0.09560597086299867, 0.22626746437576353, 0.1147271650355984, 0.0286817912588996, 0.024498338913054245, 0.03392077695653665, 0.020729363695661283, 0.8385969858699337, 0.016960388478268324, 0.020729363695661283, 0.04711219021741201, 0.01978341177667008, 0.01318894118444672, 0.01318894118444672, 0.8880553730860791, 0.010990784320372265, 0.017585254912595626, 0.0373686666892657, 0.08072608728512022, 0.180345514147609, 0.10305457951291942, 0.13397095336679524, 0.03435152650430647, 0.10305457951291942, 0.36584375727086393, 0.043503789930583445, 0.44989285196505807, 0.09761826033204091, 0.13899991416844956, 0.040320585789321246, 0.15067166268641097, 0.07851903548446769, 0.29758159129117556, 0.01227140582644023, 0.03988206893593074, 0.5061954903406595, 0.05828917767559109, 0.02454281165288046, 0.06749273204542126, 0.3063763009427247, 0.04855143566851922, 0.4871885441220377, 0.05859656028959216, 0.006696749747381962, 0.013393499494763924, 0.07701262209489255, 0.2249402985899251, 0.034713009041655106, 0.02638188687165788, 0.2971433573965677, 0.058317855189980575, 0.041655610849986126, 0.31658264245989454, 0.07584369369928298, 0.02230696873508323, 0.008922787494033291, 0.7160536963961717, 0.10930414680190782, 0.042383240596658135, 0.026768362482099874, 0.08956686358179025, 0.09228101096305662, 0.2469874116952398, 0.04885465286279468, 0.10313760048812211, 0.29584206455803447, 0.12213663215698671, 0.3125285119731007, 0.033485197711403646, 0.385079773681142, 0.1618451222717843, 0.025113898283552736, 0.027904331426169708, 0.05301822970972245, 0.07795770144202303, 0.0323598005985756, 0.22210590410840525, 0.019121700353703763, 0.0161799002992878, 0.6001272111008565, 0.030888900571367617, 0.2639887439921415, 0.16258909398191498, 0.16783390346520255, 0.06468598362721349, 0.14685466553205223, 0.09615484052693897, 0.09615484052693897, 0.32210310689200927, 0.21157753099769236, 0.12315707028223884, 0.05684172474564869, 0.09473620790941449, 0.09789408150639498, 0.09789408150639498, 0.16740633784255426, 0.3137318775864165, 0.1426053989029166, 0.06324239429607606, 0.0830831454477862, 0.11656441301629705, 0.11532436606931518, 0.24345409221012504, 0.03695285328189398, 0.14129032137194758, 0.07825310106754019, 0.32388089052954133, 0.10651116534192971, 0.06955831206003572, 0.3766063086748934, 0.10343412703042847, 0.05834745627357504, 0.11139059834046143, 0.12465138385718302, 0.15912942620065917, 0.06895608468695232, 0.04315746186540923, 0.46034625989769845, 0.074806267233376, 0.10070074435262154, 0.06905193898465477, 0.13810387796930954, 0.11220940085006399, 0.14097110838680899, 0.032993238133082955, 0.014996926424128617, 0.4649047191479871, 0.029993852848257233, 0.044990779272385845, 0.26994467563431507, 0.02154112322971892, 0.3963566674268281, 0.038774021813494056, 0.10914169103057586, 0.12350243985038847, 0.24269665505483315, 0.06749551945311928, 0.12377665350358798, 0.005460734713393587, 0.003640489808929058, 0.012741714331251703, 0.7936267783465346, 0.0436858777071487, 0.014561959235716232, 0.013104261095549942, 0.03669193106753984, 0.7233552124743567, 0.020966817752879906, 0.07338386213507968, 0.0891089754497396, 0.0445544877248698, 0.0668704260855382, 0.014860094685675155, 0.05944037874270062, 0.052010331399863045, 0.7553881465218204, 0.01733677713328768, 0.03219687181896284, 0.17159223372042984, 0.05231470540257007, 0.01569441162077102, 0.09521276383267753, 0.09102758740047193, 0.5367488774303689, 0.03766658788985045, 0.0050330971189506205, 0.1686087534848458, 0.055364068308456825, 0.0050330971189506205, 0.007549645678425931, 0.030198582713703723, 0.7272825336883647, 0.14182933090362781, 0.03636649510349431, 0.17092252698642327, 0.10182618628978407, 0.37821154907634086, 0.13091938237257952, 0.040003144613843744, 0.14280342308747065, 0.1391417968544586, 0.10618716075734998, 0.3258847347380741, 0.12449529192241032, 0.09398173998064309, 0.06590927219421723, 0.06983025447204273, 0.21100881242639, 0.4311259189143508, 0.06224000942073374, 0.04705951931811576, 0.12144392082094388, 0.05768586238994835, 0.18672409021964717, 0.18350470935379118, 0.14165275809766337, 0.06116823645126373, 0.23823418407334293, 0.10302018770739155, 0.0901426642439676, 0.21262746379896885, 0.347836722830108, 0.07741820476782968, 0.06651423226531845, 0.07196621851657407, 0.12103409477787458, 0.10358773877385662, 0.006153079323879414, 0.08921965019625151, 0.4337920923334987, 0.22151085565965892, 0.049224634591035314, 0.11383196749176916, 0.0861431105343118, 0.05510399233455833, 0.4084882910018346, 0.15093702248161628, 0.14854119672793983, 0.06109355671874945, 0.11499963617646955, 0.06109355671874945, 0.2014943529758556, 0.1030901340806703, 0.10777604926615532, 0.11714787963712535, 0.14526337075003543, 0.14526337075003543, 0.18275069223391555, 0.13403902799433065, 0.21267525775100463, 0.07863622975667398, 0.1894418262319873, 0.028594992638790537, 0.11259278351523774, 0.24127025038979516, 0.03900487443440189, 0.6240779909504303, 0.07303040319632695, 0.09875702250412395, 0.021577164580732965, 0.07800974886880378, 0.06639127563302451, 0.2628618043418273, 0.02550979535806763, 0.06432904916382272, 0.11978512602918713, 0.44697597953483714, 0.04769222610421339, 0.033273646119218646, 0.01002085875179828, 0.024336371254367255, 0.05583049876001899, 0.04151498625745002, 0.1560390862780018, 0.669965985120228, 0.04294653750770692, 0.022103052345941634, 0.11901643570891648, 0.015302113162574977, 0.09351291377129152, 0.15472136642159143, 0.5661781870152741, 0.02890399152930829, 0.01587662981366455, 0.6866642394409918, 0.007938314906832274, 0.18258124285714233, 0.09129062142857117, 0.01587662981366455, 0.24185647571595026, 0.15566294447675522, 0.18782470986451455, 0.07976117816164317, 0.12092823785797513, 0.11063647293389213, 0.10163117862531952], \"Term\": [\"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"array\", \"array\", \"array\", \"array\", \"array\", \"array\", \"array\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"browser\", \"browser\", \"browser\", \"browser\", \"browser\", \"browser\", \"browser\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"button\", \"button\", \"button\", \"button\", \"button\", \"button\", \"button\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"check\", \"check\", \"check\", \"check\", \"check\", \"check\", \"check\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"click\", \"click\", \"click\", \"click\", \"click\", \"click\", \"click\", \"client\", \"client\", \"client\", \"client\", \"client\", \"client\", \"client\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"command\", \"command\", \"command\", \"command\", \"command\", \"command\", \"command\", \"config\", \"config\", \"config\", \"config\", \"config\", \"config\", \"config\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"console\", \"console\", \"console\", \"console\", \"console\", \"console\", \"console\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"database\", \"database\", \"database\", \"database\", \"database\", \"database\", \"database\", \"date\", \"date\", \"date\", \"date\", \"date\", \"date\", \"date\", \"debug\", \"debug\", \"debug\", \"debug\", \"debug\", \"debug\", \"debug\", \"default\", \"default\", \"default\", \"default\", \"default\", \"default\", \"default\", \"difference\", \"difference\", \"difference\", \"difference\", \"difference\", \"difference\", \"difference\", \"directory\", \"directory\", \"directory\", \"directory\", \"directory\", \"directory\", \"directory\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"element\", \"element\", \"element\", \"element\", \"element\", \"element\", \"element\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exception\", \"exception\", \"exception\", \"exception\", \"exception\", \"exception\", \"exception\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"header\", \"header\", \"header\", \"header\", \"header\", \"header\", \"header\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"http\", \"http\", \"http\", \"http\", \"http\", \"http\", \"http\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"import\", \"import\", \"import\", \"import\", \"import\", \"import\", \"import\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"info\", \"info\", \"info\", \"info\", \"info\", \"info\", \"info\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"init\", \"init\", \"init\", \"init\", \"init\", \"init\", \"init\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"install\", \"install\", \"install\", \"install\", \"install\", \"install\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"jquery\", \"jquery\", \"jquery\", \"jquery\", \"jquery\", \"json\", \"json\", \"json\", \"json\", \"json\", \"json\", \"json\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"load\", \"load\", \"load\", \"load\", \"load\", \"load\", \"load\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"module\", \"module\", \"module\", \"module\", \"module\", \"module\", \"module\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"null\", \"null\", \"null\", \"null\", \"null\", \"null\", \"null\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"package\", \"package\", \"package\", \"package\", \"package\", \"package\", \"package\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"password\", \"password\", \"password\", \"password\", \"password\", \"password\", \"password\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"please\", \"please\", \"please\", \"please\", \"please\", \"please\", \"please\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"print\", \"print\", \"print\", \"print\", \"print\", \"print\", \"print\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"request\", \"request\", \"request\", \"request\", \"request\", \"request\", \"request\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"root\", \"root\", \"root\", \"root\", \"root\", \"root\", \"root\", \"script\", \"script\", \"script\", \"script\", \"script\", \"script\", \"script\", \"server\", \"server\", \"server\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"status\", \"status\", \"status\", \"status\", \"status\", \"status\", \"status\", \"string\", \"string\", \"string\", \"string\", \"string\", \"string\", \"string\", \"studio\", \"studio\", \"studio\", \"studio\", \"studio\", \"studio\", \"studio\", \"style\", \"style\", \"style\", \"style\", \"style\", \"style\", \"style\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"title\", \"title\", \"title\", \"title\", \"title\", \"title\", \"title\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"void\", \"void\", \"void\", \"void\", \"void\", \"void\", \"void\", \"width\", \"width\", \"width\", \"width\", \"width\", \"width\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 7, 4, 1, 2, 6, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1611622292244783523490226709\", ldavis_el1611622292244783523490226709_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1611622292244783523490226709\", ldavis_el1611622292244783523490226709_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1611622292244783523490226709\", ldavis_el1611622292244783523490226709_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.25 s\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import HTML\n",
    "css_str = '<style> \\\n",
    ".jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    ".bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    ".jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "text.terms { fill: #616161;} \\\n",
    "</style>'\n",
    "display(HTML(css_str))\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(optimal_model, tfidf_corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'lda_tfidf.html')\n",
    "display(HTML('lda_tfidf.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-renaissance",
   "metadata": {},
   "source": [
    "En observant le tableau et le diagramme nous voyons que les documents sont répartis de manière assez égale hormis le topic 6 (sous-représenté à 9,72%) et le topic 7 (sur-représenté à 20,60%). Hormis le topic 7, des noms de technologies font partie des dix mots clés les plus représentés. \n",
    "\n",
    "Nous constatons cependant un nombre important de mots clés génériques associés à chaque topic comme par exemple error, number ou class. Enfin, les topics 1 et 3 ainsi que 2 et 4 ont de petites zones de recoupement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-chassis",
   "metadata": {},
   "source": [
    "### Fonction de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-trance",
   "metadata": {},
   "source": [
    "La fonction de prédiction des tags que nous avons construisons retourne les 20 mots les plus représentés du topic le plus représenté du texte soumis au modèle. A l’image de l’approche supervisée nous filtrons les résultats en ne gardant que les mots clés présents dans le texte soumis. \n",
    "\n",
    "A noter que l’approche non supervisée ne nécessite que de maintenir, en plus du TF-IDF le modèle LDA ainsi qu’un vocabulary (dictionnaire de correspondance) lié au corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "featured-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = optimal_model\n",
    "def predict_unsupervised_tags(text):\n",
    "    \"\"\"\n",
    "    Predict tags of a preprocessed text\n",
    "    \n",
    "    Args:\n",
    "        text(list): preprocessed text\n",
    "        \n",
    "    Returns:\n",
    "        relevant_tags(list): list of tags\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus_new = id2word.doc2bow(text)\n",
    "    topics = lda_model.get_document_topics(corpus_new)\n",
    "    \n",
    "    #find most relevant topic according to probability\n",
    "    relevant_topic = topics[0][0]\n",
    "    relevant_topic_prob = topics[0][1]\n",
    "    \n",
    "    for i in range(len(topics)):\n",
    "        if topics[i][1] > relevant_topic_prob:\n",
    "            relevant_topic = topics[i][0]\n",
    "            relevant_topic_prob = topics[i][1]\n",
    "            \n",
    "    #retrieve associated to topic tags present in submited text\n",
    "    potential_tags = lda_model.get_topic_terms(topicid=relevant_topic, topn=20)\n",
    "    \n",
    "    relevant_tags = [id2word[tag[0]] for tag in potential_tags if id2word[tag[0]] in text]\n",
    "    \n",
    "    return relevant_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-spotlight",
   "metadata": {},
   "source": [
    "### Fonction de vérification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-juvenile",
   "metadata": {},
   "source": [
    "Nous mettons à jour la fonction de vérification afin de comparer pour un document les tags renseignés par les utilisateurs et ceux prédit par les approches supervisées et non supervisée. \n",
    "\n",
    "Nous la testons sur les premiers documents du corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ordered-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test des 10 premiers documents du corpus\n",
      "\n",
      "Document 0:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "Why is processing a sorted array faster than processing an unsorted array? <p>Here is a piece of C++ code that shows some very peculiar behavior. For some strange reason, sorting the data miraculously makes the code almost six times faster:</p>\n",
      "<pre class=\"lang-cpp prettyprint-override\"><code>#include &lt;algorithm&gt;\n",
      "#include &lt;ctime&gt;\n",
      "#include &lt;iostream&gt;\n",
      "\n",
      "int main()\n",
      "{\n",
      "    // Generate data\n",
      "    const unsigned arraySize = 32768;\n",
      "    int data[arraySize];\n",
      "\n",
      "    for (unsigned c = 0; c &lt; arraySize; ++c)\n",
      "        data[c] = std::rand() % 256;\n",
      "\n",
      "    // !!! With this, the next loop runs faster.\n",
      "    std::sort(data, data + arraySize);\n",
      "\n",
      "    // Test\n",
      "    clock_t start = clock();\n",
      "    long long sum = 0;\n",
      "    for (unsigned i = 0; i &lt; 100000; ++i)\n",
      "    {\n",
      "        for (unsigned c = 0; c &lt; arraySize; ++c)\n",
      "        {   // Primary loop\n",
      "            if (data[c] &gt;= 128)\n",
      "                sum += data[c];\n",
      "        }\n",
      "    }\n",
      "\n",
      "    double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC;\n",
      "\n",
      "    std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl;\n",
      "    std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; std::endl;\n",
      "}\n",
      "</code></pre>\n",
      "<ul>\n",
      "<li>Without <code>std::sort(data, data + arraySize);</code>, the code runs in 11.54 seconds.</li>\n",
      "<li>With the sorted data, the code runs in 1.93 seconds.</li>\n",
      "</ul>\n",
      "<hr />\n",
      "<p>Initially, I thought this might be just a language or compiler anomaly, so I tried Java:</p>\n",
      "<pre class=\"lang-java prettyprint-override\"><code>import java.util.Arrays;\n",
      "import java.util.Random;\n",
      "\n",
      "public class Main\n",
      "{\n",
      "    public static void main(String[] args)\n",
      "    {\n",
      "        // Generate data\n",
      "        int arraySize = 32768;\n",
      "        int data[] = new int[arraySize];\n",
      "\n",
      "        Random rnd = new Random(0);\n",
      "        for (int c = 0; c &lt; arraySize; ++c)\n",
      "            data[c] = rnd.nextInt() % 256;\n",
      "\n",
      "        // !!! With this, the next loop runs faster\n",
      "        Arrays.sort(data);\n",
      "\n",
      "        // Test\n",
      "        long start = System.nanoTime();\n",
      "        long sum = 0;\n",
      "        for (int i = 0; i &lt; 100000; ++i)\n",
      "        {\n",
      "            for (int c = 0; c &lt; arraySize; ++c)\n",
      "            {   // Primary loop\n",
      "                if (data[c] &gt;= 128)\n",
      "                    sum += data[c];\n",
      "            }\n",
      "        }\n",
      "\n",
      "        System.out.println((System.nanoTime() - start) / 1000000000.0);\n",
      "        System.out.println(&quot;sum = &quot; + sum);\n",
      "    }\n",
      "}\n",
      "</code></pre>\n",
      "<p>With a similar but less extreme result.</p>\n",
      "<hr />\n",
      "<p>My first thought was that sorting brings the data into the <a href=\"https://en.wikipedia.org/wiki/CPU_cache\" rel=\"noreferrer\">cache</a>, but then I thought how silly that was because the array was just generated.</p>\n",
      "<ul>\n",
      "<li>What is going on?</li>\n",
      "<li>Why is processing a sorted array faster than processing an unsorted array?</li>\n",
      "</ul>\n",
      "<p>The code is summing up some independent terms, so the order should not matter.</p>\n",
      "<hr />\n",
      "<p><strong>Related / followup Q&amp;As</strong> about the same effect with different / later compilers and options:</p>\n",
      "<ul>\n",
      "<li><a href=\"https://stackoverflow.com/q/66521344\">Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?</a></li>\n",
      "<li><a href=\"https://stackoverflow.com/q/28875325\">gcc optimization flag -O3 makes code slower than -O2</a></li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['java', 'performance', 'architecture', 'branch', 'prediction']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['loop', 'array', 'java', 'string']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['system', 'void', 'class', 'code', 'string']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 1:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How do I undo the most recent local commits in Git? <p>I accidentally <strong>committed the wrong files</strong> to <a href=\"https://en.wikipedia.org/wiki/Git\" rel=\"noreferrer\">Git</a>, but didn't push the commit to the server yet.</p>\n",
      "<p>How can I <strong>undo those commits from the local repository</strong>?</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['version', 'control', 'commit', 'undo']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['server']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['server']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How do I delete a Git branch locally and remotely? <p>I want to delete a branch both locally and remotely.</p>\n",
      "<h2>Failed Attempts to Delete a Remote Branch</h2>\n",
      "<pre class=\"lang-sh prettyprint-override\"><code>$ git branch -d remotes/origin/bugfix\n",
      "error: branch 'remotes/origin/bugfix' not found.\n",
      "\n",
      "$ git branch -d origin/bugfix\n",
      "error: branch 'origin/bugfix' not found.\n",
      "\n",
      "$ git branch -rd origin/bugfix\n",
      "Deleted remote branch origin/bugfix (was 2a14ef7).\n",
      "\n",
      "$ git push\n",
      "Everything up-to-date\n",
      "\n",
      "$ git pull\n",
      "From github.com:gituser/gitproject\n",
      "\n",
      "* [new branch] bugfix -&gt; origin/bugfix\n",
      "Already up-to-date.\n",
      "</code></pre>\n",
      "<p>What should I do differently to successfully delete the <code>remotes/origin/bugfix</code> branch both locally and remotely?</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['version', 'control', 'branch', 'push', 'remote']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['push', 'date', 'github']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['date']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 3:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How do I force \"git pull\" to overwrite local files? <p>How do I force an overwrite of local files on a <code>git pull</code>?</p>\n",
      "\n",
      "<p><strong>The scenario is the following:</strong></p>\n",
      "\n",
      "<ul>\n",
      "<li>A team member is modifying the templates for a website we are working on</li>\n",
      "<li>They are adding some images to the images directory (but forgets to add them under source control)</li>\n",
      "<li>They are sending the images by mail, later, to me</li>\n",
      "<li>I'm adding the images under the source control and pushing them to GitHub together with other changes</li>\n",
      "<li>They cannot pull updates from GitHub because Git doesn't want to overwrite their files.</li>\n",
      "</ul>\n",
      "\n",
      "<p><strong>This is the error I'm getting:</strong></p>\n",
      "\n",
      "<blockquote>\n",
      "  <p>error: Untracked working tree file 'public/images/icon.gif' would be overwritten by merge</p>\n",
      "</blockquote>\n",
      "\n",
      "<p>How do I force Git to overwrite them? The person is a designer - usually, I resolve all the conflicts by hand, so the server has the most recent version that they just need to update on their computer.</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['version', 'control', 'overwrite', 'pull', 'fetch']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['github', 'file']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['file', 'error', 'version']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 4:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How do I revert a Git repository to a previous commit? <p>How do I revert from my current state to a snapshot made on a certain commit?</p>\n",
      "\n",
      "<p>If I do <code>git log</code>, then I get the following output:</p>\n",
      "\n",
      "<pre><code>$ git log\n",
      "commit a867b4af366350be2e7c21b8de9cc6504678a61b`\n",
      "Author: Me &lt;me@me.com&gt;\n",
      "Date:   Thu Nov 4 18:59:41 2010 -0400\n",
      "\n",
      "blah blah blah...\n",
      "\n",
      "commit 25eee4caef46ae64aa08e8ab3f988bc917ee1ce4\n",
      "Author: Me &lt;me@me.com&gt;\n",
      "Date:   Thu Nov 4 05:13:39 2010 -0400\n",
      "\n",
      "more blah blah blah...\n",
      "\n",
      "commit 0766c053c0ea2035e90f504928f8df3c9363b8bd\n",
      "Author: Me &lt;me@me.com&gt;\n",
      "Date:   Thu Nov 4 00:55:06 2010 -0400\n",
      "\n",
      "And yet more blah blah...\n",
      "\n",
      "commit 0d1d7fc32e5a947fbd92ee598033d85bfc445a50\n",
      "Author: Me &lt;me@me.com&gt;\n",
      "Date:   Wed Nov 3 23:56:08 2010 -0400\n",
      "\n",
      "Yep, more blah blah.\n",
      "</code></pre>\n",
      "\n",
      "<p>How do I revert to the commit from November 3, i.e. commit <code>0d1d7fc</code>?</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['checkout', 'reset', 'revert']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['date']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['date']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 5:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How do I check out a remote Git branch? <p>Somebody pushed a branch called <code>test</code> with <code>git push origin test</code> to a shared repository. I can see the branch with <code>git branch -r</code>.</p>\n",
      "\n",
      "<p>Now I'm trying to check out the remote <code>test</code> branch.</p>\n",
      "\n",
      "<p>I've tried:</p>\n",
      "\n",
      "<ul>\n",
      "<li><p><code>git checkout test</code> which does nothing</p></li>\n",
      "<li><p><code>git checkout origin/test</code> gives <code>* (no branch)</code>. Which is confusing. How can I be on \"no branch\"?</p></li>\n",
      "</ul>\n",
      "\n",
      "<p>How do I check out a remote Git branch?</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['checkout', 'remote', 'branch']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['push']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['test']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 6:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How to make Git \"forget\" about a file that was tracked but is now in .gitignore? <p>There is a file that was being tracked by <code>git</code>, but now the file is on the <code>.gitignore</code> list.</p>\n",
      "\n",
      "<p>However, that file keeps showing up in <code>git status</code> after it's edited. How do you force <code>git</code> to completely forget about it?</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['gitignore']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['list', 'file']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['file']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 7:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "What is the difference between \"px\", \"dip\", \"dp\" and \"sp\"? <p>What is the difference between Android units of measure?</p>\n",
      "\n",
      "<ul>\n",
      "<li>px</li>\n",
      "<li>dip</li>\n",
      "<li>dp</li>\n",
      "<li>sp</li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['android', 'android', 'layout', 'user', 'interface', 'dimension', 'unit', 'measurement']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: []\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['difference']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 8:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "How do I find all files containing specific text on Linux? <p>I'm trying to find a way to scan my entire Linux system for all files containing a specific string of text. Just to clarify, I'm looking for text within the file, not in the file name.</p>\n",
      "\n",
      "<p>When I was looking up how to do this, I came across this solution twice:</p>\n",
      "\n",
      "<pre><code>find / -type f -exec grep -H 'text-to-find-here' {} \\;\n",
      "</code></pre>\n",
      "\n",
      "<p>However, it doesn't work. It seems to display every single file in the system.</p>\n",
      "\n",
      "<p>Is this close to the proper way to do it? If not, how should I? This ability to find text strings in files would be extraordinarily useful for some programming projects I'm doing.</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['linux', 'text', 'grep', 'directory', 'find']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['file']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['file']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document 9:\n",
      "\n",
      "\n",
      "Publication originale: \n",
      "\n",
      "What is the difference between POST and PUT in HTTP? <p>According to <a href=\"https://tools.ietf.org/html/rfc2616#section-9.5\" rel=\"noreferrer\">RFC 2616, § 9.5</a>, <code>POST</code> is used to <em>create</em> a resource:</p>\n",
      "<blockquote>\n",
      "<p>The POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-Line.</p>\n",
      "</blockquote>\n",
      "<p>According to <a href=\"https://tools.ietf.org/html/rfc2616#section-9.6\" rel=\"noreferrer\">RFC 2616, § 9.6</a>, <code>PUT</code> is used to <em>create or replace</em> a resource:</p>\n",
      "<blockquote>\n",
      "<p>The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.</p>\n",
      "</blockquote>\n",
      "<p>So which HTTP method should be used to create a resource? Or should both be supported?</p>\n",
      "\n",
      "\n",
      "\n",
      "Liste des tags pré-traités utilisés par l'utilisateur: ['http', 'rest', 'post']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle supervisé: ['server', 'entity']\n",
      "\n",
      "\n",
      "Liste des tags prédits par le modèle non supervisé: ['request', 'http', 'post', 'server']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_tag_predction(original_text, original_tags, preprocessed_text, supervised_model):\n",
    "    \"\"\"\n",
    "    Check original tags vs predicted tags for a post.\n",
    "    \n",
    "    Args:\n",
    "        post(list) : original text\n",
    "        original_tags(list) : preprocessed_tags\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_supervised_tags = predict_supervised_tags(supervised_model, mlb, preprocessed_text)\n",
    "    predicted_unsupervised_tags = predict_unsupervised_tags(preprocessed_text)\n",
    "    print(\"Publication originale: \\n\")\n",
    "    print(f\"{original_text}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags pré-traités utilisés par l'utilisateur: {original_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle supervisé: {predicted_supervised_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle non supervisé: {predicted_unsupervised_tags}\")\n",
    "\n",
    "print(\"Test des 10 premiers documents du corpus\\n\")\n",
    "for i in range(10):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(\"\\n\")\n",
    "    check_tag_predction(filtered_tokenized_vs_original.loc[i,'Post'], \n",
    "                    filtered_tokenized_vs_original.loc[i,'splitted_tags'],\n",
    "                    filtered_tokenized_vs_original.loc[i,'splitted_text'],\n",
    "                    svm_clf)\n",
    "    print(\"-\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-apartment",
   "metadata": {},
   "source": [
    "Si nous n’avons pas pu pas comparer les performances des approches supervisées et non supervisées sur des indicateurs communs nous avons comparé les prédictions des deux modèles  retenus aux tags initiaux renseignés par des utilisateurs sur dix documents. \n",
    "\n",
    "Sur un nombre aussi restreint de tests empiriques il serait hasardeux de tirer des conclusions quant aux choix d’un modèle. Nous notons néanmoins, qu’à une exception près pour chacun d’eux, que les deux modèles ont retourné des tags cohérents avec ceux initialement renseigné par les utilisateurs . \n",
    "Au-delà des prédictions, il s’avère que l’approche non supervisée est soumise à moins de contraintes que l’approche supervisée. En effet l’approche supervisée nécessite un travail plus important sur le dimensionnement des données et leur pré-traitement avant entrainement. De plus cette approche nécessite de maintenir plus de ressources (modèle de PCA,  modèle de vectorisation des tags, SVM) que l’approche non supervisée (modèle LDA et vocabulary). Pour ces raisons nous privilégions l’approche non supervisée. Nous intégrons toutefois les deux approches dans l’API à titre d’illustration.\n",
    "\n",
    "Nous sauvegardons enfin le modèle LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recovered-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "filename_model = './models/lda_model.pkl'\n",
    "pickle.dump(lda_model, open(filename_model,'wb'))\n",
    "\n",
    "filename_dictionary = './models/dictionary.pkl'\n",
    "pickle.dump(id2word, open(filename_dictionary,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-plate",
   "metadata": {},
   "source": [
    "Les livrables sont disponibles en ligne :\n",
    "- [Repository de travaux de pré-traitement des documents et entrainement des modèles](https://github.com/viczer/IML/tree/main/P5_draft_v3)\n",
    "- [Repository de l’API](https://github.com/viczer/API_stackoverflow)\n",
    "- [Documentation de l’API](https://stackoverflowtagspredict.herokuapp.com/docs)\n",
    "- [Endepoint de l’API](https://stackoverflowtagspredict.herokuapp.com/predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "253cd15c32ffb283b0558be93b097dc27093fe6b891853f454fa08d2f15e4a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
